"""
Doubao-Seed èŠ‚ç‚¹
åŸºäºComfyUI_Comflyé¡¹ç›®çš„Doubao Seedream4å®ç°
é›†æˆå¤šå®¶APIè°ƒç”¨ï¼Œæ”¯æŒå›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”ŸæˆåŠŸèƒ½
"""

import os
import json
import requests
import time
import random
import base64
import io
import subprocess
from PIL import Image
import torch
import numpy as np
from typing import Optional, Dict, Any, List, Tuple
import urllib3
import ssl
import glob

# å¯¼å…¥ ComfyUI çš„æ–‡ä»¶å¤¹è·¯å¾„
try:
    import folder_paths
    input_dir = folder_paths.get_input_directory()
    output_dir = folder_paths.get_output_directory()
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ folder_pathsï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    input_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "input")
    output_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "output")
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import tempfile
import shutil
from urllib.parse import urlparse
from fractions import Fraction

# å¯¼å…¥ComfyUIçš„è§†é¢‘ç±»å‹ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†
try:
    from comfy_api.input_impl import VideoFromFile
    HAS_COMFYUI_VIDEO = True
    print("[Video_Utiliities] ä¿¡æ¯ï¼šâœ… ComfyUIå®˜æ–¹è§†é¢‘ç±»å‹å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    HAS_COMFYUI_VIDEO = False
    print(f"[Video_Utiliities] ä¿¡æ¯ï¼šâš ï¸ ComfyUIè§†é¢‘ç±»å‹å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
    # åˆ›å»ºç®€å•çš„æ›¿ä»£ç±»
    class VideoFromFile:
        def __init__(self, file_path):
            self.file_path = file_path
        def get_dimensions(self):
            return (512, 512)  # é»˜è®¤å°ºå¯¸

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†åº“
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    _log_warning("OpenCVæœªå®‰è£…ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å—é™")

try:
    import imageio
    HAS_IMAGEIO = True
except ImportError:
    HAS_IMAGEIO = False

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def create_ssl_compatible_session():
    """åˆ›å»ºSSLå…¼å®¹çš„requests session"""
    session = requests.Session()

    # é…ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )

    # åˆ›å»ºè‡ªå®šä¹‰çš„HTTPAdapter
    class SSLAdapter(HTTPAdapter):
        def init_poolmanager(self, *args, **kwargs):
            # åˆ›å»ºæ›´å®½æ¾çš„SSLä¸Šä¸‹æ–‡
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            # æ”¯æŒæ›´å¤šSSLåè®®ç‰ˆæœ¬å’Œå¯†ç å¥—ä»¶
            try:
                ssl_context.minimum_version = ssl.TLSVersion.TLSv1
                ssl_context.maximum_version = ssl.TLSVersion.TLSv1_3
            except AttributeError:
                # å…¼å®¹æ—§ç‰ˆæœ¬Python
                pass

            # è®¾ç½®æ›´å®½æ¾çš„å¯†ç å¥—ä»¶
            try:
                ssl_context.set_ciphers('DEFAULT:@SECLEVEL=1')
            except ssl.SSLError:
                try:
                    ssl_context.set_ciphers('ALL:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!SRP:!CAMELLIA')
                except ssl.SSLError:
                    pass  # ä½¿ç”¨é»˜è®¤å¯†ç å¥—ä»¶

            # ç¦ç”¨å„ç§SSLæ£€æŸ¥
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            kwargs['ssl_context'] = ssl_context
            return super().init_poolmanager(*args, **kwargs)

    # åº”ç”¨é€‚é…å™¨
    adapter = SSLAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)

    # è®¾ç½®è¶…æ—¶å’Œå…¶ä»–é€‰é¡¹
    session.verify = False  # ç¦ç”¨SSLéªŒè¯

    return session

# å…¨å±€å¸¸é‡å’Œé…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SEEDREAM4_CONFIG_FILE = 'SeedReam4_config.json'

def _log_info(message):
    print(f"[SeedReam4API] ä¿¡æ¯ï¼š{message}")

def _log_warning(message):
    print(f"[SeedReam4API] è­¦å‘Šï¼š{message}")

def _log_error(message):
    print(f"[SeedReam4API] é”™è¯¯ï¼š{message}")
def tensor2pil(tensor):
    """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ - æ”¯æŒComfyUIçš„[B, H, W, C]æ ¼å¼"""
    if tensor is None:
        _log_warning("âš ï¸ tensor2pil: è¾“å…¥tensorä¸ºNone")
        return None
    if isinstance(tensor, list):
        return [tensor2pil(img) for img in tensor]

    try:
        # ç¡®ä¿tensoræ˜¯4ç»´çš„
        if len(tensor.shape) == 3:
            tensor = tensor.unsqueeze(0)

        # å¦‚æœæ˜¯batchï¼Œå¤„ç†å¤šå›¾æƒ…å†µï¼ˆè¿™é‡Œåªå¤„ç†å•å›¾è½¬æ¢ï¼Œå¤šå›¾æ‹¼æ¥åœ¨image_to_base64ä¸­å¤„ç†ï¼‰
        if len(tensor.shape) == 4 and tensor.shape[0] > 1:
            # å¯¹äºtensor2pilå‡½æ•°ï¼Œæˆ‘ä»¬åªè½¬æ¢ç¬¬ä¸€å¼ å›¾åƒ
            # å¤šå›¾æ‹¼æ¥é€»è¾‘åœ¨image_to_base64å‡½æ•°ä¸­å¤„ç†
            tensor = tensor[0:1]

        # ç°åœ¨åº”è¯¥æ˜¯ [1, H, W, C] æ ¼å¼ï¼Œå»æ‰batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor.squeeze(0)  # å˜æˆ [H, W, C]

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢é€šé“é¡ºåº
        if len(tensor.shape) == 3:
            # å¦‚æœæœ€åä¸€ä¸ªç»´åº¦ä¸æ˜¯3ï¼ˆRGBé€šé“ï¼‰ï¼Œå¯èƒ½æ˜¯[C, H, W]æ ¼å¼
            if tensor.shape[-1] != 3 and tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)  # [C, H, W] -> [H, W, C]

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if hasattr(tensor, 'cpu'):
            # PyTorch tensor
            np_image = tensor.cpu().numpy()
        else:
            # å·²ç»æ˜¯numpyæ•°ç»„
            np_image = tensor

        # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´æ­£ç¡®
        if np_image.dtype != np.uint8:
            if np_image.max() <= 1.0:
                np_image = (np_image * 255).astype(np.uint8)
            else:
                np_image = np.clip(np_image, 0, 255).astype(np.uint8)

        # å¦‚æœæ˜¯ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸ºRGB
        if len(np_image.shape) == 2:
            np_image = np.stack([np_image] * 3, axis=-1)
        elif np_image.shape[-1] == 1:
            np_image = np.repeat(np_image, 3, axis=-1)

        pil_image = Image.fromarray(np_image)

        return pil_image

    except Exception as e:
        _log_error(f"âŒ tensor2pilè½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def pil2tensor(image):
    """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    if image is None:
        return None
    if isinstance(image, list):
        if len(image) == 0:
            return torch.empty(0)
        return torch.cat([pil2tensor(img) for img in image], dim=0)
    
    # è½¬æ¢ä¸ºRGB
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    elif image.mode != 'RGB':
        image = image.convert('RGB')
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–åˆ°[0, 1]
    img_array = np.array(image).astype(np.float32) / 255.0
    
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(img_array)[None,]

def create_blank_tensor(width=1024, height=1024):
    """åˆ›å»ºæ­£ç¡®æ ¼å¼çš„ç©ºç™½tensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    blank_image = Image.new('RGB', (width, height), color='white')
    np_image = np.array(blank_image).astype(np.float32) / 255.0
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(np_image)[None,]

def ensure_tensor_format(tensor):
    """ç¡®ä¿tensoræ ¼å¼å®Œå…¨ç¬¦åˆComfyUIè¦æ±‚ - æ ¼å¼ä¸º[1, H, W, 3]"""
    if tensor is None:
        return create_blank_tensor()
    
    original_shape = tensor.shape
    _log_info(f"ğŸ” è¾“å…¥tensorå½¢çŠ¶: {original_shape}")
    
    # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœtensorå½¢çŠ¶æ˜¯ (1, 1, 2048) æˆ–ç±»ä¼¼æ ¼å¼
    if len(tensor.shape) == 3 and tensor.shape[1] == 1 and tensor.shape[2] > 1000:
        _log_warning(f"âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸tensorå½¢çŠ¶: {tensor.shape}ï¼Œå¯èƒ½æ˜¯1Dæ•°æ®è¢«é”™è¯¯reshape")
        return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯4ç»´tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3]
    if len(tensor.shape) != 4:
        if len(tensor.shape) == 3:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ (H, W, 3) æ ¼å¼
            if tensor.shape[-1] == 3:
                tensor = tensor.unsqueeze(0)
                _log_info(f"ğŸ”§ æ·»åŠ batchç»´åº¦: {tensor.shape}")
            else:
                _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
                return create_blank_tensor()
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯ (batch, height, width, channels) æ ¼å¼
    if tensor.shape[-1] != 3:
        if tensor.shape[1] == 3:  # å¦‚æœæ˜¯ (batch, channels, height, width) æ ¼å¼
            tensor = tensor.permute(0, 2, 3, 1)
            _log_info(f"ğŸ”§ é‡æ–°æ’åˆ—tensorç»´åº¦: {tensor.shape}")
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensoré€šé“ç»´åº¦: {tensor.shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    if tensor.dtype != torch.float32:
        tensor = tensor.float()
        _log_info(f"ğŸ”§ è½¬æ¢tensoræ•°æ®ç±»å‹: {tensor.dtype}")
    
    # ç¡®ä¿å€¼èŒƒå›´æ­£ç¡® (0-1)
    if tensor.min() < 0 or tensor.max() > 1:
        tensor = torch.clamp(tensor, 0, 1)
        _log_info(f"ğŸ”§ é™åˆ¶tensorå€¼èŒƒå›´: {tensor.min().item():.3f} åˆ° {tensor.max().item():.3f}")
    
    # ç¡®ä¿æ²¡æœ‰å¼‚å¸¸å€¼
    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
        _log_error("âŒ tensoråŒ…å«å¼‚å¸¸å€¼ï¼Œä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
        return create_blank_tensor()
    
    # æœ€ç»ˆéªŒè¯ - ç¡®ä¿æ˜¯[1, H, W, 3]æ ¼å¼
    if len(tensor.shape) != 4 or tensor.shape[-1] != 3:
        _log_error(f"âŒ æœ€ç»ˆtensoræ ¼å¼ä»ç„¶ä¸æ­£ç¡®: {tensor.shape}")
        return create_blank_tensor()
    
    _log_info(f"âœ… tensoræ ¼å¼éªŒè¯é€šè¿‡: {tensor.shape}")
    return tensor

def image_to_base64(image_tensor, max_size=2048, return_data_url=True):
    """å°†tensorè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²ï¼Œæ”¯æŒè‡ªåŠ¨å‹ç¼©å’Œå¤šå›¾æ‹¼æ¥

    Args:
        image_tensor: è¾“å…¥çš„å›¾åƒtensor
        max_size: æœ€å¤§å°ºå¯¸é™åˆ¶
        return_data_url: æ˜¯å¦è¿”å›å®Œæ•´çš„data URLæ ¼å¼ï¼ŒFalseåˆ™åªè¿”å›base64å­—ç¬¦ä¸²
    """
    if image_tensor is None:
        return None

    # å¦‚æœæ˜¯batchï¼Œå°†å¤šå¼ å›¾åƒæ°´å¹³æ‹¼æ¥æˆä¸€å¼ å¤§å›¾
    if len(image_tensor.shape) == 4 and image_tensor.shape[0] > 1:
        _log_info(f"ğŸ” æ£€æµ‹åˆ°å¤šå›¾batchè¾“å…¥ {image_tensor.shape}ï¼Œå°†æ‹¼æ¥æˆä¸€å¼ å¤§å›¾")

        # å°†æ¯å¼ å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_images = []
        for i in range(image_tensor.shape[0]):
            single_tensor = image_tensor[i:i+1]  # ä¿æŒ4Dæ ¼å¼
            pil_img = tensor2pil(single_tensor)
            if pil_img is not None:
                pil_images.append(pil_img)

        if not pil_images:
            return None

        # æ°´å¹³æ‹¼æ¥å›¾åƒ
        total_width = sum(img.width for img in pil_images)
        max_height = max(img.height for img in pil_images)

        # åˆ›å»ºæ‹¼æ¥åçš„å¤§å›¾
        combined_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))
        x_offset = 0
        for img in pil_images:
            combined_image.paste(img, (x_offset, 0))
            x_offset += img.width

        pil_image = combined_image
        _log_info(f"ğŸ”§ å¤šå›¾æ‹¼æ¥å®Œæˆ: {len(pil_images)}å¼ å›¾ -> {pil_image.size}")
    else:
        pil_image = tensor2pil(image_tensor)
        if pil_image is None:
            return None

    # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼Œå¦‚æœè¿‡å¤§åˆ™å‹ç¼©
    original_size = pil_image.size
    if max(original_size) > max_size:
        # è®¡ç®—æ–°å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
        ratio = max_size / max(original_size)
        new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))
        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
        _log_info(f"ğŸ”§ å›¾åƒå‹ç¼©: {original_size} -> {new_size}")

    buffered = io.BytesIO()
    # ä½¿ç”¨JPEGæ ¼å¼å‹ç¼©å¤§å›¾åƒï¼ŒPNGæ ¼å¼ä¿ç•™å°å›¾åƒ
    if max(pil_image.size) > 1024:
        # å¯¹äºå›¾åƒç¼–è¾‘ï¼Œä½¿ç”¨æ›´é«˜è´¨é‡çš„JPEG
        quality = 90 if max(original_size) > max_size else 85
        pil_image.save(buffered, format="JPEG", quality=quality, optimize=True)
        format_prefix = "data:image/jpeg;base64,"
    else:
        pil_image.save(buffered, format="PNG", optimize=True)
        format_prefix = "data:image/png;base64,"

    image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

    # éªŒè¯base64å­—ç¬¦ä¸²çš„æœ‰æ•ˆæ€§
    try:
        # å°è¯•è§£ç éªŒè¯
        base64.b64decode(image_base64)
    except Exception as e:
        _log_warning(f"âš ï¸ Base64ç¼–ç éªŒè¯å¤±è´¥: {e}")
        return None

    if return_data_url:
        return f"{format_prefix}{image_base64}"
    else:
        return image_base64

def download_video_from_url(video_url: str, output_dir: str = None) -> str:
    """ä»URLä¸‹è½½è§†é¢‘æ–‡ä»¶"""
    try:
        if not video_url or not video_url.strip():
            raise ValueError("è§†é¢‘URLä¸ºç©º")

        # è§£æURLè·å–æ–‡ä»¶å
        parsed_url = urlparse(video_url)
        filename = os.path.basename(parsed_url.path)
        if not filename or '.' not in filename:
            filename = f"video_{int(time.time())}.mp4"

        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir is None:
            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except:
                output_dir = tempfile.gettempdir()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # å®Œæ•´çš„è¾“å‡ºè·¯å¾„
        output_path = os.path.join(output_dir, filename)

        _log_info(f"ğŸ”½ å¼€å§‹ä¸‹è½½è§†é¢‘: {video_url}")
        _log_info(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")

        # ä¸‹è½½è§†é¢‘
        response = requests.get(video_url, stream=True, timeout=300)
        response.raise_for_status()

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        file_size = os.path.getsize(output_path)
        _log_info(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {filename} ({file_size / 1024 / 1024:.2f} MB)")

        return output_path

    except Exception as e:
        _log_error(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
        return None

def video_to_comfyui_video(video_path: str):
    """å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†VideoFromFile"""
    try:
        if not video_path or not os.path.exists(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        _log_info(f"ğŸ¬ å¼€å§‹åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡: {video_path}")

        # ä½¿ç”¨ComfyUIå®˜æ–¹æ ‡å‡†ï¼šç›´æ¥ä»æ–‡ä»¶è·¯å¾„åˆ›å»ºVideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(video_path)

        _log_info("âœ… åˆ›å»ºComfyUIæ ‡å‡†VideoFromFileå¯¹è±¡æˆåŠŸ")

        # æµ‹è¯•get_dimensionsæ–¹æ³•
        try:
            dimensions = video_obj.get_dimensions()
            _log_info(f"ğŸ“Š è§†é¢‘å°ºå¯¸: {dimensions}")
        except Exception as e:
            _log_warning(f"âš ï¸ æ— æ³•è·å–è§†é¢‘å°ºå¯¸: {e}")

        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºVideoFromFileå¯¹è±¡å¤±è´¥: {e}")
        return None

def create_video_path_wrapper(file_path):
    """åˆ›å»ºä¸€ä¸ªè§†é¢‘è·¯å¾„åŒ…è£…å™¨ï¼Œç”¨äºUtilNodeså…¼å®¹æ€§"""
    # ç›´æ¥è¿”å›æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ï¼Œè®©UtilNodesçš„os.path.basename()èƒ½æ­£å¸¸å·¥ä½œ
    return file_path

def extract_video_last_frame(video_path, output_path=None):
    """
    æå–è§†é¢‘çš„æœ€åä¸€å¸§å›¾åƒ

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        str: è¾“å‡ºå›¾ç‰‡çš„è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        import subprocess
        import tempfile
        from pathlib import Path

        if not os.path.exists(video_path):
            _log_error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if output_path is None:
            video_name = Path(video_path).stem
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{video_name}_last_frame_{int(time.time())}.jpg")

        _log_info(f"ğŸ¬ æ­£åœ¨æå–è§†é¢‘å°¾å¸§: {video_path}")

        # æ–¹æ³•1ï¼šä½¿ç”¨FFmpegçš„select=eofè¿‡æ»¤å™¨
        cmd1 = [
            'ffmpeg',
            '-i', video_path,           # è¾“å…¥è§†é¢‘
            '-vf', 'select=eof',        # é€‰æ‹©æœ€åä¸€å¸§
            '-vsync', 'vfr',            # å¯å˜å¸§ç‡
            '-frames:v', '1',           # åªè¾“å‡º1å¸§
            '-y',                       # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]

        try:
            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {output_path}")
                return output_path
        except:
            pass

        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
        _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•æå–å°¾å¸§...")

        # è·å–è§†é¢‘æ—¶é•¿
        duration_cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-show_entries', 'format=duration',
            '-of', 'csv=p=0',
            video_path
        ]

        duration_result = subprocess.run(
            duration_cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        if duration_result.returncode == 0:
            try:
                duration = float(duration_result.stdout.strip())
                seek_time = max(0, duration - 0.1)  # æå–æœ€å0.1ç§’å‰çš„å¸§

                cmd2 = [
                    'ffmpeg',
                    '-ss', str(seek_time),
                    '-i', video_path,
                    '-frames:v', '1',
                    '-y',
                    output_path
                ]

                result = subprocess.run(
                    cmd2,
                    capture_output=True,
                    text=True,
                    timeout=60
                )

                if result.returncode == 0 and os.path.exists(output_path):
                    _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ (å¤‡ç”¨æ–¹æ³•): {output_path}")
                    return output_path
            except:
                pass

        _log_error("âŒ æ‰€æœ‰å°¾å¸§æå–æ–¹æ³•éƒ½å¤±è´¥äº†")
        return None

    except Exception as e:
        _log_error(f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}")
        return None

def merge_videos_with_ffmpeg(video_paths, output_path=None):
    """ä½¿ç”¨ffmpegåˆå¹¶å¤šä¸ªè§†é¢‘æ–‡ä»¶"""
    try:
        import subprocess
        import tempfile

        if not video_paths or len(video_paths) < 2:
            _log_warning("âš ï¸ è§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return video_paths[0] if video_paths else None

        # éªŒè¯æ‰€æœ‰è§†é¢‘æ–‡ä»¶å­˜åœ¨
        valid_paths = []
        for path in video_paths:
            if path and os.path.exists(path):
                valid_paths.append(path)
            else:
                _log_warning(f"âš ï¸ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")

        if len(valid_paths) < 2:
            _log_warning("âš ï¸ æœ‰æ•ˆè§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return valid_paths[0] if valid_paths else None

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•
        if not output_path:
            timestamp = int(time.time())
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except ImportError:
                # æ¨æ–­ComfyUIè¾“å‡ºç›®å½•
                current_dir = os.path.dirname(os.path.abspath(__file__))
                path_parts = current_dir.split(os.sep)
                comfyui_root = None

                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
            except:
                import tempfile
                output_dir = tempfile.gettempdir()
            output_path = os.path.join(output_dir, f"merged_continuous_video_{timestamp}.mp4")

        _log_info(f"ğŸ¬ å¼€å§‹åˆå¹¶{len(valid_paths)}ä¸ªè§†é¢‘æ–‡ä»¶...")
        _log_info(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")

        # åˆ›å»ºffmpegè¾“å…¥æ–‡ä»¶åˆ—è¡¨
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            for path in valid_paths:
                # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                abs_path = os.path.abspath(path).replace('\\', '/')
                f.write(f"file '{abs_path}'\n")
            input_list_path = f.name

        try:
            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', input_list_path,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç 
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œffmpegå‘½ä»¤: {' '.join(cmd)}")

            # æ‰§è¡Œffmpegå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    _log_info(f"âœ… è§†é¢‘åˆå¹¶æˆåŠŸ: {output_path} (å¤§å°: {file_size} bytes)")
                    return output_path
                else:
                    _log_error("âŒ ffmpegæ‰§è¡ŒæˆåŠŸä½†è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    return None
            else:
                _log_error(f"âŒ ffmpegæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return None

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(input_list_path)
            except:
                pass

    except subprocess.TimeoutExpired:
        _log_error("âŒ ffmpegæ‰§è¡Œè¶…æ—¶")
        return None
    except FileNotFoundError:
        _log_error("âŒ æœªæ‰¾åˆ°ffmpegï¼Œè¯·ç¡®ä¿å·²å®‰è£…ffmpegå¹¶æ·»åŠ åˆ°PATH")
        return None
    except Exception as e:
        _log_error(f"âŒ è§†é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return None

def get_resolution_dimensions(resolution, aspect_ratio):
    """æ ¹æ®åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”è·å–å®é™…åƒç´ å°ºå¯¸

    Args:
        resolution: "480p", "720p", "1080p"
        aspect_ratio: "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"

    Returns:
        tuple: (width, height) æˆ– None
    """
    # Seedance 1.0 pro æ”¯æŒçš„åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”å¯¹åº”è¡¨
    resolution_map = {
        "480p": {
            "16:9": (864, 480),
            "4:3": (736, 544),
            "1:1": (640, 640),
            "3:4": (544, 736),
            "9:16": (480, 864),
            "21:9": (960, 416)
        },
        "720p": {
            "16:9": (1248, 704),
            "4:3": (1120, 832),
            "1:1": (960, 960),
            "3:4": (832, 1120),
            "9:16": (704, 1248),
            "21:9": (1504, 640)
        },
        "1080p": {
            "16:9": (1920, 1088),
            "4:3": (1664, 1248),
            "1:1": (1440, 1440),
            "3:4": (1248, 1664),
            "9:16": (1088, 1920),
            "21:9": (2176, 928)
        }
    }

    if resolution in resolution_map and aspect_ratio in resolution_map[resolution]:
        dimensions = resolution_map[resolution][aspect_ratio]
        _log_info(f"ğŸ” åˆ†è¾¨ç‡è®¡ç®—: {resolution} + {aspect_ratio} = {dimensions[0]}x{dimensions[1]}")
        return dimensions
    else:
        _log_warning(f"âš ï¸ ä¸æ”¯æŒçš„åˆ†è¾¨ç‡æˆ–å®½é«˜æ¯”ç»„åˆ: {resolution} + {aspect_ratio}")
        # è¿”å›é»˜è®¤å€¼
        default_dimensions = (1248, 704)  # 720p 16:9
        _log_info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {default_dimensions[0]}x{default_dimensions[1]}")
        return default_dimensions

def create_blank_video_object(frames=30, height=512, width=512):
    """åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡ - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åˆ›å»ºVideoFromFile"""
    try:
        _log_info(f"ğŸ¬ åˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶: {frames}å¸§, {width}x{height}")

        # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶
        temp_video_path = os.path.join(tempfile.gettempdir(), f"blank_video_{int(time.time())}.mp4")

        # ä½¿ç”¨OpenCVåˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶
        if HAS_CV2:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_video_path, fourcc, 30.0, (width, height))

            # åˆ›å»ºé»‘è‰²å¸§
            blank_frame = np.zeros((height, width, 3), dtype=np.uint8)

            for _ in range(frames):
                out.write(blank_frame)

            out.release()
            _log_info(f"âœ… ç©ºç™½è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {temp_video_path}")
        else:
            # å¦‚æœæ²¡æœ‰OpenCVï¼Œåˆ›å»ºä¸€ä¸ªæœ€å°çš„MP4æ–‡ä»¶
            _log_warning("âš ï¸ æ²¡æœ‰OpenCVï¼Œåˆ›å»ºç®€å•çš„ç©ºç™½è§†é¢‘å¯¹è±¡")
            # è¿™é‡Œæˆ‘ä»¬ä»ç„¶éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
            # ä½œä¸ºå›é€€ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè·¯å¾„
            temp_video_path = "blank_video.mp4"

        # åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(temp_video_path)
        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡å¤±è´¥: {e}")
        # æœ€åçš„å›é€€ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„VideoFromFileå¯¹è±¡
        return VideoFromFile("blank_video.mp4")


    """è°ƒç”¨Comfly API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    # è°ƒè¯•ä¿¡æ¯
    _log_info(f"ğŸ” Comfly APIè°ƒç”¨:")
    _log_info(f"   - ç«¯ç‚¹: {api_url}/images/generations")
    _log_info(f"   - æ¨¡å‹: {payload.get('model', 'N/A')}")
    _log_info(f"   - åŒ…å«å›¾åƒ: {'image' in payload and bool(payload.get('image'))}")
    if 'image' in payload and payload.get('image'):
        _log_info(f"   - å›¾åƒæ•°é‡: {len(payload['image'])}")
        _log_info(f"   - ç¬¬ä¸€å¼ å›¾åƒé•¿åº¦: {len(payload['image'][0]) if payload['image'] else 0}")

    try:
        # ä½¿ç”¨SSLå…¼å®¹çš„session
        session = create_ssl_compatible_session()
        response = session.post(
            f"{api_url}/images/generations",
            headers=headers,
            json=payload,
            timeout=timeout
        )
        return response
    except Exception as e:
        _log_error(f"Comfly APIè°ƒç”¨å¤±è´¥: {e}")
        return None


    """è°ƒç”¨OpenAIå…¼å®¹API - æ”¯æŒT8å›¾åƒç¼–è¾‘"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯T8é•œåƒç«™
        if "t8star.cn" in api_url or "ai.t8star.cn" in api_url:
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒè¾“å…¥
            has_images = "image" in payload and payload["image"]

            # å¯¹äºT8ï¼Œå›¾ç”Ÿå›¾ä¹Ÿä½¿ç”¨images/generationsç«¯ç‚¹ï¼Œè€Œä¸æ˜¯chat/completions
            # åªæœ‰ç‰¹å®šçš„å›¾åƒç¼–è¾‘ä»»åŠ¡æ‰ä½¿ç”¨chat/completions
            use_chat_endpoint = False  # æš‚æ—¶ç¦ç”¨chatç«¯ç‚¹ï¼Œç»Ÿä¸€ä½¿ç”¨images/generations

            if has_images and use_chat_endpoint:
                # å›¾åƒç¼–è¾‘ï¼šä½¿ç”¨chat/completionsç«¯ç‚¹ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
                url = "https://ai.t8star.cn/v1/chat/completions"
                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘ç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç¼–è¾‘çš„payloadæ ¼å¼
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": payload.get("prompt", "")
                            }
                        ]
                    }
                ]

                # æ·»åŠ å›¾åƒåˆ°æ¶ˆæ¯ä¸­
                image_urls = payload.get("image", [])
                if isinstance(image_urls, str):
                    image_urls = [image_urls]

                for image_url in image_urls:
                    messages[0]["content"].append({
                        "type": "image_url",
                        "image_url": {
                            "url": image_url
                        }
                    })

                t8_payload = {
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "messages": messages,
                    "max_tokens": 4096,
                    "temperature": 0.7
                }

                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘è¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æ¶ˆæ¯æ•°={len(t8_payload.get('messages', []))}")

            else:
                # å›¾åƒç”Ÿæˆï¼šä½¿ç”¨images/generationsç«¯ç‚¹
                url = "https://ai.t8star.cn/v1/images/generations"
                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç”Ÿæˆçš„payloadæ ¼å¼
                t8_payload = {
                    "prompt": payload.get("prompt", ""),
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "response_format": payload.get("response_format", "url")
                }

                # æ·»åŠ å¯é€‰å‚æ•°
                if "size" in payload:
                    t8_payload["size"] = payload["size"]
                if "n" in payload:
                    t8_payload["n"] = payload["n"]
                if "seed" in payload and payload["seed"] != -1:
                    t8_payload["seed"] = payload["seed"]
                if "watermark" in payload:
                    t8_payload["watermark"] = payload["watermark"]
                if "tail_on_partial" in payload:
                    t8_payload["tail_on_partial"] = payload["tail_on_partial"]

                # æ·»åŠ å›¾åƒè¾“å…¥æ”¯æŒï¼ˆå›¾ç”Ÿå›¾ï¼‰
                if has_images:
                    t8_payload["image"] = payload["image"]
                    _log_info(f"ğŸ–¼ï¸ T8å›¾ç”Ÿå›¾è¯·æ±‚: åŒ…å« {len(payload['image'])} å¼ è¾“å…¥å›¾åƒ")
                    _log_info(f"ğŸ” å›¾åƒæ•°æ®ç±»å‹: {type(payload['image'])}")
                    if payload['image']:
                        _log_info(f"ğŸ” ç¬¬ä¸€å¼ å›¾åƒæ•°æ®é•¿åº¦: {len(payload['image'][0]) if payload['image'][0] else 0} å­—ç¬¦")

                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆè¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æç¤ºè¯é•¿åº¦={len(t8_payload.get('prompt', ''))}")

        elif api_url.endswith('/v1/chat/completions'):
            url = api_url.replace('/v1/chat/completions', '/v1/images/generations')
            _log_info(f"ğŸ”— è½¬æ¢èŠå¤©ç«¯ç‚¹ä¸ºå›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")
            t8_payload = payload
        else:
            # å…¶ä»–OpenAIå…¼å®¹API
            url = f"{api_url}/v1/images/generations"
            _log_info(f"ğŸ”— ä½¿ç”¨æ ‡å‡†OpenAIç«¯ç‚¹: {url}")
            t8_payload = payload

        # å°è¯•å¤šç§è¿æ¥æ–¹å¼è§£å†³SSLé—®é¢˜
        response = None
        last_error = None

        # æ–¹æ³•1ï¼šç¦ç”¨æ‰€æœ‰SSLéªŒè¯çš„ç®€å•æ–¹å¼
        try:
            import urllib3
            urllib3.disable_warnings()

            # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨SSLéªŒè¯
            import os
            os.environ['PYTHONHTTPSVERIFY'] = '0'
            os.environ['CURL_CA_BUNDLE'] = ''

            response = requests.post(
                url,
                headers=headers,
                json=t8_payload,
                timeout=timeout,
                verify=False,
                stream=False
            )
            _log_info(f"âœ… ç®€å•SSLç¦ç”¨æ–¹å¼æˆåŠŸ")

        except Exception as simple_error:
            last_error = simple_error
            _log_warning(f"ç®€å•SSLç¦ç”¨å¤±è´¥: {simple_error}")

            # æ–¹æ³•2ï¼šä½¿ç”¨SSLå…¼å®¹çš„session
            try:
                session = create_ssl_compatible_session()
                response = session.post(
                    url,
                    headers=headers,
                    json=t8_payload,
                    timeout=timeout
                )
                _log_info(f"âœ… SSLå…¼å®¹sessionæˆåŠŸ")

            except Exception as ssl_error:
                last_error = ssl_error
                _log_warning(f"SSLå…¼å®¹sessionå¤±è´¥: {ssl_error}")

                # æ–¹æ³•3ï¼šä½¿ç”¨curlä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                try:
                    import subprocess
                    import tempfile

                    # å°†payloadå†™å…¥ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                        json.dump(t8_payload, f)
                        temp_file = f.name

                    # æ„å»ºcurlå‘½ä»¤
                    curl_cmd = [
                        'curl', '-k', '-X', 'POST',
                        '-H', 'Content-Type: application/json',
                        '-H', f'Authorization: Bearer {headers["Authorization"].split(" ")[1]}',
                        '-d', f'@{temp_file}',
                        '--connect-timeout', '30',
                        '--max-time', str(timeout),
                        url
                    ]

                    result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=timeout)

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(temp_file)

                    if result.returncode == 0:
                        # åˆ›å»ºæ¨¡æ‹Ÿresponseå¯¹è±¡
                        class MockResponse:
                            def __init__(self, text, status_code=200):
                                self.text = text
                                self.status_code = status_code
                            def json(self):
                                return json.loads(self.text)

                        response = MockResponse(result.stdout)
                        _log_info(f"âœ… curlå¤‡ç”¨æ–¹æ¡ˆæˆåŠŸ")
                    else:
                        raise Exception(f"curlå¤±è´¥: {result.stderr}")

                except Exception as curl_error:
                    _log_warning(f"curlå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {curl_error}")
                    raise last_error  # æŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯

        _log_info(f"ğŸ” T8 APIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ T8 APIé”™è¯¯: {response.status_code} - {response.text}")

        return response

    except Exception as e:
        _log_error(f"OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥: {e}")
        return None


    """Doubao-Seedanceå¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆèŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())

        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "ä¸€ä¸ªç¾ä¸½çš„åœºæ™¯ï¼ŒåŒ…å«[å›¾1]å’Œ[å›¾2]çš„å…ƒç´ "}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedance-1-0-lite-i2v-250428"], {"default": "doubao-seedance-1-0-lite-i2v-250428"}),
                "duration": (["3s", "5s", "10s", "12s"], {"default": "5s"}),
                "resolution": (["480p", "720p"], {"default": "720p"}),
                "aspect_ratio": (["16:9", "4:3", "1:1", "3:4", "9:16", "21:9", "adaptive"], {"default": "16:9"}),
                "fps": ([24, 30], {"default": 30}),
                "watermark": ("BOOLEAN", {"default": False}),
                "camera_fixed": ("BOOLEAN", {"default": False}),
                "api_key": ("STRING", {"default": ""}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            },
            "optional": {
                "reference_image_1": ("IMAGE",),
                "reference_image_2": ("IMAGE",),
                "reference_image_3": ("IMAGE",),
                "reference_image_4": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "STRING", "STRING", "VIDEO")
    RETURN_NAMES = ("video", "video_url", "response_text", "video_info", "AFVIDEO")
    FUNCTION = "generate_multi_ref_video"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 900  # 15åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
        self.max_retries = 3

    def generate_multi_ref_video(self, prompt, mirror_site, model, duration, resolution, aspect_ratio, fps, watermark=False, camera_fixed=False, api_key="", seed=-1,
                                reference_image_1=None, reference_image_2=None, reference_image_3=None, reference_image_4=None):
        """ç”Ÿæˆå¤šå›¾å‚è€ƒè§†é¢‘"""

        # æ”¶é›†å‚è€ƒå›¾ç‰‡
        reference_images = []
        if reference_image_1 is not None:
            reference_images.append(reference_image_1)
        if reference_image_2 is not None:
            reference_images.append(reference_image_2)
        if reference_image_3 is not None:
            reference_images.append(reference_image_3)
        if reference_image_4 is not None:
            reference_images.append(reference_image_4)

        if not reference_images:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        if len(reference_images) > 4:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœ€å¤šæ”¯æŒ4å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆ: å‚è€ƒå›¾ç‰‡æ•°é‡={len(reference_images)}")

        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")

        # å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™çš„APIæ ¼å¼ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
        if mirror_site == "t8_mirror" or "t8star.cn" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")

        if not api_key.strip():
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªæä¾›API Key", "", blank_video_path)

        try:
            # å¤šå›¾å‚è€ƒæ”¯æŒç«å±±å¼•æ“æ ¼å¼å’ŒComflyå®˜æ–¹æ ¼å¼
            if api_format not in ["volcengine", "comfly"]:
                _log_warning(f"âš ï¸ å¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å’ŒComflyæ ¼å¼ï¼Œå½“å‰æ ¼å¼: {api_format}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šå¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å®˜æ–¹ã€T8é•œåƒç«™å’ŒComflyé•œåƒç«™", "", blank_video_path)

            # æ„å»ºç»Ÿä¸€çš„contentæ•°ç»„æ ¼å¼ï¼ˆç«å±±å¼•æ“å’ŒComflyå®˜æ–¹æ ¼å¼ç›¸åŒï¼‰
            _log_info(f"ğŸ”§ æ„å»ºå¤šå›¾å‚è€ƒ{api_format}æ ¼å¼payload")

            # æ„å»ºæ–‡æœ¬å†…å®¹
            if api_format == "volcengine":
                # ç«å±±å¼•æ“æ ¼å¼ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
                text_content = f"{prompt} --rt {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")
            else:  # api_format == "comfly"
                # Comflyå®˜æ–¹æ ¼å¼ï¼šä¹Ÿä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¸ç«å±±å¼•æ“ç›¸åŒï¼‰
                text_content = f"{prompt} --ratio {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ Comflyå®˜æ–¹å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")

            content = [
                {
                    "type": "text",
                    "text": text_content
                }
            ]

            # æ·»åŠ å‚è€ƒå›¾ç‰‡åˆ°contentæ•°ç»„
            for i, ref_image in enumerate(reference_images, 1):
                _log_info(f"ğŸ” å¤„ç†å‚è€ƒå›¾ç‰‡ {i}: {ref_image.shape}")

                # ç»Ÿä¸€ä½¿ç”¨å®Œæ•´çš„Data URLæ ¼å¼
                image_data_url = image_to_base64(ref_image, return_data_url=True)
                if image_data_url:
                    image_content = {
                        "type": "image_url",
                        "image_url": {
                            "url": image_data_url
                        }
                    }

                    # å¤šå›¾å‚è€ƒç»Ÿä¸€ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ï¼Œéƒ½éœ€è¦roleå­—æ®µ
                    image_content["role"] = "reference_image"

                    content.append(image_content)
                    _log_info(f"ğŸ”§ æ·»åŠ å‚è€ƒå›¾ç‰‡{i}åˆ°content (Data URLé•¿åº¦: {len(image_data_url)})")
                else:
                    _log_error(f"âŒ å‚è€ƒå›¾ç‰‡{i} Data URLç¼–ç å¤±è´¥")

            # æ„å»ºpayload
            payload = {
                "model": model,
                "content": content
            }

            _log_info(f"ğŸ” å¤šå›¾å‚è€ƒpayloadæ„å»ºå®Œæˆ: æ ¼å¼={api_format}, æ¨¡å‹={model}, contentæ•°é‡={len(content)}")

            # è°ƒç”¨å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPIï¼ˆä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹ï¼‰
            response = call_multi_ref_video_api(api_url, api_key, payload, api_format, self.timeout)

            if not response or response.status_code != 200:
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šè§†é¢‘ç”Ÿæˆä»»åŠ¡åˆ›å»ºå¤±è´¥", "", blank_video_path)

            # ä»å“åº”ä¸­æå–ä»»åŠ¡ID
            try:
                result = response.json()
                task_id = None

                # ç«å±±å¼•æ“æ ¼å¼çš„ä»»åŠ¡IDæå–
                if "id" in result:
                    task_id = result["id"]
                elif "task_id" in result:
                    task_id = result["task_id"]
                elif "data" in result and isinstance(result["data"], dict):
                    if "id" in result["data"]:
                        task_id = result["data"]["id"]
                    elif "task_id" in result["data"]:
                        task_id = result["data"]["task_id"]

                if not task_id:
                    _log_error(f"âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»åŠ¡ID: {result}")
                    blank_video = create_blank_video_object()
                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                    return (blank_video, "", "âŒ é”™è¯¯ï¼šæ— æ³•è·å–ä»»åŠ¡ID", "", blank_video_path)

                _log_info(f"ğŸ¬ å¤šå›¾å‚è€ƒè§†é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")

            except Exception as e:
                _log_error(f"âŒ è§£æä»»åŠ¡åˆ›å»ºå“åº”å¤±è´¥: {e}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", f"âŒ é”™è¯¯ï¼šè§£æå“åº”å¤±è´¥: {str(e)}", "", blank_video_path)

            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            max_polls = 90  # 15åˆ†é’Ÿï¼Œæ¯10ç§’è½®è¯¢ä¸€æ¬¡
            poll_interval = 10

            for poll_count in range(1, max_polls + 1):
                _log_info(f"ğŸ” è½®è¯¢ä»»åŠ¡çŠ¶æ€ ({poll_count}/{max_polls})")

                status_response = call_video_task_status(api_url, api_key, task_id, api_format)
                status_result = None
                if status_response and status_response.status_code == 200:
                    status_result = status_response.json()
                    _log_info(f"ğŸ” ä»»åŠ¡çŠ¶æ€å“åº”: {str(status_result)[:200]}...")

                if status_result:
                    status = status_result.get('status', 'unknown')
                    _log_info(f"ğŸ” å½“å‰ä»»åŠ¡çŠ¶æ€: '{status}' (ç±»å‹: {type(status)})")

                    if status.lower() in ["completed", "success", "finished", "succeeded"] or status in ["SUCCESS", "COMPLETED", "FINISHED", "SUCCEEDED"]:
                        _log_info(f"âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ")

                        # è·å–è§†é¢‘URL - æ”¯æŒå¤šç§å“åº”æ ¼å¼
                        video_url = None

                        # æ ¼å¼1: data.content.video_url (Comflyå¤šå›¾å‚è€ƒæ ¼å¼)
                        if 'data' in status_result and isinstance(status_result['data'], dict):
                            if 'content' in status_result['data'] and isinstance(status_result['data']['content'], dict):
                                if 'video_url' in status_result['data']['content']:
                                    video_url = status_result['data']['content']['video_url']

                        # æ ¼å¼2: content.video_url (ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ ¼å¼)
                        if not video_url and 'content' in status_result and isinstance(status_result['content'], dict):
                            if 'video_url' in status_result['content']:
                                video_url = status_result['content']['video_url']

                        # æ ¼å¼3: video_resultæ•°ç»„æ ¼å¼
                        if not video_url and 'video_result' in status_result and status_result['video_result']:
                            video_result = status_result['video_result'][0] if isinstance(status_result['video_result'], list) else status_result['video_result']
                            video_url = video_result.get('url')

                        # æ ¼å¼4: ç›´æ¥video_urlå­—æ®µ
                        if not video_url and 'video_url' in status_result:
                            video_url = status_result['video_url']

                        # æ ¼å¼4: result.video_urlæ ¼å¼
                        if not video_url and 'result' in status_result and status_result['result']:
                            result = status_result['result']
                            if isinstance(result, dict) and 'video_url' in result:
                                video_url = result['video_url']
                                _log_info(f"ğŸ” ä»result.video_urlæå–è§†é¢‘URL")

                        if video_url:
                            _log_info(f"ğŸ¬ è·å–åˆ°è§†é¢‘URL: {video_url}")

                            # ä¸‹è½½å¹¶è½¬æ¢è§†é¢‘
                            video_path = download_video_from_url(video_url)
                            if video_path:
                                _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢è§†é¢‘ä¸ºComfyUIå¯¹è±¡...")
                                video_obj = video_to_comfyui_video(video_path)
                                if video_obj is not None:
                                    video_info = f"æ¨¡å‹: {model}, å‚è€ƒå›¾ç‰‡: {len(reference_images)}å¼ , æ—¶é•¿: {duration}, åˆ†è¾¨ç‡: {resolution}, å®½é«˜æ¯”: {aspect_ratio}, å¸§ç‡: {fps}fps, ä»»åŠ¡ID: {task_id}"
                                    return (video_obj, video_url, "âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ", video_info, video_path)
                                else:
                                    _log_error("âŒ è§†é¢‘è½¬æ¢å¤±è´¥")
                                    blank_video = create_blank_video_object()
                                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                    return (blank_video, video_url, "âŒ è§†é¢‘è½¬æ¢å¤±è´¥", "", blank_video_path)
                            else:
                                _log_error("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                                blank_video = create_blank_video_object()
                                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                return (blank_video, video_url, "âŒ è§†é¢‘ä¸‹è½½å¤±è´¥", "", blank_video_path)
                        else:
                            _log_error("âŒ æœªè·å–åˆ°è§†é¢‘URL")
                            blank_video = create_blank_video_object()
                            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                            return (blank_video, "", "âŒ æœªè·å–åˆ°è§†é¢‘URL", "", blank_video_path)

                    elif status.lower() in ["failed", "error"] or status in ["FAILED", "ERROR"]:
                        fail_reason = status_result.get('fail_reason', 'æœªçŸ¥é”™è¯¯')
                        _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}")
                        blank_video = create_blank_video_object()
                        blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                        return (blank_video, "", f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}", "", blank_video_path)

                    elif status.lower() in ["running", "processing", "in_progress", "not_start", "queued"] or status in ["RUNNING", "PROCESSING", "IN_PROGRESS", "NOT_START", "QUEUED"]:
                        _log_info(f"â³ ä»»åŠ¡è¿›è¡Œä¸­ï¼ŒçŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                    else:
                        _log_warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                else:
                    _log_warning(f"âš ï¸ æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€ï¼Œå“åº”: {status_response}")
                    if poll_count < max_polls:
                        time.sleep(poll_interval)
                    continue

            # è¶…æ—¶å¤„ç†
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆè¶…æ—¶")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ è§†é¢‘ç”Ÿæˆè¶…æ—¶", "", blank_video_path)

        except Exception as e:
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", f"âŒ é”™è¯¯ï¼š{str(e)}", "", blank_video_path)

class VideoStitchingNode:
    """è§†é¢‘æ‹¼æ¥èŠ‚ç‚¹ - æœ€å¤šå¯ä»¥å°†8ä¸ªè§†é¢‘æ‹¼æ¥åœ¨ä¸€èµ·"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video1": ("VIDEO",),
            },
            "optional": {
                "video2": ("VIDEO",),
                "video3": ("VIDEO",),
                "video4": ("VIDEO",),
                "video5": ("VIDEO",),
                "video6": ("VIDEO",),
                "video7": ("VIDEO",),
                "video8": ("VIDEO",),
                "output_filename": ("STRING", {"default": ""}),
                "stitch_method": (["concat", "concat_crossfade", "concat_advanced", "concat_morph", "concat_optical_flow", "hstack", "vstack", "grid2x2", "grid2x3", "grid2x4"], {"default": "concat"}),
                "output_quality": (["high", "medium", "low"], {"default": "high"}),
                "scale_videos": ("BOOLEAN", {"default": True}),
                "smooth_transitions": ("BOOLEAN", {"default": True}),
                "transition_duration": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.1}),
                "force_keyframes": ("BOOLEAN", {"default": True}),
                "transition_type": (["fade", "wipeleft", "wiperight", "wipeup", "wipedown", "slideleft", "slideright", "slideup", "slidedown", "smoothleft", "smoothright", "smoothup", "smoothdown", "circleopen", "circleclose", "vertopen", "vertclose", "horzopen", "horzclose", "dissolve", "pixelize", "radial", "smoothradial"], {"default": "fade"}),
                "motion_compensation": ("BOOLEAN", {"default": False}),
                "edge_enhancement": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "VIDEO")
    RETURN_NAMES = ("stitched_video", "video_path", "AFVIDEO")
    FUNCTION = "stitch_videos"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘å¤„ç†éœ€è¦æ›´é•¿æ—¶é—´

    def stitch_videos(self, video1, video2=None, video3=None, video4=None, video5=None, video6=None, video7=None, video8=None,
                     output_filename="", stitch_method="concat", output_quality="high", scale_videos=True,
                     smooth_transitions=True, transition_duration=0.5, force_keyframes=True, transition_type="fade",
                     motion_compensation=False, edge_enhancement=False):
        """
        æ‹¼æ¥å¤šä¸ªè§†é¢‘

        Args:
            video1-video8: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            stitch_method: æ‹¼æ¥æ–¹æ³•
            output_quality: è¾“å‡ºè´¨é‡
            scale_videos: æ˜¯å¦ç¼©æ”¾è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸

        Returns:
            tuple: (æ‹¼æ¥åçš„VIDEOå¯¹è±¡, è§†é¢‘æ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹è§†é¢‘æ‹¼æ¥...")

            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„è§†é¢‘
            videos = [video1]
            for video in [video2, video3, video4, video5, video6, video7, video8]:
                if video is not None:
                    videos.append(video)

            if len(videos) < 2:
                error_msg = "è‡³å°‘éœ€è¦2ä¸ªè§†é¢‘æ‰èƒ½è¿›è¡Œæ‹¼æ¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            _log_info(f"ğŸ“Š å°†æ‹¼æ¥{len(videos)}ä¸ªè§†é¢‘ï¼Œä½¿ç”¨{stitch_method}æ–¹æ³•")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„
            video_paths = []
            for i, video in enumerate(videos):
                _log_info(f"ğŸ” å¤„ç†ç¬¬{i+1}ä¸ªè§†é¢‘...")
                video_path = self._extract_video_path(video)
                if not video_path:
                    error_msg = f"æ— æ³•è·å–ç¬¬{i+1}ä¸ªè§†é¢‘çš„æœ‰æ•ˆè·¯å¾„: {video_path}"
                    _log_error(error_msg)
                    _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                    return self._create_error_result(error_msg)

                if not os.path.exists(video_path):
                    error_msg = f"ç¬¬{i+1}ä¸ªè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                    _log_error(error_msg)
                    return self._create_error_result(error_msg)

                video_paths.append(video_path)
                _log_info(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                output_filename = f"stitched_video_{stitch_method}_{int(time.time())}.mp4"

            if not output_filename.lower().endswith('.mp4'):
                output_filename += '.mp4'

            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•è€Œä¸æ˜¯ç³»ç»Ÿä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
                _log_info(f"ğŸ“ ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
            except ImportError:
                # å¦‚æœåœ¨ComfyUIç¯å¢ƒå¤–ï¼Œå°è¯•æ¨æ–­ComfyUIè·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None

                # å‘ä¸ŠæŸ¥æ‰¾ComfyUIæ ¹ç›®å½•
                path_parts = current_dir.split(os.sep)
                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")) and \
                       os.path.exists(os.path.join(potential_root, "nodes.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                    _log_info(f"ğŸ“ æ¨æ–­ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
                    _log_info(f"ğŸ“ å›é€€åˆ°ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir}")
            except Exception as e:
                import tempfile
                output_dir = tempfile.gettempdir()
                _log_info(f"ğŸ“ å¼‚å¸¸ï¼Œä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir} (é”™è¯¯: {e})")

            output_path = os.path.join(output_dir, output_filename)

            # æ ¹æ®æ‹¼æ¥æ–¹æ³•æ‰§è¡Œä¸åŒçš„å¤„ç†
            success = False
            if stitch_method == "concat":
                success = self._concat_videos(video_paths, output_path, output_quality, smooth_transitions, transition_duration, force_keyframes)
            elif stitch_method == "concat_crossfade":
                if len(video_paths) <= 2:
                    success = self._concat_with_crossfade_transitions(video_paths, output_path, output_quality, transition_duration)
                else:
                    success = self._concat_with_xfade_multiple(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "concat_advanced":
                success = self._concat_with_advanced_transitions(video_paths, output_path, output_quality, transition_duration, transition_type, motion_compensation, edge_enhancement)
            elif stitch_method == "concat_morph":
                success = self._concat_with_morphing_transitions(video_paths, output_path, output_quality, transition_duration, motion_compensation)
            elif stitch_method == "concat_optical_flow":
                success = self._concat_with_optical_flow_transitions(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "hstack":
                success = self._hstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "vstack":
                success = self._vstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "grid2x2":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x2", scale_videos)
            elif stitch_method == "grid2x3":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x3", scale_videos)
            elif stitch_method == "grid2x4":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x4", scale_videos)

            if not success:
                error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥ï¼Œæ–¹æ³•: {stitch_method}"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            # è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡
            stitched_video = video_to_comfyui_video(output_path)
            if stitched_video:
                stitched_video.file_path = output_path
                _log_info(f"âœ… è§†é¢‘æ‹¼æ¥æˆåŠŸ: {output_path}")

                # AFVIDEOä½¿ç”¨è·¯å¾„åŒ…è£…å™¨ï¼Œä¸æ ‡å‡†è§†é¢‘èŠ‚ç‚¹ä¿æŒä¸€è‡´
                afvideo = create_video_path_wrapper(output_path) if output_path else create_blank_video_object()

                return (stitched_video, output_path, afvideo)
            else:
                error_msg = "æ‹¼æ¥è§†é¢‘è½¬æ¢ä¸ºComfyUIå¯¹è±¡å¤±è´¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

        except Exception as e:
            error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            return self._create_error_result(error_msg)

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _get_quality_params(self, quality):
        """è·å–è´¨é‡å‚æ•°"""
        quality_settings = {
            "high": ["-crf", "18", "-preset", "medium"],
            "medium": ["-crf", "23", "-preset", "fast"],
            "low": ["-crf", "28", "-preset", "faster"]
        }
        return quality_settings.get(quality, quality_settings["high"])

    def _concat_videos(self, video_paths, output_path, quality, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """è¿ç»­æ‹¼æ¥è§†é¢‘ï¼ˆæ—¶é—´è½´ä¸Šè¿æ¥ï¼‰- æ”¹è¿›ç‰ˆæœ¬å‡å°‘é—ªçƒ"""
        try:
            import subprocess
            import tempfile

            _log_info("ğŸ”— ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            # é¦–å…ˆæ£€æŸ¥è§†é¢‘å±æ€§ä¸€è‡´æ€§
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§")
                return False

            # åˆ›å»ºconcatæ–‡ä»¶åˆ—è¡¨ - ä½¿ç”¨åˆé€‚çš„ä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                temp_dir = folder_paths.get_temp_directory()
            except:
                import tempfile
                temp_dir = tempfile.gettempdir()
            concat_file = os.path.join(temp_dir, f"concat_list_{int(time.time())}.txt")

            with open(concat_file, 'w', encoding='utf-8') as f:
                for video_path in video_paths:
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                    abs_path = os.path.abspath(video_path).replace('\\', '/')
                    f.write(f"file '{abs_path}'\n")

            # æ ¹æ®è§†é¢‘å±æ€§ä¸€è‡´æ€§é€‰æ‹©å¤„ç†æ–¹å¼
            if video_info['consistent']:
                # å±æ€§ä¸€è‡´ï¼Œå°è¯•ç›´æ¥å¤åˆ¶æµï¼ˆæœ€å¿«ï¼Œæ— è´¨é‡æŸå¤±ï¼‰
                success = self._concat_with_copy(concat_file, output_path)
                if success:
                    self._cleanup_temp_file(concat_file)
                    return True
                _log_info("ğŸ”„ ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œå°è¯•é‡æ–°ç¼–ç ...")

            # å±æ€§ä¸ä¸€è‡´æˆ–ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›çš„é‡æ–°ç¼–ç æ–¹æ³•
            success = self._concat_with_smooth_transitions(concat_file, output_path, quality, video_info, smooth_transitions, transition_duration, force_keyframes)

            self._cleanup_temp_file(concat_file)
            return success

        except Exception as e:
            _log_error(f"concatæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _analyze_video_properties(self, video_paths):
        """åˆ†æè§†é¢‘å±æ€§ï¼Œæ£€æŸ¥ä¸€è‡´æ€§"""
        try:
            import subprocess
            import json

            _log_info("ğŸ” åˆ†æè§†é¢‘å±æ€§...")

            video_props = []
            for video_path in video_paths:
                # ä½¿ç”¨ffprobeè·å–è§†é¢‘ä¿¡æ¯
                cmd = [
                    'ffprobe',
                    '-v', 'quiet',
                    '-print_format', 'json',
                    '-show_streams',
                    '-select_streams', 'v:0',
                    video_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                if result.returncode != 0:
                    _log_error(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_path}")
                    return None

                try:
                    info = json.loads(result.stdout)
                    if 'streams' in info and len(info['streams']) > 0:
                        stream = info['streams'][0]
                        props = {
                            'width': stream.get('width', 0),
                            'height': stream.get('height', 0),
                            'fps': eval(stream.get('r_frame_rate', '0/1')),
                            'codec': stream.get('codec_name', ''),
                            'pix_fmt': stream.get('pix_fmt', '')
                        }
                        video_props.append(props)
                        _log_info(f"ğŸ“Š {os.path.basename(video_path)}: {props['width']}x{props['height']} @{props['fps']:.2f}fps {props['codec']}")
                    else:
                        _log_error(f"æ— æ³•è§£æè§†é¢‘æµä¿¡æ¯: {video_path}")
                        return None
                except json.JSONDecodeError:
                    _log_error(f"æ— æ³•è§£æffprobeè¾“å‡º: {video_path}")
                    return None

            # æ£€æŸ¥å±æ€§ä¸€è‡´æ€§
            if not video_props:
                return None

            first_props = video_props[0]
            consistent = all(
                props['width'] == first_props['width'] and
                props['height'] == first_props['height'] and
                abs(props['fps'] - first_props['fps']) < 0.1 and
                props['codec'] == first_props['codec'] and
                props['pix_fmt'] == first_props['pix_fmt']
                for props in video_props
            )

            _log_info(f"âœ… è§†é¢‘å±æ€§ä¸€è‡´æ€§: {'æ˜¯' if consistent else 'å¦'}")

            return {
                'consistent': consistent,
                'properties': video_props,
                'target_width': first_props['width'],
                'target_height': first_props['height'],
                'target_fps': first_props['fps'],
                'target_codec': first_props['codec'],
                'target_pix_fmt': first_props['pix_fmt']
            }

        except Exception as e:
            _log_error(f"åˆ†æè§†é¢‘å±æ€§å¤±è´¥: {str(e)}")
            return None

    def _concat_with_copy(self, concat_file, output_path):
        """ä½¿ç”¨æµå¤åˆ¶æ–¹å¼æ‹¼æ¥ï¼ˆæœ€å¿«ï¼Œé€‚ç”¨äºå±æ€§ä¸€è‡´çš„è§†é¢‘ï¼‰"""
        try:
            import subprocess

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµ
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œæµå¤åˆ¶å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… æµå¤åˆ¶æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_info(f"âš ï¸ æµå¤åˆ¶å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"æµå¤åˆ¶æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_smooth_transitions(self, concat_file, output_path, quality, video_info, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """ä½¿ç”¨å¹³æ»‘è¿‡æ¸¡çš„é‡æ–°ç¼–ç æ–¹å¼æ‹¼æ¥"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            # æ„å»ºæ”¹è¿›çš„FFmpegå‘½ä»¤ï¼Œå‡å°‘é—ªçƒ
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',  # å¼ºåˆ¶ä½¿ç”¨H.264ç¼–ç å™¨
                '-pix_fmt', 'yuv420p',  # ç»Ÿä¸€åƒç´ æ ¼å¼
                '-r', str(int(video_info['target_fps'])),  # ç»Ÿä¸€å¸§ç‡
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",  # ç»Ÿä¸€åˆ†è¾¨ç‡
                '-vsync', 'cfr',  # æ’å®šå¸§ç‡
                '-bf', '2',  # Bå¸§æ•°é‡
                '-sc_threshold', '0',  # ç¦ç”¨åœºæ™¯åˆ‡æ¢æ£€æµ‹
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-fflags', '+genpts',  # ç”ŸæˆPTS
            ]

            # æ ¹æ®å‚æ•°æ·»åŠ å…³é”®å¸§æ§åˆ¶
            if force_keyframes:
                keyframe_interval = max(1, int(video_info['target_fps'] * 2))  # æ¯2ç§’ä¸€ä¸ªå…³é”®å¸§
                cmd.extend([
                    '-force_key_frames', f'expr:gte(t,n_forced*2)',
                    '-g', str(keyframe_interval),
                ])

            # æ·»åŠ å¹³æ»‘è¿‡æ¸¡æ»¤é•œï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if smooth_transitions and transition_duration > 0:
                # ä½¿ç”¨minterpolateæ»¤é•œè¿›è¡Œå¸§æ’å€¼ï¼Œå‡å°‘è·³è·ƒæ„Ÿ
                cmd.extend([
                    '-vf', f'minterpolate=fps={video_info["target_fps"]}:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1'
                ])

            cmd.extend(quality_params + ['-y', output_path])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¹³æ»‘è¿‡æ¸¡ç¼–ç : {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å¦‚æœé«˜çº§æ»¤é•œå¤±è´¥ï¼Œå°è¯•åŸºç¡€æ–¹æ³•
                if smooth_transitions:
                    _log_info("ğŸ”„ å°è¯•åŸºç¡€å¹³æ»‘æ–¹æ³•...")
                    return self._concat_with_basic_smooth(concat_file, output_path, quality, video_info)
                return False

        except Exception as e:
            _log_error(f"å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_basic_smooth(self, concat_file, output_path, quality, video_info):
        """åŸºç¡€å¹³æ»‘æ‹¼æ¥æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",
                '-vsync', 'cfr',
                '-bf', '2',
                '-g', str(int(video_info['target_fps'] * 2)),
                '-sc_threshold', '0',
                '-avoid_negative_ts', 'make_zero',
                '-fflags', '+genpts',
            ] + quality_params + [
                '-y',
                output_path
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"åŸºç¡€å¹³æ»‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _cleanup_temp_file(self, temp_file):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        except Exception as e:
            _log_error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

    def _concat_with_crossfade_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, False, 0, True)

            _log_info(f"ğŸ¬ ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # å¯¹äºäº¤å‰æ·¡åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼š
            # 1. å…ˆç”¨concatæ­£å¸¸æ‹¼æ¥
            # 2. ç„¶ååœ¨æ‹¼æ¥ç‚¹æ·»åŠ æ·¡åŒ–æ•ˆæœ

            # é¦–å…ˆè·å–è§†é¢‘ä¿¡æ¯ä»¥è®¡ç®—æ€»æ—¶é•¿
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # è®¡ç®—æ¯ä¸ªè§†é¢‘çš„æ—¶é•¿å’Œç´¯ç§¯æ—¶é•¿
            video_durations = []
            cumulative_time = 0

            for video_path in video_paths:
                try:
                    cmd_duration = [
                        'ffprobe',
                        '-v', 'quiet',
                        '-show_entries', 'format=duration',
                        '-of', 'csv=p=0',
                        video_path
                    ]
                    result = subprocess.run(cmd_duration, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        video_durations.append(duration)
                        cumulative_time += duration
                    else:
                        video_durations.append(2.0)  # é»˜è®¤2ç§’
                        cumulative_time += 2.0
                except:
                    video_durations.append(2.0)
                    cumulative_time += 2.0

            _log_info(f"ğŸ“Š è§†é¢‘æ—¶é•¿: {[f'{d:.1f}s' for d in video_durations]}, æ€»æ—¶é•¿: {cumulative_time:.1f}s")

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºç®€åŒ–çš„äº¤å‰æ·¡åŒ–æ»¤é•œ
            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•äº¤å‰æ·¡åŒ–
                filter_complex = self._build_simple_crossfade_filter(video_durations, transition_duration)
            else:
                # å¤šä¸ªè§†é¢‘ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•
                _log_info("ğŸ”„ å¤šè§†é¢‘äº¤å‰æ·¡åŒ–ï¼Œä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œäº¤å‰æ·¡åŒ–å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… äº¤å‰æ·¡åŒ–æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å›é€€åˆ°æ™®é€šæ‹¼æ¥
                _log_info("ğŸ”„ å›é€€åˆ°æ™®é€šæ‹¼æ¥æ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

        except Exception as e:
            _log_error(f"äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°æ™®é€šæ‹¼æ¥
            return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

    def _build_simple_crossfade_filter(self, video_durations, transition_duration):
        """æ„å»ºç®€å•çš„ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–æ»¤é•œ"""
        if len(video_durations) != 2:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        duration1, duration2 = video_durations

        # ç¡®ä¿è¿‡æ¸¡æ—¶é—´ä¸è¶…è¿‡è¾ƒçŸ­è§†é¢‘çš„ä¸€åŠ
        max_transition = min(duration1, duration2) / 2
        actual_transition = min(transition_duration, max_transition)

        if actual_transition <= 0:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        # ä½¿ç”¨xfadeæ»¤é•œè¿›è¡Œäº¤å‰æ·¡åŒ–ï¼ˆæ›´ä¸“ä¸šçš„æ–¹æ³•ï¼‰
        # xfadeæ»¤é•œä¼šè‡ªåŠ¨å¤„ç†æ—¶é—´å¯¹é½
        offset_time = duration1 - actual_transition

        filter_complex = f"[0:v][1:v]xfade=transition=fade:duration={actual_transition}:offset={offset_time}[output]"

        return filter_complex

    def _concat_with_xfade_multiple(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥å¤šä¸ªè§†é¢‘ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        try:
            import subprocess
            import tempfile

            _log_info(f"ğŸ¬ ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨xfade
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

            # å¤šä¸ªè§†é¢‘éœ€è¦é€’å½’å¤„ç†
            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"intermediate_{i}.mp4")

                    # ä½¿ç”¨ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–
                    success = self._concat_with_crossfade_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘xfadeæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_advanced_transitions(self, video_paths, output_path, quality, transition_duration=0.5, transition_type="fade", motion_compensation=False, edge_enhancement=False):
        """ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ¨ ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘ï¼Œè¿‡æ¸¡ç±»å‹: {transition_type}")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ
            if len(video_paths) == 2:
                filter_complex = self._build_advanced_transition_filter(video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨é€’å½’å¤„ç†
                return self._concat_advanced_multiple(video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œé«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout * 2  # é«˜çº§å¤„ç†éœ€è¦æ›´å¤šæ—¶é—´
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                # å›é€€åˆ°äº¤å‰æ·¡åŒ–
                _log_info("ğŸ”„ å›é€€åˆ°äº¤å‰æ·¡åŒ–æ–¹æ³•...")
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

        except Exception as e:
            _log_error(f"é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°äº¤å‰æ·¡åŒ–
            return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

    def _build_advanced_transition_filter(self, video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # é¢„å¤„ç†æ»¤é•œ
            preprocess_filters = []

            # è¾¹ç¼˜å¢å¼º
            if edge_enhancement:
                preprocess_filters.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                input_labels = ["[v0enhanced]", "[v1enhanced]"]
            else:
                input_labels = ["[0:v]", "[1:v]"]

            # è¿åŠ¨è¡¥å¿ï¼ˆä½¿ç”¨minterpolateè¿›è¡Œå¸§æ’å€¼ï¼‰
            if motion_compensation:
                preprocess_filters.extend([
                    f"{input_labels[0]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    f"{input_labels[1]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                input_labels = ["[v0smooth]", "[v1smooth]"]

            # æ„å»ºxfadeè¿‡æ¸¡
            xfade_filter = f"{input_labels[0]}{input_labels[1]}xfade=transition={transition_type}:duration={actual_transition}:offset={offset_time}[output]"

            # ç»„åˆæ‰€æœ‰æ»¤é•œ
            if preprocess_filters:
                filter_complex = ";".join(preprocess_filters) + ";" + xfade_filter
            else:
                filter_complex = xfade_filter

            return filter_complex

        except Exception as e:
            _log_error(f"æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            return f"[0:v][1:v]xfade=transition=fade:duration={transition_duration}:offset={max(0, durations[0] - transition_duration)}[output]"

    def _concat_advanced_multiple(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—é—®é¢˜"""
        try:
            # å¯¹äºå¤šè§†é¢‘ï¼Œä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾è€Œä¸æ˜¯é€’å½’æ‹¼æ¥
            # è¿™æ ·å¯ä»¥é¿å…é‡å¤å‡å»è¿‡æ¸¡æ—¶é—´çš„é—®é¢˜

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨åŸæ–¹æ³•
                return self._concat_with_advanced_transitions(
                    video_paths, output_path, quality, transition_duration,
                    transition_type, motion_compensation, edge_enhancement
                )

            # å¤šäº2ä¸ªè§†é¢‘æ—¶ï¼Œæ„å»ºä¸€æ¬¡æ€§æ»¤é•œé“¾
            return self._concat_advanced_multiple_chain(
                video_paths, output_path, quality, transition_duration,
                transition_type, motion_compensation, edge_enhancement
            )

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_advanced_multiple_chain(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾æ‹¼æ¥å¤šä¸ªè§†é¢‘ - æ­£ç¡®çš„æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾
            filter_complex = self._build_multiple_xfade_chain(video_paths, durations, actual_transition, transition_type)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘é«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_xfade_chain(self, video_paths, durations, transition_duration, transition_type):
        """æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration
                return f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[output]"

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            filter_parts.append(f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[v01]")
            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration
                filter_parts.append(f"[{input_label}][{i}:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _simple_concat_multiple(self, video_paths, output_path):
        """ç®€å•çš„å¤šè§†é¢‘æ‹¼æ¥ï¼ˆæ— è¿‡æ¸¡ï¼‰"""
        try:
            import subprocess
            import tempfile

            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                concat_file = f.name

            try:
                cmd = [
                    'ffmpeg',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', concat_file,
                    '-c', 'copy',
                    '-y',
                    output_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

                if result.returncode == 0 and os.path.exists(output_path):
                    return True
                else:
                    return False

            finally:
                try:
                    os.unlink(concat_file)
                except:
                    pass

        except Exception as e:
            _log_error(f"ç®€å•å¤šè§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_morphing_transitions(self, video_paths, output_path, quality, transition_duration=0.5, motion_compensation=False):
        """ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆå®éªŒæ€§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ§¬ ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "fade", motion_compensation, False)

            # å¯¹äºå½¢æ€å­¦è¿‡æ¸¡ï¼Œæˆ‘ä»¬ä½¿ç”¨blendæ»¤é•œå’Œmorphologicalæ“ä½œ
            if len(video_paths) == 2:
                filter_complex = self._build_morphing_filter(video_paths, transition_duration, motion_compensation)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾ï¼Œé¿å…æ—¶é•¿è®¡ç®—é”™è¯¯
                return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # å¤§å¹…ç¼©çŸ­è¶…æ—¶æ—¶é—´ - å½¢æ€å­¦è¿‡æ¸¡ä¹Ÿåº”è¯¥å¿«é€Ÿå¤„ç†
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except Exception as e:
            _log_error(f"å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

    def _build_morphing_filter(self, video_paths, transition_duration, motion_compensation):
        """æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ - æ›´ç¨³å®šçš„å®ç°
            filter_parts = []

            # è¿åŠ¨è¡¥å¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                # ä½¿ç”¨é«˜è´¨é‡dissolveè¿‡æ¸¡
                filter_parts.append(
                    f"[v0smooth][v1smooth]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )
            else:
                # ä¸ä½¿ç”¨è¿åŠ¨è¡¥å¿æ—¶ï¼Œä½¿ç”¨è¾¹ç¼˜å¢å¼ºçš„dissolve
                filter_parts.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                filter_parts.append(
                    f"[v0enhanced][v1enhanced]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°ç®€å•çš„dissolveè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=dissolve:duration={transition_duration}:offset={offset_time}[output]"

    def _concat_with_optical_flow_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆæœ€é«˜çº§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸŒŠ ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

            # ç°åœ¨FFmpegå‚æ•°å·²ä¿®å¤ï¼Œå¯ä»¥æ”¯æŒå„ç§åˆ†è¾¨ç‡çš„å…‰æµè¿‡æ¸¡
            # ä½†å¯¹äºè¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ï¼Œä»ç„¶å»ºè®®ä½¿ç”¨å¿«é€Ÿæ–¹æ³•ä»¥ä¿è¯ç”¨æˆ·ä½“éªŒ
            if 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (å¦‚1920x1080)ï¼Œæé†’ç”¨æˆ·ä½†ä¸å¼ºåˆ¶è·³è¿‡
                    _log_info(f"âš ï¸ æ£€æµ‹åˆ°è¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ ({video_info['target_width']}x{video_info['target_height']})ï¼Œå…‰æµè¿‡æ¸¡å¯èƒ½è¾ƒæ…¢")
                    _log_info("ğŸ’¡ å¦‚éœ€å¿«é€Ÿå¤„ç†ï¼Œå»ºè®®ä½¿ç”¨concat_advancedæ–¹æ³•")
                    # ä¸å†å¼ºåˆ¶è·³è¿‡ï¼Œè®©ç”¨æˆ·é€‰æ‹©

            # å°è¯•çœŸæ­£çš„å…‰æµè¿‡æ¸¡å¤„ç†
            if len(video_paths) == 2:
                filter_complex = self._build_optical_flow_filter(video_paths, transition_duration)
            else:
                # å¤šè§†é¢‘å…‰æµè¿‡æ¸¡ï¼šä½¿ç”¨é“¾å¼å…‰æµå¤„ç†
                _log_info("ğŸŒŠ æ‰§è¡Œå¤šè§†é¢‘å…‰æµè¿‡æ¸¡å¤„ç†...")
                filter_complex = self._build_optical_flow_multiple_filter(video_paths, transition_duration)

                # å¦‚æœå¤šè§†é¢‘å…‰æµæ»¤é•œæ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡
                if filter_complex is None:
                    _log_info("ğŸ”„ å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                    return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "radial", False, False)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå…‰æµè¿‡æ¸¡å‘½ä»¤...")

            # ä¸ºçœŸæ­£çš„å…‰æµè¿‡æ¸¡è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                    timeout_seconds = 600  # 10åˆ†é’Ÿï¼Œè½»é‡çº§å…‰æµ
                elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                    timeout_seconds = 480  # 8åˆ†é’Ÿï¼Œæ ‡å‡†å…‰æµ
                else:
                    timeout_seconds = 300  # 5åˆ†é’Ÿï¼Œé«˜è´¨é‡å…‰æµ
            else:
                timeout_seconds = 300  # é»˜è®¤5åˆ†é’Ÿ

            _log_info(f"â±ï¸ å…‰æµè¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (çœŸæ­£å…‰æµå¤„ç†)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å…‰æµè¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å…‰æµè¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except Exception as e:
            _log_error(f"å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

    def _build_optical_flow_filter(self, video_paths, transition_duration):
        """æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œï¼ˆç®€åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç°åœ¨æä¾›çœŸæ­£çš„å…‰æµè¿‡æ¸¡é€‰é¡¹
            # ç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒçº§åˆ«çš„å…‰æµå¤„ç†

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
            pixels = 1248 * 704  # é»˜è®¤å€¼
            if len(video_paths) >= 2:
                try:
                    # å°è¯•è·å–å®é™…åˆ†è¾¨ç‡
                    cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and 'x' in result.stdout:
                        width, height = map(int, result.stdout.strip().split('x'))
                        pixels = width * height
                except:
                    pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ ä½¿ç”¨è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                # è½»é‡çº§å…‰æµï¼šä»…ä½¿ç”¨åŸºç¡€è¿åŠ¨è¡¥å¿
                filter_parts = [
                    "[0:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v0flow]",
                    "[1:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ ä½¿ç”¨æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆå¹³è¡¡è´¨é‡ä¸é€Ÿåº¦ï¼‰")
                # æ ‡å‡†å…‰æµï¼šä¸­ç­‰å¤æ‚åº¦
                filter_parts = [
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v0flow]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            else:
                _log_info("ğŸŒŠ ä½¿ç”¨é«˜è´¨é‡å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                # é«˜è´¨é‡å…‰æµï¼šå®Œæ•´ç®—æ³•
                filter_parts = [
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v0flow]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]

            return ";".join(filter_parts)

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜è´¨é‡çš„smoothleftè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"

    def _build_optical_flow_multiple_filter(self, video_paths, transition_duration):
        """æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œé“¾"""
        try:
            # è·å–æ‰€æœ‰è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        durations.append(duration)
                    else:
                        _log_error(f"ffprobeå¤±è´¥: {video_path}, è¿”å›ç : {result.returncode}")
                        _log_error(f"stderr: {result.stderr}")
                        durations.append(4.0)
                except Exception as e:
                    _log_error(f"ffprobeå¼‚å¸¸: {video_path}, é”™è¯¯: {str(e)}")
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v]concat=n=1:v=1[output]"

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯ç”¨äºé€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            pixels = 1248 * 704  # é»˜è®¤å€¼
            try:
                cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                if result.returncode == 0 and 'x' in result.stdout:
                    width, height = map(int, result.stdout.strip().split('x'))
                    pixels = width * height
            except:
                pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ å¤šè§†é¢‘è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ å¤šè§†é¢‘å¿«é€Ÿå…‰æµè¿‡æ¸¡ï¼ˆä¼˜åŒ–å¤„ç†é€Ÿåº¦ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"  # é™ä½fpsæé«˜é€Ÿåº¦
            else:
                _log_info("ğŸŒŠ å¤šè§†é¢‘æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1"

            filter_parts = []

            # é¦–å…ˆå¯¹æ‰€æœ‰è¾“å…¥è§†é¢‘åº”ç”¨å…‰æµå¤„ç†
            for i in range(len(video_paths)):
                filter_parts.append(f"[{i}:v]minterpolate={minterpolate_params}[v{i}flow]")

            # ä½¿ç”¨æ­£ç¡®çš„å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ–¹æ³•ï¼šé“¾å¼å¤„ç†ï¼Œä½†éœ€è¦æ­£ç¡®è®¡ç®—æ¯ä¸ªè¿‡æ¸¡çš„æ—¶é•¿
            #
            # å…³é”®ç†è§£ï¼šxfadeçš„offsetæ˜¯ç›¸å¯¹äºç¬¬ä¸€ä¸ªè¾“å…¥çš„æ—¶é•¿ï¼Œè€Œä¸æ˜¯ç»å¯¹æ—¶é—´
            # æ¯ä¸ªxfadeè¾“å‡ºçš„é•¿åº¦ = offset + transition_duration

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡ï¼švideo1 + video2
            offset_time = durations[0] - transition_duration  # 11.5ç§’
            filter_parts.append(f"[v0flow][v1flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[v01]")
            # v01çš„é•¿åº¦ = durations[0] + durations[1] - transition_duration = 23.5ç§’

            # åç»­è¿‡æ¸¡éœ€è¦é‡æ–°æ€è€ƒï¼šæˆ‘ä»¬éœ€è¦å°†v01å’Œåç»­è§†é¢‘æ‹¼æ¥
            # ä½†v01å·²ç»æ˜¯23.5ç§’çš„å®Œæ•´è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å…¶æœ«å°¾æ·»åŠ æ–°è§†é¢‘

            current_video_length = durations[0] + durations[1] - transition_duration  # v01çš„é•¿åº¦

            for i in range(2, len(video_paths)):
                if i == 2:
                    input_label = "v01"
                    output_label = "v02" if i < len(video_paths) - 1 else "output"
                else:
                    input_label = f"v0{i-1}"
                    output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # å¯¹äºåç»­è¿‡æ¸¡ï¼Œoffsetåº”è¯¥æ˜¯å½“å‰è§†é¢‘é•¿åº¦å‡å»è¿‡æ¸¡æ—¶é—´
                offset_time = current_video_length - transition_duration
                filter_parts.append(f"[{input_label}][v{i}flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[{output_label}]")

                # æ›´æ–°å½“å‰è§†é¢‘é•¿åº¦ï¼šåŠ ä¸Šæ–°è§†é¢‘é•¿åº¦ï¼Œå‡å»è¿‡æ¸¡æ—¶é—´
                current_video_length += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•
            _log_info("ğŸ”„ å…‰æµè¿‡æ¸¡å¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return None  # è¿”å›Noneè¡¨ç¤ºéœ€è¦å›é€€

    def _concat_morphing_multiple(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿ç•™æ—§æ–¹æ³•ä½œä¸ºå¤‡ç”¨"""
        _log_info("ğŸ”„ ä½¿ç”¨æ—§çš„é€’å½’å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰")
        return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

    def _concat_morphing_multiple_chain(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾çš„å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾
            filter_complex = self._build_multiple_morphing_chain(video_paths, durations, actual_transition, motion_compensation)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡è°ƒæ•´è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout_seconds)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            return False
        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_morphing_chain(self, video_paths, durations, transition_duration, motion_compensation):
        """æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration

                # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ
                if motion_compensation:
                    # å¸¦è¿åŠ¨è¡¥å¿çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                        "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                        f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]
                else:
                    # ç®€å•çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]edgedetect=low=0.1:high=0.4[v0edge]",
                        "[1:v]edgedetect=low=0.1:high=0.4[v1edge]",
                        f"[v0edge][v1edge]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]

                return ";".join(filter_parts)

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ - ä½¿ç”¨ç®€åŒ–çš„è¿‡æ¸¡æ•ˆæœ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                    f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]"
                ])
            else:
                filter_parts.append(f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]")

            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration

                if motion_compensation and i == 2:  # åªå¯¹ç¬¬äºŒä¸ªè¿‡æ¸¡ä½¿ç”¨è¿åŠ¨è¡¥å¿ï¼Œé¿å…è¿‡äºå¤æ‚
                    filter_parts.extend([
                        f"[{i}:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v{i}smooth]",
                        f"[{input_label}][v{i}smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]"
                    ])
                else:
                    filter_parts.append(f"[{input_label}][{i}:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _concat_optical_flow_multiple(self, video_paths, output_path, quality, transition_duration):
        """å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥"""
        try:
            import tempfile

            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"flow_intermediate_{i}.mp4")

                    success = self._concat_with_optical_flow_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"å…‰æµè¿‡æ¸¡ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _hstack_videos(self, video_paths, output_path, quality, scale_videos):
        """æ°´å¹³æ‹¼æ¥è§†é¢‘ï¼ˆå¹¶æ’æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†”ï¸ ä½¿ç”¨hstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("hstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†æ°´å¹³æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                hstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]hstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + hstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "hstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"hstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _vstack_videos(self, video_paths, output_path, quality, scale_videos):
        """å‚ç›´æ‹¼æ¥è§†é¢‘ï¼ˆä¸Šä¸‹æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†•ï¸ ä½¿ç”¨vstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("vstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†å‚ç›´æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                vstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]vstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + vstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "vstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"vstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _grid_videos(self, video_paths, output_path, quality, grid_type, scale_videos):
        """ç½‘æ ¼æ‹¼æ¥è§†é¢‘ï¼ˆ2x2ã€2x3æˆ–2x4å¸ƒå±€ï¼‰"""
        try:
            import subprocess

            _log_info(f"ğŸ”² ä½¿ç”¨{grid_type}ç½‘æ ¼æ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if grid_type == "2x2":
                max_videos = 4
            elif grid_type == "2x3":
                max_videos = 6
            elif grid_type == "2x4":
                max_videos = 8
            else:
                max_videos = 4

            if len(video_paths) > max_videos:
                _log_error(f"{grid_type}ç½‘æ ¼æœ€å¤šæ”¯æŒ{max_videos}ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # ä¸ºä¸è¶³çš„ä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
            while len(video_paths) < max_videos:
                video_paths.append(None)

            # æ„å»ºç½‘æ ¼æ»¤é•œ
            if scale_videos:
                # ç¼©æ”¾æ‰€æœ‰è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸
                scale_filters = []
                for i in range(len([v for v in video_paths if v is not None])):
                    scale_filters.append(f"[{i}:v]scale=320:240[v{i}]")

                # ä¸ºç©ºä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:320x240:d=1[v{i}]")

                if grid_type == "2x2":
                    # 2x2ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    # 2x3ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[middle];[v4][v5]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    # 2x4ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[row1];[v2][v3]hstack[row2];[v4][v5]hstack[row3];[v6][v7]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                all_filters = scale_filters + black_filters + [grid_filter]
                filter_complex = ";".join(all_filters)
            else:
                # ä¸ç¼©æ”¾ï¼Œç›´æ¥ç½‘æ ¼æ‹¼æ¥ï¼ˆå¯èƒ½ä¼šæœ‰å°ºå¯¸ä¸åŒ¹é…é—®é¢˜ï¼‰
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:640x480:d=1[v{i}]")

                if grid_type == "2x2":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[middle];[4:v][5:v]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    grid_filter = f"[0:v][1:v]hstack[row1];[2:v][3:v]hstack[row2];[4:v][5:v]hstack[row3];[6:v][7:v]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                filter_complex = ";".join(black_filters + [grid_filter])

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"gridæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _create_error_result(self, error_msg):
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        try:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            afvideo = create_video_path_wrapper(blank_video_path) if blank_video_path else create_blank_video_object()
            return (blank_video, f"âŒ {error_msg}", afvideo)
        except:
            return (None, f"âŒ {error_msg}", None)


class GetLastFrameNode:
    """æå–ä»»æ„è§†é¢‘å°¾å¸§çš„ç‹¬ç«‹èŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
            },
            "optional": {
                "output_filename": ("STRING", {"default": ""}),
                "image_quality": (["high", "medium", "low"], {"default": "high"}),
                "offset_from_last": ("INT", {"default": 0, "min": 0, "max": 100000, "step": 1}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("last_frame_image", "frame_path")
    FUNCTION = "extract_last_frame"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 60  # 1åˆ†é’Ÿè¶…æ—¶

    def extract_last_frame(self, video, output_filename="", image_quality="high", offset_from_last=0):
        """
        æå–è§†é¢‘çš„æœ€åä¸€å¸§æˆ–ä»å°¾éƒ¨èµ·ç¬¬Nå¸§ï¼ˆ0è¡¨ç¤ºå°¾å¸§ï¼‰

        Args:
            video: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            image_quality: å›¾åƒè´¨é‡è®¾ç½®
            offset_from_last: ä»å°¾éƒ¨èµ·çš„åç§»å¸§æ•°ï¼ˆ0=å°¾å¸§ï¼Œ1=å€’æ•°ç¬¬2å¸§...ï¼‰

        Returns:
            tuple: (å›¾åƒå¼ é‡, å›¾åƒæ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹æå–è§†é¢‘å°¾å¸§...")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ”¹è¿›çš„æå–æ–¹æ³•
            video_path = self._extract_video_path(video)

            if not video_path:
                error_msg = f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}"
                _log_error(error_msg)
                _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                # è¿”å›ç©ºç™½å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            if not os.path.exists(video_path):
                error_msg = f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"ğŸ“¹ è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                if offset_from_last and offset_from_last > 0:
                    output_filename = f"{video_name}_last_minus_{offset_from_last}.jpg"
                else:
                    output_filename = f"{video_name}_last_frame.jpg"

            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
            if not output_filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                output_filename += '.jpg'

            # ä½¿ç”¨ä¸´æ—¶ç›®å½•
            import tempfile
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{int(time.time())}_{output_filename}")

            # è®¾ç½®å›¾åƒè´¨é‡å‚æ•°
            quality_settings = {
                "high": ["-q:v", "2"],      # é«˜è´¨é‡
                "medium": ["-q:v", "5"],    # ä¸­ç­‰è´¨é‡
                "low": ["-q:v", "8"]        # ä½è´¨é‡
            }
            quality_params = quality_settings.get(image_quality, quality_settings["high"])

            # æå–æŒ‡å®šå¸§ï¼ˆæ”¯æŒä»å°¾éƒ¨åç§»ï¼‰
            frame_path = None
            try:
                # ä¼˜å…ˆå°è¯•ä½¿ç”¨å¸§åºå·æ–¹å¼
                total_frames = self._get_total_frames(video_path)
                if isinstance(total_frames, int) and total_frames > 0:
                    target_index = max(total_frames - 1 - max(0, int(offset_from_last or 0)), 0)
                    frame_path = self._extract_frame_by_index(video_path, output_path, quality_params, target_index)
                else:
                    frame_path = None
            except Exception:
                frame_path = None

            # é€€å›ç­–ç•¥ï¼šå½“ä¸èƒ½ç²¾ç¡®æŒ‰å¸§ç´¢å¼•æ—¶ï¼Œä½¿ç”¨æ—¶é—´ä¼°ç®—æˆ–å°¾å¸§æ–¹å¼
            if not frame_path:
                if offset_from_last and offset_from_last > 0:
                    # ä½¿ç”¨æ—¶é•¿å’Œfpsä¼°ç®—å®šä½
                    duration, fps = self._get_duration_and_fps(video_path)
                    if duration and fps:
                        seek_time = max(0.0, float(duration) - (float(offset_from_last) + 1.0) / float(fps))
                        frame_path = self._extract_frame_by_time(video_path, output_path, quality_params, seek_time)
                # æœ€åå…œåº•ä¸ºå°¾å¸§
                if not frame_path:
                    frame_path = self._extract_frame_with_ffmpeg(video_path, output_path, quality_params)

            if not frame_path:
                error_msg = "å°¾å¸§æå–å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            # å°†å›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼
            image_tensor = self._load_image_as_tensor(frame_path)

            if image_tensor is None:
                error_msg = "å›¾åƒåŠ è½½å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {frame_path}")
            return (image_tensor, frame_path)

        except Exception as e:
            error_msg = f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            blank_image = self._create_blank_image()
            return (blank_image, f"âŒ {error_msg}")

    def _extract_frame_by_index(self, video_path, output_path, quality_params, frame_index):
        """ä½¿ç”¨å¸§ç´¢å¼•æå–æŒ‡å®šå¸§ï¼ˆ0-basedï¼‰"""
        try:
            import subprocess
            # ä½¿ç”¨select=eq(n,frame_index) ç²¾ç¡®é€‰å¸§
            vf_expr = f"select='eq(n,{int(frame_index)})'"
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-vf', vf_expr,
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰ç´¢å¼•æå–å¸§: index={frame_index}, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰ç´¢å¼•æå–å¤±è´¥: {str(e)}")
            return None

    def _extract_frame_by_time(self, video_path, output_path, quality_params, seek_time):
        """æŒ‰æ—¶é—´å®šä½æå–å•å¸§ï¼ˆseek_timeä¸ºç§’ï¼‰"""
        try:
            import subprocess
            cmd = [
                'ffmpeg',
                '-ss', f"{seek_time}",
                '-i', video_path,
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰æ—¶é—´æå–å¸§: t={seek_time:.3f}s, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰æ—¶é—´æå–å¤±è´¥: {str(e)}")
            return None

    def _get_total_frames(self, video_path):
        """ä½¿ç”¨ffprobeå°½å¯èƒ½è·å–æ€»å¸§æ•°ï¼Œå¤±è´¥è¿”å›None"""
        try:
            import subprocess, json
            # æ–¹æ¡ˆ1ï¼šcount_frames
            cmd1 = [
                'ffprobe',
                '-v', 'error',
                '-count_frames',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=nb_read_frames',
                '-of', 'default=nokey=1:noprint_wrappers=1',
                video_path
            ]
            res1 = subprocess.run(cmd1, capture_output=True, text=True, timeout=20)
            if res1.returncode == 0:
                val = res1.stdout.strip()
                if val.isdigit():
                    return int(val)

            # æ–¹æ¡ˆ2ï¼šè¯»å–nb_frames
            cmd2 = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=nb_frames',
                '-of', 'default=nokey=1:noprint_wrappers=1',
                video_path
            ]
            res2 = subprocess.run(cmd2, capture_output=True, text=True, timeout=20)
            if res2.returncode == 0:
                val = res2.stdout.strip()
                if val.isdigit():
                    return int(val)
        except Exception as e:
            _log_warning(f"æ— æ³•è·å–æ€»å¸§æ•°: {str(e)}")
        return None

    def _get_duration_and_fps(self, video_path):
        """è¿”å›(duration_seconds, fps) æˆ– (None, None)"""
        try:
            import subprocess, json
            # è·å–æ—¶é•¿
            cmd = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=avg_frame_rate:format=duration',
                '-of', 'json',
                video_path
            ]
            res = subprocess.run(cmd, capture_output=True, text=True, timeout=20)
            if res.returncode == 0 and res.stdout:
                data = json.loads(res.stdout)
                duration = None
                fps = None
                if 'format' in data and 'duration' in data['format']:
                    try:
                        duration = float(data['format']['duration'])
                    except:
                        duration = None
                if 'streams' in data and data['streams']:
                    afr = data['streams'][0].get('avg_frame_rate')
                    if afr and afr != '0/0':
                        try:
                            num, den = afr.split('/')
                            num = float(num)
                            den = float(den) if float(den) != 0 else 1.0
                            fps = num / den if den else None
                        except:
                            fps = None
                return duration, fps
        except Exception as e:
            _log_warning(f"æ— æ³•è·å–æ—¶é•¿ä¸FPS: {str(e)}")
        return None, None

    def _extract_frame_with_ffmpeg(self, video_path, output_path, quality_params):
        """ä½¿ç”¨FFmpegæå–å°¾å¸§"""
        try:
            import subprocess

            # æ–¹æ³•1ï¼šä½¿ç”¨select=eofè¿‡æ»¤å™¨
            cmd1 = [
                'ffmpeg',
                '-i', video_path,
                '-vf', 'select=eof',
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd1)}")

            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                return output_path

            # æ–¹æ³•2ï¼šå¤‡ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
            _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•...")

            # è·å–è§†é¢‘æ—¶é•¿
            duration_cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                video_path
            ]

            duration_result = subprocess.run(
                duration_cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if duration_result.returncode == 0:
                try:
                    duration = float(duration_result.stdout.strip())
                    seek_time = max(0, duration - 0.1)

                    cmd2 = [
                        'ffmpeg',
                        '-ss', str(seek_time),
                        '-i', video_path,
                        '-frames:v', '1',
                    ] + quality_params + [
                        '-y',
                        output_path
                    ]

                    result = subprocess.run(
                        cmd2,
                        capture_output=True,
                        text=True,
                        timeout=self.timeout
                    )

                    if result.returncode == 0 and os.path.exists(output_path):
                        return output_path
                except:
                    pass

            return None

        except Exception as e:
            _log_error(f"FFmpegæå–å¤±è´¥: {str(e)}")
            return None

    def _load_image_as_tensor(self, image_path):
        """å°†å›¾åƒæ–‡ä»¶åŠ è½½ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        try:
            from PIL import Image
            import numpy as np
            import torch

            # ä½¿ç”¨PILåŠ è½½å›¾åƒ
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img).astype(np.float32) / 255.0

                # æ·»åŠ batchç»´åº¦ [H, W, C] -> [1, H, W, C]
                img_array = np.expand_dims(img_array, axis=0)

                # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
                img_tensor = torch.from_numpy(img_array)

                _log_info(f"âœ… å›¾åƒå¼ é‡æ ¼å¼: {img_tensor.shape}, dtype: {img_tensor.dtype}")
                return img_tensor

        except Exception as e:
            _log_error(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
            return None

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _create_blank_image(self):
        """åˆ›å»ºç©ºç™½å›¾åƒå¼ é‡"""
        try:
            import numpy as np
            import torch
            # åˆ›å»º512x512çš„é»‘è‰²å›¾åƒ
            blank_array = np.zeros((1, 512, 512, 3), dtype=np.float32)
            # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
            blank_tensor = torch.from_numpy(blank_array)
            return blank_tensor
        except:
            return None






# ä¸UtilNodes-ComfyUIå®Œå…¨ä¸€è‡´çš„èŠ‚ç‚¹ï¼šVideoUtilitiesGetVHSFilePath
class VideoUtilitiesGetVHSFilePath:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "filenames": ("VHS_FILENAMES",),
                "sleep": ("INT", {"default": 3, "min": 0, "max": 60, "step": 1}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Get video file path from Video Combine node output"

    RETURN_TYPES = ("VIDEO",)
    RETURN_NAMES = ("AFVIDEO",)

    OUTPUT_NODE = False

    FUNCTION = "get_video_path"

    def get_video_path(self, filenames, sleep):
        import time, os, shutil

        if sleep > 0:
            time.sleep(sleep)

        # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•
        try:
            import folder_paths
            output_dir = folder_paths.get_output_directory()
        except Exception:
            output_dir = tempfile.gettempdir()

        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        # åªå¤„ç†å…ƒç»„æˆ–åˆ—è¡¨ä¸”ç¬¬äºŒé¡¹ä¸ºåˆ—è¡¨çš„æƒ…å†µ
        if isinstance(filenames, (tuple, list)) and len(filenames) >= 2 and isinstance(filenames[1], list):
            file_paths = filenames[1]
            # é€†åºæŸ¥æ‰¾æœ€åä¸€ä¸ªå­˜åœ¨çš„è§†é¢‘æ–‡ä»¶
            for path in reversed(file_paths):
                if isinstance(path, str) and path.lower().endswith((".mp4", ".webm", ".mkv", ".avi")) and os.path.exists(path):
                    # æ‹·è´åˆ°outputç›®å½•
                    new_path = os.path.join(output_dir, os.path.basename(path))
                    try:
                        shutil.copy2(path, new_path)
                    except Exception:
                        # æ‹·è´å¤±è´¥å°±è¿”å›åŸè·¯å¾„
                        return (path,)
                    return (new_path,)
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­˜åœ¨çš„è§†é¢‘æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥åªè¿”å›æœ€åä¸€ä¸ªè§†é¢‘æ–‡ä»¶åï¼ˆä¸åˆ¤æ–­å­˜åœ¨æ€§ï¼‰
            for path in reversed(file_paths):
                if isinstance(path, str) and path.lower().endswith((".mp4", ".webm", ".mkv", ".avi")):
                    return (path,)
        # å…œåº•ï¼šè¿”å›ç©ºå­—ç¬¦ä¸²
        return ("",)

# å°†è§†é¢‘è½¬ä¸ºGIFçš„èŠ‚ç‚¹
class VideoToGIFNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
                "fps": ("INT", {"default": 12, "min": 1, "max": 60, "step": 1}),
                "max_width": ("INT", {"default": 512, "min": 64, "max": 4096, "step": 16}),
                "max_size_mb": ("INT", {"default": 8, "min": 1, "max": 200, "step": 1}),
                "colors": ("INT", {"default": 128, "min": 2, "max": 256, "step": 1}),
                "dither": (["floyd_steinberg", "bayer", "none"], {"default": "floyd_steinberg"}),
                "loop": ("INT", {"default": 0, "min": 0, "max": 1000, "step": 1}),
            },
            "optional": {
                "keep_aspect": ("BOOLEAN", {"default": True}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Convert a video file to GIF with controllable quality and size"

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("GIF_PATH", "STATUS")

    OUTPUT_NODE = False

    FUNCTION = "convert_to_gif"

    def _extract_video_path(self, video):
        try:
            if isinstance(video, str):
                return video
            for attr in ["file_path", "filename", "file", "path", "filepath", "video_path"]:
                if hasattr(video, attr):
                    val = getattr(video, attr)
                    if isinstance(val, str) and val:
                        return val
            if isinstance(video, dict):
                for k in ["file_path", "filename", "path", "url", "source"]:
                    if k in video and isinstance(video[k], str):
                        return video[k]
            s = str(video)
            if s and ("/" in s or "\\" in s) and s.lower().endswith((".mp4", ".webm", ".mkv", ".avi")):
                return s
        except:
            pass
        return None

    def _ensure_output_dir(self):
        try:
            import folder_paths
            out_dir = folder_paths.get_output_directory()
        except Exception:
            out_dir = tempfile.gettempdir()
        os.makedirs(out_dir, exist_ok=True)
        return out_dir

    def _run_ffmpeg_gif(self, src, dst, fps, width, colors, dither, loop):
        palette = dst + ".palette.png"
        vf_scale = f"scale={width}:-1:flags=lanczos"
        palettegen = [
            "-vf", f"fps={fps},{vf_scale},palettegen=max_colors={colors}:stats_mode=full"
        ]
        paletteuse = [
            "-lavfi", f"fps={fps},{vf_scale} [x]; [x][1:v] paletteuse=dither={dither}:diff_mode=rectangle"
        ]
        # ç”Ÿæˆè°ƒè‰²æ¿
        cmd1 = [
            "ffmpeg", "-y", "-i", src,
        ] + palettegen + [palette]
        # ä½¿ç”¨è°ƒè‰²æ¿ç”Ÿæˆgif
        cmd2 = [
            "ffmpeg", "-y", "-i", src, "-i", palette,
            "-loop", str(loop),
        ] + paletteuse + [dst]

        r1 = subprocess.run(cmd1, capture_output=True)
        if r1.returncode != 0:
            return False, f"palettegen failed: {r1.stderr.decode(errors='ignore')[:200]}"
        r2 = subprocess.run(cmd2, capture_output=True)
        try:
            os.unlink(palette)
        except:
            pass
        if r2.returncode != 0:
            return False, f"gif encode failed: {r2.stderr.decode(errors='ignore')[:200]}"
        return True, "ok"

    def convert_to_gif(self, video, fps, max_width, max_size_mb, colors, dither, loop, keep_aspect=True):
        try:
            src = self._extract_video_path(video)
            if not src or not os.path.exists(src):
                return ("", f"Video not found: {src}")

            out_dir = self._ensure_output_dir()
            base = os.path.splitext(os.path.basename(src))[0]
            dst = os.path.join(out_dir, f"{base}_{int(time.time())}.gif")

            # è‡ªé€‚åº”å‹ç¼©å¾ªç¯
            attempt_fps = int(max(1, fps))
            attempt_width = int(max(64, min(max_width, 4096)))
            min_width = 64
            status = ""

            for _ in range(12):
                ok, msg = self._run_ffmpeg_gif(src, dst, attempt_fps, attempt_width, int(colors), dither, int(loop))
                if not ok:
                    status = msg
                    break
                size_mb = os.path.getsize(dst) / (1024 * 1024)
                if size_mb <= max_size_mb:
                    status = f"OK {size_mb:.2f}MB @ {attempt_fps}fps {attempt_width}px {colors}c dither={dither}"
                    return (dst, status)
                # è¿‡å¤§åˆ™è°ƒæ•´ï¼šä¼˜å…ˆé™fpsï¼Œå…¶æ¬¡é™å®½åº¦
                if attempt_fps > 6:
                    attempt_fps = max(6, int(attempt_fps * 0.8))
                elif attempt_width > min_width:
                    attempt_width = max(min_width, int(attempt_width * 0.85))
                else:
                    break

            # è‹¥å¤±è´¥ï¼Œç»™å‡ºçŠ¶æ€
            if os.path.exists(dst):
                size_mb = os.path.getsize(dst) / (1024 * 1024)
                status = status or f"Exceeded target: {size_mb:.2f}MB (target {max_size_mb}MB)"
                return (dst, status)
            return ("", status or "GIF conversion failed")
        except Exception as e:
            return ("", f"Error: {str(e)}")

class PreviewGIFNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "gif_path": ("STRING", {"default": ""}),
                "copy_to_output": ("BOOLEAN", {"default": True}),
                "preview_method": (["browser", "media_player"], {"default": "browser"}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Preview a GIF file in browser or external media player"

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("file_path",)
    OUTPUT_NODE = True
    FUNCTION = "preview"

    def _ensure_output_dir(self):
        try:
            import folder_paths
            out_dir = folder_paths.get_output_directory()
        except Exception:
            out_dir = tempfile.gettempdir()
        os.makedirs(out_dir, exist_ok=True)
        return out_dir

    def preview(self, gif_path, copy_to_output=True, preview_method="browser"):
        if not gif_path or not os.path.exists(gif_path):
            return ("", {"ui": {"text": "GIF æ–‡ä»¶ä¸å­˜åœ¨"}})

        final_path = gif_path
        if copy_to_output:
            out_dir = self._ensure_output_dir()
            new_path = os.path.join(out_dir, os.path.basename(gif_path))
            if os.path.abspath(new_path) != os.path.abspath(gif_path):
                try:
                    shutil.copy2(gif_path, new_path)
                    final_path = new_path
                except Exception:
                    final_path = gif_path

        # æ ¹æ®é¢„è§ˆæ–¹æ³•é€‰æ‹©å¤„ç†æ–¹å¼
        if preview_method == "browser":
            self._open_in_browser(final_path)
            return (final_path, {"ui": {"text": f"å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {os.path.basename(final_path)}"}})
        elif preview_method == "media_player":
            self._open_in_media_player(final_path)
            return (final_path, {"ui": {"text": f"å·²åœ¨åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€: {os.path.basename(final_path)}"}})
        else:
            # é»˜è®¤ç”¨æµè§ˆå™¨æ‰“å¼€
            self._open_in_browser(final_path)
            return (final_path, {"ui": {"text": f"å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {os.path.basename(final_path)}"}})


    def _open_in_browser(self, file_path):
        """åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ–‡ä»¶"""
        try:
            import webbrowser
            import urllib.parse
            # å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸º file:// URL
            file_url = urllib.parse.urljoin('file:', urllib.request.pathname2url(os.path.abspath(file_path)))
            webbrowser.open(file_url)
            _log_info(f"ğŸŒ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {file_path}")
        except Exception as e:
            _log_error(f"âŒ æ— æ³•åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ–‡ä»¶: {e}")

    def _open_in_media_player(self, file_path):
        """åœ¨ç³»ç»Ÿé»˜è®¤åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€æ–‡ä»¶"""
        try:
            import subprocess
            import platform
            
            system = platform.system()
            if system == "Windows":
                os.startfile(file_path)
            elif system == "Darwin":  # macOS
                subprocess.run(["open", file_path])
            elif system == "Linux":
                subprocess.run(["xdg-open", file_path])
            else:
                # é€šç”¨æ–¹æ³•
                subprocess.run(["open", file_path])
            
            _log_info(f"ğŸ¬ å·²åœ¨åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€: {file_path}")
        except Exception as e:
            _log_error(f"âŒ æ— æ³•åœ¨åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€æ–‡ä»¶: {e}")

class VideoPreviewNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {"required":{
            "video":("VIDEO",),
        }}
    
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Preview video with clear previous content"

    RETURN_TYPES = ()

    OUTPUT_NODE = True

    FUNCTION = "load_video"

    def load_video(self, video):
        video_name = os.path.basename(video)
        video_path_name = os.path.basename(os.path.dirname(video))
        # ä½¿ç”¨clearå‚æ•°æ¥æ¸…é™¤ä¹‹å‰çš„è§†é¢‘é¢„è§ˆ
        return {"ui":{"video":[video_name,video_path_name]}, "clear": True}

class VideoUtilitiesUploadLiveVideo:
    @classmethod
    def INPUT_TYPES(s):
        # è·å–è§†é¢‘æ–‡ä»¶æ‰©å±•å
        video_extensions = ["mp4", "webm", "mkv", "avi"]
        
        # è·å–inputç›®å½•çš„è§†é¢‘æ–‡ä»¶
        input_files = []
        if os.path.exists(input_dir):
            for f in os.listdir(input_dir):
                if os.path.isfile(os.path.join(input_dir, f)) and f.split('.')[-1].lower() in video_extensions:
                    file_path = os.path.join(input_dir, f)
                    mtime = os.path.getmtime(file_path)
                    input_files.append((f, mtime, "Input"))
        
        # è·å–outputç›®å½•çš„è§†é¢‘æ–‡ä»¶
        output_files = []
        if os.path.exists(output_dir):
            for f in os.listdir(output_dir):
                if os.path.isfile(os.path.join(output_dir, f)) and f.split('.')[-1].lower() in video_extensions:
                    file_path = os.path.join(output_dir, f)
                    mtime = os.path.getmtime(file_path)
                    output_files.append((f, mtime, "Output"))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åº
        input_files.sort(key=lambda x: x[1], reverse=True)
        output_files.sort(key=lambda x: x[1], reverse=True)
        
        # åªä¿ç•™å¸¦å‰ç¼€çš„æ–‡ä»¶å
        files = []
        for f, _, _ in output_files:
            files.append(f"[Output] {f}")
        for f, _, _ in input_files:
            files.append(f"[Input] {f}")
        if not files:
            files = ["No video files found"]
        return {"required":{
            "video":(files,),
        },
        "optional":{
            "upload":("VIDEOPLOAD_LIVE",),
        },
        }
    
    @classmethod
    def VALIDATE_INPUTS(s, video, **kwargs):
        """éªŒè¯è¾“å…¥ï¼Œå…è®¸åŠ¨æ€æ–‡ä»¶å"""
        # å¦‚æœæ˜¯é»˜è®¤é€‰é¡¹ï¼Œç›´æ¥é€šè¿‡éªŒè¯
        if video == "No video files found":
            return True
        
        # è§£ææ–‡ä»¶åå’Œè·¯å¾„
        if video.startswith("[Output] "):
            actual_filename = video[9:]
            video_path = os.path.join(output_dir, actual_filename)
        elif video.startswith("[Input] "):
            actual_filename = video[8:]
            video_path = os.path.join(input_dir, actual_filename)
        else:
            # å…¼å®¹æ—§æ ¼å¼æˆ–ç›´æ¥æ–‡ä»¶å
            actual_filename = video
            video_path = os.path.join(input_dir, video)
            if not os.path.exists(video_path):
                video_path = os.path.join(output_dir, video)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”ä¸ºæ”¯æŒçš„è§†é¢‘æ ¼å¼
        if os.path.exists(video_path):
            video_extensions = ["mp4", "webm", "mkv", "avi"]
            file_ext = actual_filename.split('.')[-1].lower()
            if file_ext in video_extensions:
                return True
        
        return f"Video file not found or unsupported format: {video}"
    
    @classmethod
    def IS_CHANGED(s, **kwargs):
        # åªè¦æœ‰å‚æ•°å˜åŒ–å°±å¼ºåˆ¶åˆ·æ–°ä¸‹æ‹‰é€‰é¡¹
        import random
        return random.random()
    
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Upload and live video loader with preview functionality"

    RETURN_TYPES = ("IMAGE", "AUDIO", "VHS_FILENAMES", "INT", "STRING",)
    RETURN_NAMES = ("IMAGE", "AUDIO", "FILENAMES", "FILE_AGE", "STATUS",)

    OUTPUT_NODE = False

    FUNCTION = "load_video"

    def load_video(self, video, **kwargs):
        # å…¼å®¹ç›´æ¥ä¼ å…¥hashæ–‡ä»¶å
        if video.startswith("[Output] "):
            actual_filename = video[9:]  # ç§»é™¤ "[Output] " å‰ç¼€
            video_path = os.path.join(output_dir, actual_filename)
        elif video.startswith("[Input] "):
            actual_filename = video[8:]  # ç§»é™¤ "[Input] " å‰ç¼€
            video_path = os.path.join(input_dir, actual_filename)
        elif os.path.exists(os.path.join(input_dir, video)):
            actual_filename = video
            video_path = os.path.join(input_dir, video)
        elif os.path.exists(os.path.join(output_dir, video)):
            actual_filename = video
            video_path = os.path.join(output_dir, video)
        elif video.startswith("--- ") or video == "No video files found":
            # åˆ†ç±»æ ‡ç­¾æˆ–æ— æ–‡ä»¶æƒ…å†µ
            return (None, None, "", 0, "Please select a valid video file")
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼Œé»˜è®¤ä»inputç›®å½•
            actual_filename = video
            video_path = os.path.join(input_dir, video)
        
        video_filename = os.path.basename(video_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            return (None, None, (False, []), 0, f"Video file not found: {video_filename}")
        
        # è®¡ç®—æ–‡ä»¶å¹´é¾„ï¼ˆç§’ï¼‰
        file_age = int(time.time() - os.path.getmtime(video_path))
        
        # æå–éŸ³é¢‘
        try:
            # æ ¹æ®è§†é¢‘æ¥æºé€‰æ‹©ä¸´æ—¶æ–‡ä»¶ç›®å½•
            temp_dir = output_dir if video.startswith("[Output] ") else input_dir
            with tempfile.NamedTemporaryFile(suffix=".wav", dir=temp_dir, delete=False) as aud:
                os.system(f"""ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 44100 -ac 1 "{aud.name}" -y""")
            waveform, sample_rate = torchaudio.load(aud.name)
            audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            try:
                os.unlink(aud.name)
            except:
                pass
        except:
            audio = None
        
        # æå–è§†é¢‘å¸§ä½œä¸ºå›¾åƒåºåˆ—
        try:
            cap = cv2.VideoCapture(video_path)
            
            # è·å–è§†é¢‘çš„æ€»å¸§æ•°
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            print(f"[VideoUtilitiesUploadLiveVideo] Video info: {total_frames} frames, {fps:.2f} fps")
            
            frames = []
            frame_count = 0
            
            # è¯»å–æ‰€æœ‰å¸§
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è½¬æ¢BGRåˆ°RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # éªŒè¯frame_rgbçš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹
                print(f"[VideoUtilitiesUploadLiveVideo] Frame RGB shape: {frame_rgb.shape}, dtype: {frame_rgb.dtype}")
                
                # ç›´æ¥è½¬æ¢ä¸ºtorch tensor
                frame_tensor = torch.from_numpy(frame_rgb).float()
                # è½¬æ¢ä¸º0-1èŒƒå›´
                frame_tensor = frame_tensor / 255.0
                
                # ç¡®ä¿ç»´åº¦é¡ºåºæ­£ç¡®ï¼š(H, W, C) -> (C, H, W)
                if frame_tensor.dim() == 3:
                    # éªŒè¯è¾“å…¥æ ¼å¼
                    H, W, C = frame_tensor.shape
                    print(f"[VideoUtilitiesUploadLiveVideo] Frame tensor before permute: H={H}, W={W}, C={C}")
                    
                    if C != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3 channels, got {C}")
                        continue
                    
                    frame_tensor = frame_tensor.permute(2, 0, 1)  # (3, H, W)
                    print(f"[VideoUtilitiesUploadLiveVideo] Frame tensor after permute: {frame_tensor.shape}")
                    
                    # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
                    frame_tensor = frame_tensor.float()
                    
                    # éªŒè¯å€¼èŒƒå›´
                    if frame_tensor.min() < 0.0 or frame_tensor.max() > 1.0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Warning: Values outside [0,1] range: min={frame_tensor.min():.3f}, max={frame_tensor.max():.3f}")
                        frame_tensor = torch.clamp(frame_tensor, 0.0, 1.0)
                    
                    # æœ€ç»ˆéªŒè¯
                    if frame_tensor.shape[0] != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Final tensor should have 3 channels, got {frame_tensor.shape[0]}")
                        continue
                else:
                    print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3D tensor (H, W, C), got {frame_tensor.shape}")
                    continue
                
                frames.append(frame_tensor)
                frame_count += 1
            
            cap.release()
            
            if frames:
                # å †å æ‰€æœ‰å¸§ï¼Œæ ¼å¼ä¸º(batch_size, channels, height, width)
                image_tensor = torch.stack(frames, dim=0)  # (N, 3, H, W) å…¶ä¸­Næ˜¯å®é™…å¸§æ•°
                # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
                image_tensor = image_tensor.float()
                
                # éªŒè¯tensoræ ¼å¼
                if len(image_tensor.shape) == 4:
                    N, C, H, W = image_tensor.shape
                    print(f"[VideoUtilitiesUploadLiveVideo] Extracted {N} frames, tensor shape: {image_tensor.shape}")
                    print(f"[VideoUtilitiesUploadLiveVideo] Format: (N={N}, C={C}, H={H}, W={W})")
                    
                    # ç¡®ä¿å€¼èŒƒå›´åœ¨0-1ä¹‹é—´
                    if image_tensor.max() > 1.0 or image_tensor.min() < 0.0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Warning: Values outside [0,1] range: min={image_tensor.min():.3f}, max={image_tensor.max():.3f}")
                        image_tensor = torch.clamp(image_tensor, 0.0, 1.0)
                    
                    # ç¡®ä¿tensoræ ¼å¼å®Œå…¨æ­£ç¡®
                    if C != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3 channels, got {C}")
                        image_tensor = None
                    elif H <= 0 or W <= 0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Invalid dimensions H={H}, W={W}")
                        image_tensor = None
                    else:
                        # è½¬æ¢ä¸ºVideoHelperSuiteå…¼å®¹æ ¼å¼ï¼š(N, C, H, W) -> (N, H, W, C)
                        image_tensor = image_tensor.permute(0, 2, 3, 1)  # (N, H, W, C)
                        print(f"[VideoUtilitiesUploadLiveVideo] Converted to VideoHelperSuite format: (N={N}, H={H}, W={W}, C={C})")
                else:
                    print(f"[VideoUtilitiesUploadLiveVideo] Error: Unexpected tensor shape: {image_tensor.shape}")
                    image_tensor = None
            else:
                image_tensor = None
        except Exception as e:
            print(f"[VideoUtilitiesUploadLiveVideo] Error extracting image: {e}")
            image_tensor = None
        
        # è¿”å›ç»“æœï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯
        if video_path:
            # è·å–æ–‡ä»¶å¤§å°å’Œåˆ›å»ºæ—¶é—´
            try:
                file_size = os.path.getsize(video_path)
                file_size_mb = file_size / (1024 * 1024)
                # è·å–æ–‡ä»¶åˆ›å»ºæ—¶é—´
                create_time = time.localtime(os.path.getctime(video_path))
                create_time_str = time.strftime("%Y-%m-%d %H:%M:%S", create_time)
                status = f"Loaded: {video_filename} ({file_size_mb:.1f}MB, created: {create_time_str})"
            except:
                # å¦‚æœè·å–åˆ›å»ºæ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
                try:
                    modify_time = time.localtime(os.path.getmtime(video_path))
                    modify_time_str = time.strftime("%Y-%m-%d %H:%M:%S", modify_time)
                    status = f"Loaded: {video_filename} (modified: {modify_time_str})"
                except:
                    status = f"Loaded: {video_filename}"
        else:
            status = "No video found"

        # VHS_FILENAMES å…¼å®¹è¾“å‡ºï¼ˆä¸ Video Combine èŠ‚ç‚¹ä¸€è‡´ï¼‰ï¼š(bool, [full_paths])
        vhs_filenames = (True, [video_path]) if os.path.exists(video_path) else (False, [])
        return (image_tensor, audio, vhs_filenames, file_age, status)

class VideoUtilitiesLoadAFVideo:
    @classmethod
    def INPUT_TYPES(s):
        files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f)) and f.split('.')[-1] in ["mp4", "webm","mkv","avi"]]
        return {"required":{
            "video":(files,),
        },
        "optional":{
            "upload":("VIDEOPLOAD",),
        },
        }
    
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Load Audio/Video File with preview functionality"

    RETURN_TYPES = ("VIDEO","AUDIO",)

    OUTPUT_NODE = False

    FUNCTION = "load_video"

    def load_video(self, video):
        video_path = os.path.join(input_dir,video)
        try:
            with tempfile.NamedTemporaryFile(suffix=".wav",dir=input_dir,delete=False) as aud:
                os.system(f"""ffmpeg -i "{video_path}" -vn -acodec pcm_s16le -ar 44100 -ac 1 "{aud.name}" -y""")
            waveform, sample_rate = torchaudio.load(aud.name)
            audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            try:
                os.unlink(aud.name)
            except:
                pass
        except:
            audio = None
        return (video_path,audio,)

class VideoUtilitiesPromptTextNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "text": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),
            }
        }

    RETURN_TYPES = ("STRING",)

    FUNCTION = "encode"

    CATEGORY = "Ken-Chen/Video_Utilities"

    def encode(self, text):
        return (text,)

class VideoUtilitiesLiveVideoMonitor:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "refresh_interval": ("INT", {"default": 2, "min": 1, "max": 60, "step": 1, "tooltip": "Refresh interval in seconds"}),
                "auto_refresh": ("BOOLEAN", {"default": True, "tooltip": "Enable automatic refresh"}),
                "min_file_age": ("INT", {"default": 1, "min": 0, "max": 10, "step": 1, "tooltip": "Minimum file age in seconds to avoid loading incomplete files"}),
            }
        }

    @classmethod
    def IS_CHANGED(s, **kwargs):
        return float("nan")

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Live video loader that monitors output directory for latest video files"

    RETURN_TYPES = ("IMAGE", "AUDIO", "VHS_FILENAMES", "INT", "STRING",)
    RETURN_NAMES = ("IMAGE", "AUDIO", "FILENAMES", "FILE_AGE", "STATUS",)

    OUTPUT_NODE = True

    FUNCTION = "load_latest_video"

    def load_latest_video(self, refresh_interval, auto_refresh, min_file_age):
        video_extensions = ["*.mp4", "*.webm", "*.mkv", "*.avi"]
        video_files = []
        for ext in video_extensions:
            video_files.extend(glob.glob(os.path.join(output_dir, ext)))
            video_files.extend(glob.glob(os.path.join(output_dir, ext.upper())))

        if not video_files:
            return {"result": (None, None, "", 0, "No video files found")}

        latest_video = max(video_files, key=os.path.getmtime)
        video_filename = os.path.basename(latest_video)

        file_age = int(time.time() - os.path.getmtime(latest_video))
        if file_age < min_file_age:
            return {"result": (None, None, "", file_age, f"File too new (age: {file_age}s)")}

        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", dir=output_dir, delete=False) as aud:
                os.system(f"""ffmpeg -i "{latest_video}" -vn -acodec pcm_s16le -ar 44100 -ac 1 "{aud.name}" -y""")
            waveform, sample_rate = torchaudio.load(aud.name)
            audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
            try:
                os.unlink(aud.name)
            except:
                pass
        except:
            audio = None

        try:
            cap = cv2.VideoCapture(latest_video)
            frames = []
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_tensor = torch.from_numpy(frame_rgb).float() / 255.0
                if frame_tensor.dim() == 3 and frame_tensor.shape[2] == 3:
                    frame_tensor = frame_tensor.permute(2, 0, 1).float()
                    frame_tensor = torch.clamp(frame_tensor, 0.0, 1.0)
                else:
                    continue
                frames.append(frame_tensor)
            cap.release()

            if frames:
                image_tensor = torch.stack(frames, dim=0).float()
                if len(image_tensor.shape) == 4 and image_tensor.shape[1] == 3:
                    image_tensor = image_tensor.permute(0, 2, 3, 1)
                else:
                    image_tensor = None
            else:
                image_tensor = None
        except Exception:
            image_tensor = None

        if latest_video:
            try:
                file_size_mb = os.path.getsize(latest_video) / (1024 * 1024)
                create_time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(os.path.getctime(latest_video)))
                status = f"Loaded: {video_filename} ({file_size_mb:.1f}MB, created: {create_time_str})"
            except:
                status = f"Loaded: {video_filename}"
        else:
            status = "No video found"

        if latest_video and os.path.exists(latest_video):
            video_path_name = "output"
            vhs_filenames = (1, [latest_video])
            return {"ui": {"video": [video_filename, video_path_name]}, "result": (image_tensor, audio, vhs_filenames, file_age, status)}
        else:
            vhs_filenames = (0, [])
            return {"result": (image_tensor, audio, vhs_filenames, file_age, status)}

class VideoUtilitiesRGBEmptyImage:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "width": ("INT", {"default": 512, "min": 128, "max": 1024, "step": 64, "display": "number"}),
                "height": ("INT", {"default": 512, "min": 128, "max": 1024, "step": 64, "display": "number"}),
                "R": ("INT", {"default": 124, "min": 0, "max": 255, "step": 1, "display": "number"}),
                "G": ("INT", {"default": 252, "min": 0, "max": 255, "step": 1, "display": "number"}),
                "B": ("INT", {"default": 0,   "min": 0, "max": 255, "step": 1, "display": "number"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "gen_img"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def gen_img(self, width: int, height: int, R: int, G: int, B: int):
        new_image = Image.new("RGB", (width, height), color=(R, G, B))
        tensor = torch.from_numpy(np.asarray(new_image) / 255.0).unsqueeze(0)
        return (tensor,)

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "VideoStitchingNode": VideoStitchingNode,
    "GetLastFrameNode": GetLastFrameNode,
    "VideoUtilitiesGetVHSFilePath": VideoUtilitiesGetVHSFilePath,
    "VideoToGIFNode": VideoToGIFNode,
    "PreviewGIFNode": PreviewGIFNode,
    "VideoPreviewNode": VideoPreviewNode,
    "VideoUtilitiesUploadLiveVideo": VideoUtilitiesUploadLiveVideo,
    "VideoUtilitiesLoadAFVideo": VideoUtilitiesLoadAFVideo,
    "VideoUtilitiesPromptTextNode": VideoUtilitiesPromptTextNode,
    "VideoUtilitiesLiveVideoMonitor": VideoUtilitiesLiveVideoMonitor,
    "VideoUtilitiesRGBEmptyImage": VideoUtilitiesRGBEmptyImage,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoStitchingNode": "Video_Stitching",
    "GetLastFrameNode": "Get_Last_Frame",
    "VideoUtilitiesGetVHSFilePath": "Get VHS File Path",
    "VideoToGIFNode": "Video_To_GIF",
    "PreviewGIFNode": "Preview_GIF",
    "VideoPreviewNode": "Video_Preview",
    "VideoUtilitiesUploadLiveVideo": "Upload_Live_Video",
    "VideoUtilitiesLoadAFVideo": "Load_AF_Video",
    "VideoUtilitiesPromptTextNode": "Prompt_Text_Node",
    "VideoUtilitiesLiveVideoMonitor": "Live_Video_Monitor",
    "VideoUtilitiesRGBEmptyImage": "RGB_Empty_Image",
}

