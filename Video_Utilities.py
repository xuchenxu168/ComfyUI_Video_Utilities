"""
Doubao-Seed èŠ‚ç‚¹
åŸºäºComfyUI_Comflyé¡¹ç›®çš„Doubao Seedream4å®ç°
é›†æˆå¤šå®¶APIè°ƒç”¨ï¼Œæ”¯æŒå›¾åƒç”Ÿæˆå’Œè§†é¢‘ç”ŸæˆåŠŸèƒ½
"""

import os
import json
import requests
import time
import random
import base64
import io
import subprocess
from PIL import Image
import torch
import numpy as np
from typing import Optional, Dict, Any, List, Tuple
import urllib3
import ssl
import glob
import torchaudio

# å¯¼å…¥ ComfyUI çš„æ–‡ä»¶å¤¹è·¯å¾„
try:
    import folder_paths
    input_dir = folder_paths.get_input_directory()
    output_dir = folder_paths.get_output_directory()
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ folder_pathsï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    input_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "input")
    output_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "output")
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import tempfile
import shutil
from urllib.parse import urlparse
from fractions import Fraction

# å¯¼å…¥ComfyUIçš„è§†é¢‘ç±»å‹ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†
try:
    from comfy_api.input_impl import VideoFromFile
    HAS_COMFYUI_VIDEO = True
    print("[Video Utilities] ä¿¡æ¯ï¼šâœ… ComfyUIå®˜æ–¹è§†é¢‘ç±»å‹å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    HAS_COMFYUI_VIDEO = False
    print(f"[Video Utilities] ä¿¡æ¯ï¼šâš ï¸ ComfyUIè§†é¢‘ç±»å‹å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")
    # åˆ›å»ºç®€å•çš„æ›¿ä»£ç±»
    class VideoFromFile:
        def __init__(self, file_path):
            self.file_path = file_path
        def get_dimensions(self):
            return (512, 512)  # é»˜è®¤å°ºå¯¸

# å°è¯•å¯¼å…¥è§†é¢‘å¤„ç†åº“
try:
    import cv2
    HAS_CV2 = True
except ImportError:
    HAS_CV2 = False
    _log_warning("OpenCVæœªå®‰è£…ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å—é™")

try:
    import imageio
    HAS_IMAGEIO = True
except ImportError:
    HAS_IMAGEIO = False

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def create_ssl_compatible_session():
    """åˆ›å»ºSSLå…¼å®¹çš„requests session"""
    session = requests.Session()

    # é…ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
    )

    # åˆ›å»ºè‡ªå®šä¹‰çš„HTTPAdapter
    class SSLAdapter(HTTPAdapter):
        def init_poolmanager(self, *args, **kwargs):
            # åˆ›å»ºæ›´å®½æ¾çš„SSLä¸Šä¸‹æ–‡
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            # æ”¯æŒæ›´å¤šSSLåè®®ç‰ˆæœ¬å’Œå¯†ç å¥—ä»¶
            try:
                ssl_context.minimum_version = ssl.TLSVersion.TLSv1
                ssl_context.maximum_version = ssl.TLSVersion.TLSv1_3
            except AttributeError:
                # å…¼å®¹æ—§ç‰ˆæœ¬Python
                pass

            # è®¾ç½®æ›´å®½æ¾çš„å¯†ç å¥—ä»¶
            try:
                ssl_context.set_ciphers('DEFAULT:@SECLEVEL=1')
            except ssl.SSLError:
                try:
                    ssl_context.set_ciphers('ALL:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!SRP:!CAMELLIA')
                except ssl.SSLError:
                    pass  # ä½¿ç”¨é»˜è®¤å¯†ç å¥—ä»¶

            # ç¦ç”¨å„ç§SSLæ£€æŸ¥
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            kwargs['ssl_context'] = ssl_context
            return super().init_poolmanager(*args, **kwargs)

    # åº”ç”¨é€‚é…å™¨
    adapter = SSLAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)

    # è®¾ç½®è¶…æ—¶å’Œå…¶ä»–é€‰é¡¹
    session.verify = False  # ç¦ç”¨SSLéªŒè¯

    return session

# å…¨å±€å¸¸é‡å’Œé…ç½®
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SEEDREAM4_CONFIG_FILE = 'SeedReam4_config.json'

def _log_info(message):
    print(f"[Video Utilities] ä¿¡æ¯ï¼š{message}")

def _log_warning(message):
    print(f"[Video Utilities] è­¦å‘Šï¼š{message}")

def _log_error(message):
    print(f"[Video Utilities] é”™è¯¯ï¼š{message}")
def tensor2pil(tensor):
    """å°†tensorè½¬æ¢ä¸ºPILå›¾åƒ - æ”¯æŒComfyUIçš„[B, H, W, C]æ ¼å¼"""
    if tensor is None:
        _log_warning("âš ï¸ tensor2pil: è¾“å…¥tensorä¸ºNone")
        return None
    if isinstance(tensor, list):
        return [tensor2pil(img) for img in tensor]

    try:
        # ç¡®ä¿tensoræ˜¯4ç»´çš„
        if len(tensor.shape) == 3:
            tensor = tensor.unsqueeze(0)

        # å¦‚æœæ˜¯batchï¼Œå¤„ç†å¤šå›¾æƒ…å†µï¼ˆè¿™é‡Œåªå¤„ç†å•å›¾è½¬æ¢ï¼Œå¤šå›¾æ‹¼æ¥åœ¨image_to_base64ä¸­å¤„ç†ï¼‰
        if len(tensor.shape) == 4 and tensor.shape[0] > 1:
            # å¯¹äºtensor2pilå‡½æ•°ï¼Œæˆ‘ä»¬åªè½¬æ¢ç¬¬ä¸€å¼ å›¾åƒ
            # å¤šå›¾æ‹¼æ¥é€»è¾‘åœ¨image_to_base64å‡½æ•°ä¸­å¤„ç†
            tensor = tensor[0:1]

        # ç°åœ¨åº”è¯¥æ˜¯ [1, H, W, C] æ ¼å¼ï¼Œå»æ‰batchç»´åº¦
        if len(tensor.shape) == 4:
            tensor = tensor.squeeze(0)  # å˜æˆ [H, W, C]

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢é€šé“é¡ºåº
        if len(tensor.shape) == 3:
            # å¦‚æœæœ€åä¸€ä¸ªç»´åº¦ä¸æ˜¯3ï¼ˆRGBé€šé“ï¼‰ï¼Œå¯èƒ½æ˜¯[C, H, W]æ ¼å¼
            if tensor.shape[-1] != 3 and tensor.shape[0] == 3:
                tensor = tensor.permute(1, 2, 0)  # [C, H, W] -> [H, W, C]

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if hasattr(tensor, 'cpu'):
            # PyTorch tensor
            np_image = tensor.cpu().numpy()
        else:
            # å·²ç»æ˜¯numpyæ•°ç»„
            np_image = tensor

        # ç¡®ä¿æ•°æ®ç±»å‹å’ŒèŒƒå›´æ­£ç¡®
        if np_image.dtype != np.uint8:
            if np_image.max() <= 1.0:
                np_image = (np_image * 255).astype(np.uint8)
            else:
                np_image = np.clip(np_image, 0, 255).astype(np.uint8)

        # å¦‚æœæ˜¯ç°åº¦å›¾åƒï¼Œè½¬æ¢ä¸ºRGB
        if len(np_image.shape) == 2:
            np_image = np.stack([np_image] * 3, axis=-1)
        elif np_image.shape[-1] == 1:
            np_image = np.repeat(np_image, 3, axis=-1)

        pil_image = Image.fromarray(np_image)

        return pil_image

    except Exception as e:
        _log_error(f"âŒ tensor2pilè½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def pil2tensor(image):
    """å°†PILå›¾åƒè½¬æ¢ä¸ºtensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    if image is None:
        return None
    if isinstance(image, list):
        if len(image) == 0:
            return torch.empty(0)
        return torch.cat([pil2tensor(img) for img in image], dim=0)
    
    # è½¬æ¢ä¸ºRGB
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    elif image.mode != 'RGB':
        image = image.convert('RGB')
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–åˆ°[0, 1]
    img_array = np.array(image).astype(np.float32) / 255.0
    
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(img_array)[None,]

def create_blank_tensor(width=1024, height=1024):
    """åˆ›å»ºæ­£ç¡®æ ¼å¼çš„ç©ºç™½tensor - å‚è€ƒComfyUI_Comflyçš„å®ç°"""
    blank_image = Image.new('RGB', (width, height), color='white')
    np_image = np.array(blank_image).astype(np.float32) / 255.0
    # è¿”å›tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3] - è¿™æ˜¯ComfyUIçš„æ ‡å‡†æ ¼å¼
    return torch.from_numpy(np_image)[None,]

def ensure_tensor_format(tensor):
    """ç¡®ä¿tensoræ ¼å¼å®Œå…¨ç¬¦åˆComfyUIè¦æ±‚ - æ ¼å¼ä¸º[1, H, W, 3]"""
    if tensor is None:
        return create_blank_tensor()
    
    original_shape = tensor.shape
    _log_info(f"ğŸ” è¾“å…¥tensorå½¢çŠ¶: {original_shape}")
    
    # å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœtensorå½¢çŠ¶æ˜¯ (1, 1, 2048) æˆ–ç±»ä¼¼æ ¼å¼
    if len(tensor.shape) == 3 and tensor.shape[1] == 1 and tensor.shape[2] > 1000:
        _log_warning(f"âš ï¸ æ£€æµ‹åˆ°å¼‚å¸¸tensorå½¢çŠ¶: {tensor.shape}ï¼Œå¯èƒ½æ˜¯1Dæ•°æ®è¢«é”™è¯¯reshape")
        return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯4ç»´tensorï¼Œæ ¼å¼ä¸º[1, H, W, 3]
    if len(tensor.shape) != 4:
        if len(tensor.shape) == 3:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ (H, W, 3) æ ¼å¼
            if tensor.shape[-1] == 3:
                tensor = tensor.unsqueeze(0)
                _log_info(f"ğŸ”§ æ·»åŠ batchç»´åº¦: {tensor.shape}")
            else:
                _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
                return create_blank_tensor()
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensorç»´åº¦: {original_shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ˜¯ (batch, height, width, channels) æ ¼å¼
    if tensor.shape[-1] != 3:
        if tensor.shape[1] == 3:  # å¦‚æœæ˜¯ (batch, channels, height, width) æ ¼å¼
            tensor = tensor.permute(0, 2, 3, 1)
            _log_info(f"ğŸ”§ é‡æ–°æ’åˆ—tensorç»´åº¦: {tensor.shape}")
        else:
            _log_error(f"âŒ æ— æ³•ä¿®å¤tensoré€šé“ç»´åº¦: {tensor.shape}")
            return create_blank_tensor()
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    if tensor.dtype != torch.float32:
        tensor = tensor.float()
        _log_info(f"ğŸ”§ è½¬æ¢tensoræ•°æ®ç±»å‹: {tensor.dtype}")
    
    # ç¡®ä¿å€¼èŒƒå›´æ­£ç¡® (0-1)
    if tensor.min() < 0 or tensor.max() > 1:
        tensor = torch.clamp(tensor, 0, 1)
        _log_info(f"ğŸ”§ é™åˆ¶tensorå€¼èŒƒå›´: {tensor.min().item():.3f} åˆ° {tensor.max().item():.3f}")
    
    # ç¡®ä¿æ²¡æœ‰å¼‚å¸¸å€¼
    if torch.isnan(tensor).any() or torch.isinf(tensor).any():
        _log_error("âŒ tensoråŒ…å«å¼‚å¸¸å€¼ï¼Œä½¿ç”¨ç©ºç™½tensoræ›¿ä»£")
        return create_blank_tensor()
    
    # æœ€ç»ˆéªŒè¯ - ç¡®ä¿æ˜¯[1, H, W, 3]æ ¼å¼
    if len(tensor.shape) != 4 or tensor.shape[-1] != 3:
        _log_error(f"âŒ æœ€ç»ˆtensoræ ¼å¼ä»ç„¶ä¸æ­£ç¡®: {tensor.shape}")
        return create_blank_tensor()
    
    _log_info(f"âœ… tensoræ ¼å¼éªŒè¯é€šè¿‡: {tensor.shape}")
    return tensor

def image_to_base64(image_tensor, max_size=2048, return_data_url=True):
    """å°†tensorè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²ï¼Œæ”¯æŒè‡ªåŠ¨å‹ç¼©å’Œå¤šå›¾æ‹¼æ¥

    Args:
        image_tensor: è¾“å…¥çš„å›¾åƒtensor
        max_size: æœ€å¤§å°ºå¯¸é™åˆ¶
        return_data_url: æ˜¯å¦è¿”å›å®Œæ•´çš„data URLæ ¼å¼ï¼ŒFalseåˆ™åªè¿”å›base64å­—ç¬¦ä¸²
    """
    if image_tensor is None:
        return None

    # å¦‚æœæ˜¯batchï¼Œå°†å¤šå¼ å›¾åƒæ°´å¹³æ‹¼æ¥æˆä¸€å¼ å¤§å›¾
    if len(image_tensor.shape) == 4 and image_tensor.shape[0] > 1:
        _log_info(f"ğŸ” æ£€æµ‹åˆ°å¤šå›¾batchè¾“å…¥ {image_tensor.shape}ï¼Œå°†æ‹¼æ¥æˆä¸€å¼ å¤§å›¾")

        # å°†æ¯å¼ å›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        pil_images = []
        for i in range(image_tensor.shape[0]):
            single_tensor = image_tensor[i:i+1]  # ä¿æŒ4Dæ ¼å¼
            pil_img = tensor2pil(single_tensor)
            if pil_img is not None:
                pil_images.append(pil_img)

        if not pil_images:
            return None

        # æ°´å¹³æ‹¼æ¥å›¾åƒ
        total_width = sum(img.width for img in pil_images)
        max_height = max(img.height for img in pil_images)

        # åˆ›å»ºæ‹¼æ¥åçš„å¤§å›¾
        combined_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))
        x_offset = 0
        for img in pil_images:
            combined_image.paste(img, (x_offset, 0))
            x_offset += img.width

        pil_image = combined_image
        _log_info(f"ğŸ”§ å¤šå›¾æ‹¼æ¥å®Œæˆ: {len(pil_images)}å¼ å›¾ -> {pil_image.size}")
    else:
        pil_image = tensor2pil(image_tensor)
        if pil_image is None:
            return None

    # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼Œå¦‚æœè¿‡å¤§åˆ™å‹ç¼©
    original_size = pil_image.size
    if max(original_size) > max_size:
        # è®¡ç®—æ–°å°ºå¯¸ï¼Œä¿æŒå®½é«˜æ¯”
        ratio = max_size / max(original_size)
        new_size = (int(original_size[0] * ratio), int(original_size[1] * ratio))
        pil_image = pil_image.resize(new_size, Image.Resampling.LANCZOS)
        _log_info(f"ğŸ”§ å›¾åƒå‹ç¼©: {original_size} -> {new_size}")

    buffered = io.BytesIO()
    # ä½¿ç”¨JPEGæ ¼å¼å‹ç¼©å¤§å›¾åƒï¼ŒPNGæ ¼å¼ä¿ç•™å°å›¾åƒ
    if max(pil_image.size) > 1024:
        # å¯¹äºå›¾åƒç¼–è¾‘ï¼Œä½¿ç”¨æ›´é«˜è´¨é‡çš„JPEG
        quality = 90 if max(original_size) > max_size else 85
        pil_image.save(buffered, format="JPEG", quality=quality, optimize=True)
        format_prefix = "data:image/jpeg;base64,"
    else:
        pil_image.save(buffered, format="PNG", optimize=True)
        format_prefix = "data:image/png;base64,"

    image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

    # éªŒè¯base64å­—ç¬¦ä¸²çš„æœ‰æ•ˆæ€§
    try:
        # å°è¯•è§£ç éªŒè¯
        base64.b64decode(image_base64)
    except Exception as e:
        _log_warning(f"âš ï¸ Base64ç¼–ç éªŒè¯å¤±è´¥: {e}")
        return None

    if return_data_url:
        return f"{format_prefix}{image_base64}"
    else:
        return image_base64

def download_video_from_url(video_url: str, output_dir: str = None) -> str:
    """ä»URLä¸‹è½½è§†é¢‘æ–‡ä»¶"""
    try:
        if not video_url or not video_url.strip():
            raise ValueError("è§†é¢‘URLä¸ºç©º")

        # è§£æURLè·å–æ–‡ä»¶å
        parsed_url = urlparse(video_url)
        filename = os.path.basename(parsed_url.path)
        if not filename or '.' not in filename:
            filename = f"video_{int(time.time())}.mp4"

        # ç¡®å®šè¾“å‡ºç›®å½•
        if output_dir is None:
            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except:
                output_dir = tempfile.gettempdir()

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

        # å®Œæ•´çš„è¾“å‡ºè·¯å¾„
        output_path = os.path.join(output_dir, filename)

        _log_info(f"ğŸ”½ å¼€å§‹ä¸‹è½½è§†é¢‘: {video_url}")
        _log_info(f"ğŸ“ ä¿å­˜è·¯å¾„: {output_path}")

        # ä¸‹è½½è§†é¢‘
        response = requests.get(video_url, stream=True, timeout=300)
        response.raise_for_status()

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        file_size = os.path.getsize(output_path)
        _log_info(f"âœ… è§†é¢‘ä¸‹è½½å®Œæˆ: {filename} ({file_size / 1024 / 1024:.2f} MB)")

        return output_path

    except Exception as e:
        _log_error(f"è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
        return None

def create_preview_compatible_video(video_path: str, force_convert=False, use_cache=True):
    """ä¸º MPEG-4 ç­‰ä¸å…¼å®¹æ ¼å¼åˆ›å»ºé¢„è§ˆå…¼å®¹çš„ H.264 ç‰ˆæœ¬

    Args:
        video_path: åŸå§‹è§†é¢‘è·¯å¾„
        force_convert: æ˜¯å¦å¼ºåˆ¶é‡æ–°è½¬æ¢
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜çš„é¢„è§ˆç‰ˆæœ¬

    Returns:
        str: é¢„è§ˆç‰ˆæœ¬çš„è·¯å¾„ï¼Œå¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å› None
    """
    try:
        if not video_path or not os.path.exists(video_path):
            _log_error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        # ç¡®å®šé¢„è§ˆæ–‡ä»¶çš„ä¿å­˜ä½ç½®
        # å¦‚æœåŸè§†é¢‘åœ¨ input ç›®å½•ï¼Œé¢„è§ˆç‰ˆæœ¬ä¹Ÿæ”¾åœ¨ input ç›®å½•
        # å¦‚æœåŸè§†é¢‘åœ¨ output ç›®å½•ï¼Œé¢„è§ˆç‰ˆæœ¬ä¹Ÿæ”¾åœ¨ output ç›®å½•
        video_dir = os.path.dirname(video_path)
        base_name = os.path.splitext(os.path.basename(video_path))[0]
        preview_filename = f"{base_name}_h264_preview.mp4"
        preview_path = os.path.join(video_dir, preview_filename)

        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨é¢„è§ˆç‰ˆæœ¬
        if use_cache and os.path.exists(preview_path) and not force_convert:
            # æ£€æŸ¥é¢„è§ˆç‰ˆæœ¬æ˜¯å¦æ¯”åŸè§†é¢‘æ–°
            if os.path.getmtime(preview_path) >= os.path.getmtime(video_path):
                _log_info(f"ğŸ¬ ä½¿ç”¨ç¼“å­˜çš„é¢„è§ˆç‰ˆæœ¬: {preview_path}")
                return preview_path
            else:
                _log_info(f"ğŸ”„ é¢„è§ˆç‰ˆæœ¬è¿‡æœŸï¼Œéœ€è¦é‡æ–°åˆ›å»º")

        # æ£€æŸ¥åŸè§†é¢‘ç¼–ç 
        import subprocess
        probe_cmd = [
            "ffprobe", "-v", "quiet", "-select_streams", "v:0",
            "-show_entries", "stream=codec_name", "-of", "csv=p=0", video_path
        ]
        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)

        if probe_result.returncode != 0:
            _log_error(f"âŒ æ— æ³•æ£€æµ‹è§†é¢‘ç¼–ç : {video_path}")
            return None

        codec_name = probe_result.stdout.strip()
        _log_info(f"ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘ç¼–ç : {codec_name}")

        # åªä¸º MPEG-4 ç­‰é—®é¢˜ç¼–ç åˆ›å»ºé¢„è§ˆç‰ˆæœ¬
        if codec_name not in ['mpeg4', 'xvid', 'divx']:
            _log_info(f"âœ… è§†é¢‘ç¼–ç  {codec_name} é€šå¸¸è¢«æµè§ˆå™¨æ”¯æŒï¼Œæ— éœ€è½¬æ¢")
            return None

        _log_info(f"ğŸ”§ ä¸º {codec_name} ç¼–ç åˆ›å»º H.264 é¢„è§ˆç‰ˆæœ¬...")
        _log_info(f"ğŸ“ é¢„è§ˆæ–‡ä»¶å°†ä¿å­˜åˆ°: {preview_path}")

        # åˆ›å»º H.264 é¢„è§ˆç‰ˆæœ¬
        # ä½¿ç”¨å¿«é€Ÿç¼–ç å‚æ•°ä»¥å‡å°‘è½¬æ¢æ—¶é—´
        convert_cmd = [
            "ffmpeg", "-i", video_path,
            "-c:v", "libx264",           # H.264 ç¼–ç 
            "-preset", "veryfast",       # å¿«é€Ÿç¼–ç 
            "-crf", "23",                # è´¨é‡å‚æ•°ï¼ˆ23 æ˜¯è¾ƒå¥½çš„è´¨é‡ï¼‰
            "-c:a", "aac",               # AAC éŸ³é¢‘ç¼–ç 
            "-b:a", "128k",              # éŸ³é¢‘æ¯”ç‰¹ç‡
            "-movflags", "+faststart",   # ä¼˜åŒ–ç½‘ç»œæ’­æ”¾
            "-y",                        # è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            preview_path
        ]

        _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢...")
        _log_info(f"å‘½ä»¤: {' '.join(convert_cmd)}")

        # æ‰§è¡Œè½¬æ¢
        convert_result = subprocess.run(
            convert_cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )

        if convert_result.returncode == 0 and os.path.exists(preview_path):
            file_size = os.path.getsize(preview_path) / (1024 * 1024)
            _log_info(f"âœ… é¢„è§ˆç‰ˆæœ¬åˆ›å»ºæˆåŠŸ: {preview_path} ({file_size:.2f} MB)")
            return preview_path
        else:
            _log_error(f"âŒ é¢„è§ˆç‰ˆæœ¬åˆ›å»ºå¤±è´¥")
            _log_error(f"FFmpeg é”™è¯¯: {convert_result.stderr}")
            # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
            if os.path.exists(preview_path):
                try:
                    os.remove(preview_path)
                except:
                    pass
            return None

    except subprocess.TimeoutExpired:
        _log_error(f"âŒ è§†é¢‘è½¬æ¢è¶…æ—¶ï¼ˆè¶…è¿‡5åˆ†é’Ÿï¼‰")
        return None
    except Exception as e:
        _log_error(f"âŒ åˆ›å»ºé¢„è§ˆç‰ˆæœ¬å¤±è´¥: {e}")
        import traceback
        _log_error(traceback.format_exc())
        return None

def video_to_comfyui_video(video_path: str):
    """å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡ - ä½¿ç”¨å®˜æ–¹æ ‡å‡†VideoFromFileï¼Œæ”¯æŒ MPEG-4 ç­‰ç‰¹æ®Šç¼–ç """
    try:
        if not video_path or not os.path.exists(video_path):
            raise ValueError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

        _log_info(f"ğŸ¬ å¼€å§‹åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡: {video_path}")

        # æ£€æŸ¥è§†é¢‘ç¼–ç æ ¼å¼
        codec_info = None
        try:
            import subprocess
            probe_cmd = [
                "ffprobe", "-v", "quiet", "-print_format", "json",
                "-show_streams", "-select_streams", "v:0", video_path
            ]
            probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
            if probe_result.returncode == 0:
                import json
                probe_data = json.loads(probe_result.stdout)
                if probe_data.get("streams"):
                    codec_info = probe_data["streams"][0]
                    codec_name = codec_info.get("codec_name", "unknown")
                    _log_info(f"ğŸ¬ è§†é¢‘ç¼–ç : {codec_name}")

                    # ç‰¹åˆ«å¤„ç† MPEG-4 part 2 ç¼–ç ï¼ˆTopaz Video AI å¸¸ç”¨ï¼‰
                    if codec_name == "mpeg4":
                        _log_info(f"ğŸ”§ æ£€æµ‹åˆ° MPEG-4 part 2 ç¼–ç ï¼Œè¿™å¯èƒ½æ˜¯ Topaz Video AI å¤„ç†çš„è§†é¢‘")
                        _log_info(f"ğŸ’¡ æç¤º: å¦‚æœé¢„è§ˆæœ‰é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘è½¬æ¢ä¸º H.264 æ ¼å¼")
        except Exception as e:
            _log_warning(f"âš ï¸ æ— æ³•æ£€æµ‹è§†é¢‘ç¼–ç : {e}")

        # ä½¿ç”¨ComfyUIå®˜æ–¹æ ‡å‡†ï¼šç›´æ¥ä»æ–‡ä»¶è·¯å¾„åˆ›å»ºVideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(video_path)

        _log_info("âœ… åˆ›å»ºComfyUIæ ‡å‡†VideoFromFileå¯¹è±¡æˆåŠŸ")

        # æµ‹è¯•get_dimensionsæ–¹æ³•
        try:
            dimensions = video_obj.get_dimensions()
            _log_info(f"ğŸ“Š è§†é¢‘å°ºå¯¸: {dimensions}")
        except Exception as e:
            _log_warning(f"âš ï¸ æ— æ³•è·å–è§†é¢‘å°ºå¯¸: {e}")

        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºVideoFromFileå¯¹è±¡å¤±è´¥: {e}")
        return None

def extract_video_path(video):
    """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„ - é€šç”¨å‡½æ•°ï¼Œæ”¯æŒå¤šç§VIDEOç±»å‹"""
    _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
    if isinstance(video, str):
        _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
        return video

    # å¦‚æœæ˜¯ VHS çš„ VIDEO å¯¹è±¡ï¼ˆé€šå¸¸æ˜¯å­—å…¸ï¼‰
    if isinstance(video, dict):
        # VHS çš„ VIDEO å¯¹è±¡å¯èƒ½åŒ…å« 'filename' å’Œ 'subfolder' é”®
        if 'filename' in video:
            filename = video['filename']
            subfolder = video.get('subfolder', '')
            video_type = video.get('type', 'output')  # 'output', 'input', 'temp'

            # æ„å»ºå®Œæ•´è·¯å¾„
            if video_type == 'output':
                base_dir = folder_paths.get_output_directory()
            elif video_type == 'input':
                base_dir = folder_paths.get_input_directory()
            elif video_type == 'temp':
                base_dir = folder_paths.get_temp_directory()
            else:
                base_dir = folder_paths.get_output_directory()

            if subfolder:
                video_path = os.path.join(base_dir, subfolder, filename)
            else:
                video_path = os.path.join(base_dir, filename)

            _log_info(f"âœ… ä» VHS VIDEO å­—å…¸æå–è·¯å¾„: {video_path}")
            return video_path

    # æ‰“å°å¯¹è±¡çš„æ‰€æœ‰å±æ€§ï¼ˆè°ƒè¯•ç”¨ï¼‰
    try:
        all_attrs = dir(video)
        _log_info(f"ğŸ” å¯¹è±¡çš„æ‰€æœ‰å±æ€§: {[attr for attr in all_attrs if not attr.startswith('_')]}")
    except:
        pass

    # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
    path_attributes = [
        'saved_path',   # ComfyUI VideoFromFile å¯¹è±¡çš„ä¿å­˜è·¯å¾„
        'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
        'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
        'file',         # å‘åå…¼å®¹
        'path',         # é€šç”¨è·¯å¾„å±æ€§
        'filepath',     # æ–‡ä»¶è·¯å¾„
        'video_path',   # è§†é¢‘è·¯å¾„
        'source',       # æºæ–‡ä»¶
        'url',          # URLè·¯å¾„
        'video_file',   # è§†é¢‘æ–‡ä»¶
        'file_name',    # æ–‡ä»¶å
    ]

    for attr in path_attributes:
        if hasattr(video, attr):
            value = getattr(video, attr)
            _log_info(f"ğŸ” æ£€æŸ¥å±æ€§ {attr}: {type(value)} = {value}")
            if isinstance(value, str) and value.strip() and not value.startswith('<'):
                _log_info(f"âœ… é€šè¿‡å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                return value.strip()

    # å¦‚æœæ˜¯å­—å…¸ç±»å‹
    if isinstance(video, dict):
        for key in path_attributes:
            if key in video and isinstance(video[key], str) and video[key].strip():
                _log_info(f"âœ… é€šè¿‡å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                return video[key].strip()

    # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œå°è¯•ç¬¬ä¸€ä¸ªå…ƒç´ 
    if isinstance(video, (list, tuple)) and len(video) > 0:
        first_item = video[0]
        if isinstance(first_item, str) and first_item.strip():
            _log_info(f"âœ… é€šè¿‡åˆ—è¡¨ç¬¬ä¸€ä¸ªå…ƒç´ è·å–è·¯å¾„: {first_item}")
            return first_item.strip()

    # å°è¯• get_stream_source æ–¹æ³•ï¼ˆComfyUI VideoFromFile å¯¹è±¡ï¼‰
    if hasattr(video, 'get_stream_source'):
        try:
            stream_source = video.get_stream_source()
            _log_info(f"ğŸ” è°ƒç”¨ get_stream_source è¿”å›: {type(stream_source)} = {stream_source}")

            # stream_source å¯èƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œå°è¯•æå–è·¯å¾„
            if isinstance(stream_source, str):
                if stream_source.strip() and not stream_source.startswith('<'):
                    _log_info(f"âœ… é€šè¿‡ get_stream_source è·å–è·¯å¾„: {stream_source}")
                    return stream_source.strip()
            elif hasattr(stream_source, 'path'):
                path = getattr(stream_source, 'path')
                if isinstance(path, str) and path.strip():
                    _log_info(f"âœ… é€šè¿‡ get_stream_source().path è·å–è·¯å¾„: {path}")
                    return path.strip()
            elif hasattr(stream_source, 'file_path'):
                path = getattr(stream_source, 'file_path')
                if isinstance(path, str) and path.strip():
                    _log_info(f"âœ… é€šè¿‡ get_stream_source().file_path è·å–è·¯å¾„: {path}")
                    return path.strip()
            elif hasattr(stream_source, 'filename'):
                path = getattr(stream_source, 'filename')
                if isinstance(path, str) and path.strip():
                    _log_info(f"âœ… é€šè¿‡ get_stream_source().filename è·å–è·¯å¾„: {path}")
                    return path.strip()

            # æ‰“å° stream_source çš„å±æ€§
            try:
                stream_attrs = dir(stream_source)
                _log_info(f"ğŸ” stream_source çš„å±æ€§: {[attr for attr in stream_attrs if not attr.startswith('_')]}")
            except:
                pass

        except Exception as e:
            _log_warning(f"âš ï¸ è°ƒç”¨ get_stream_source å¤±è´¥: {e}")

    # å°è¯•è°ƒç”¨å¯èƒ½çš„æ–¹æ³•ï¼ˆä½†ä¸åŒ…æ‹¬ __str__ï¼Œå› ä¸ºå®ƒå¯èƒ½è¿”å›å¯¹è±¡è¡¨ç¤ºï¼‰
    method_names = ['get_path', 'get_file_path', 'get_filename', 'to_string']
    for method_name in method_names:
        if hasattr(video, method_name):
            try:
                result = getattr(video, method_name)()
                _log_info(f"ğŸ” è°ƒç”¨æ–¹æ³• {method_name} è¿”å›: {type(result)} = {result}")
                if isinstance(result, str) and result.strip() and not result.startswith('<'):
                    _log_info(f"âœ… é€šè¿‡æ–¹æ³• {method_name} è·å–è·¯å¾„: {result}")
                    return result.strip()
            except Exception as e:
                _log_warning(f"âš ï¸ è°ƒç”¨æ–¹æ³• {method_name} å¤±è´¥: {e}")

    _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")
    _log_error(f"âŒ å¯¹è±¡å†…å®¹: {repr(video)}")
    return None

def create_video_path_wrapper(file_path):
    """åˆ›å»ºä¸€ä¸ªè§†é¢‘è·¯å¾„åŒ…è£…å™¨ï¼Œç”¨äºUtilNodeså…¼å®¹æ€§"""
    # ç›´æ¥è¿”å›æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ï¼Œè®©UtilNodesçš„os.path.basename()èƒ½æ­£å¸¸å·¥ä½œ
    return file_path

def extract_video_last_frame(video_path, output_path=None):
    """
    æå–è§†é¢‘çš„æœ€åä¸€å¸§å›¾åƒ

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºå›¾ç‰‡è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        str: è¾“å‡ºå›¾ç‰‡çš„è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        import subprocess
        import tempfile
        from pathlib import Path

        if not os.path.exists(video_path):
            _log_error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return None

        # å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if output_path is None:
            video_name = Path(video_path).stem
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{video_name}_last_frame_{int(time.time())}.jpg")

        _log_info(f"ğŸ¬ æ­£åœ¨æå–è§†é¢‘å°¾å¸§: {video_path}")

        # æ–¹æ³•1ï¼šä½¿ç”¨FFmpegçš„select=eofè¿‡æ»¤å™¨
        cmd1 = [
            'ffmpeg',
            '-i', video_path,           # è¾“å…¥è§†é¢‘
            '-vf', 'select=eof',        # é€‰æ‹©æœ€åä¸€å¸§
            '-vsync', 'vfr',            # å¯å˜å¸§ç‡
            '-frames:v', '1',           # åªè¾“å‡º1å¸§
            '-y',                       # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            output_path
        ]

        try:
            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=60
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {output_path}")
                return output_path
        except:
            pass

        # æ–¹æ³•2ï¼šå¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œä½¿ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
        _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•æå–å°¾å¸§...")

        # è·å–è§†é¢‘æ—¶é•¿
        duration_cmd = [
            'ffprobe',
            '-v', 'quiet',
            '-show_entries', 'format=duration',
            '-of', 'csv=p=0',
            video_path
        ]

        duration_result = subprocess.run(
            duration_cmd,
            capture_output=True,
            text=True,
            timeout=30
        )

        if duration_result.returncode == 0:
            try:
                duration = float(duration_result.stdout.strip())
                seek_time = max(0, duration - 0.1)  # æå–æœ€å0.1ç§’å‰çš„å¸§

                cmd2 = [
                    'ffmpeg',
                    '-ss', str(seek_time),
                    '-i', video_path,
                    '-frames:v', '1',
                    '-y',
                    output_path
                ]

                result = subprocess.run(
                    cmd2,
                    capture_output=True,
                    text=True,
                    timeout=60
                )

                if result.returncode == 0 and os.path.exists(output_path):
                    _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ (å¤‡ç”¨æ–¹æ³•): {output_path}")
                    return output_path
            except:
                pass

        _log_error("âŒ æ‰€æœ‰å°¾å¸§æå–æ–¹æ³•éƒ½å¤±è´¥äº†")
        return None

    except Exception as e:
        _log_error(f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}")
        return None

def merge_videos_with_ffmpeg(video_paths, output_path=None):
    """ä½¿ç”¨ffmpegåˆå¹¶å¤šä¸ªè§†é¢‘æ–‡ä»¶"""
    try:
        import subprocess
        import tempfile

        if not video_paths or len(video_paths) < 2:
            _log_warning("âš ï¸ è§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return video_paths[0] if video_paths else None

        # éªŒè¯æ‰€æœ‰è§†é¢‘æ–‡ä»¶å­˜åœ¨
        valid_paths = []
        for path in video_paths:
            if path and os.path.exists(path):
                valid_paths.append(path)
            else:
                _log_warning(f"âš ï¸ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {path}")

        if len(valid_paths) < 2:
            _log_warning("âš ï¸ æœ‰æ•ˆè§†é¢‘æ•°é‡ä¸è¶³ï¼Œæ— éœ€åˆå¹¶")
            return valid_paths[0] if valid_paths else None

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•
        if not output_path:
            timestamp = int(time.time())
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
            except ImportError:
                # æ¨æ–­ComfyUIè¾“å‡ºç›®å½•
                current_dir = os.path.dirname(os.path.abspath(__file__))
                path_parts = current_dir.split(os.sep)
                comfyui_root = None

                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
            except:
                import tempfile
                output_dir = tempfile.gettempdir()
            output_path = os.path.join(output_dir, f"merged_continuous_video_{timestamp}.mp4")

        _log_info(f"ğŸ¬ å¼€å§‹åˆå¹¶{len(valid_paths)}ä¸ªè§†é¢‘æ–‡ä»¶...")
        _log_info(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")

        # åˆ›å»ºffmpegè¾“å…¥æ–‡ä»¶åˆ—è¡¨
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False, encoding='utf-8') as f:
            for path in valid_paths:
                # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                abs_path = os.path.abspath(path).replace('\\', '/')
                f.write(f"file '{abs_path}'\n")
            input_list_path = f.name

        try:
            # æ„å»ºffmpegå‘½ä»¤
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', input_list_path,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµï¼Œä¸é‡æ–°ç¼–ç 
                '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œffmpegå‘½ä»¤: {' '.join(cmd)}")

            # æ‰§è¡Œffmpegå‘½ä»¤
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )

            if result.returncode == 0:
                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    _log_info(f"âœ… è§†é¢‘åˆå¹¶æˆåŠŸ: {output_path} (å¤§å°: {file_size} bytes)")
                    return output_path
                else:
                    _log_error("âŒ ffmpegæ‰§è¡ŒæˆåŠŸä½†è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
                    return None
            else:
                _log_error(f"âŒ ffmpegæ‰§è¡Œå¤±è´¥: {result.stderr}")
                return None

        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(input_list_path)
            except:
                pass

    except subprocess.TimeoutExpired:
        _log_error("âŒ ffmpegæ‰§è¡Œè¶…æ—¶")
        return None
    except FileNotFoundError:
        _log_error("âŒ æœªæ‰¾åˆ°ffmpegï¼Œè¯·ç¡®ä¿å·²å®‰è£…ffmpegå¹¶æ·»åŠ åˆ°PATH")
        return None
    except Exception as e:
        _log_error(f"âŒ è§†é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return None

def get_resolution_dimensions(resolution, aspect_ratio):
    """æ ¹æ®åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”è·å–å®é™…åƒç´ å°ºå¯¸

    Args:
        resolution: "480p", "720p", "1080p"
        aspect_ratio: "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"

    Returns:
        tuple: (width, height) æˆ– None
    """
    # Seedance 1.0 pro æ”¯æŒçš„åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”å¯¹åº”è¡¨
    resolution_map = {
        "480p": {
            "16:9": (864, 480),
            "4:3": (736, 544),
            "1:1": (640, 640),
            "3:4": (544, 736),
            "9:16": (480, 864),
            "21:9": (960, 416)
        },
        "720p": {
            "16:9": (1248, 704),
            "4:3": (1120, 832),
            "1:1": (960, 960),
            "3:4": (832, 1120),
            "9:16": (704, 1248),
            "21:9": (1504, 640)
        },
        "1080p": {
            "16:9": (1920, 1088),
            "4:3": (1664, 1248),
            "1:1": (1440, 1440),
            "3:4": (1248, 1664),
            "9:16": (1088, 1920),
            "21:9": (2176, 928)
        }
    }

    if resolution in resolution_map and aspect_ratio in resolution_map[resolution]:
        dimensions = resolution_map[resolution][aspect_ratio]
        _log_info(f"ğŸ” åˆ†è¾¨ç‡è®¡ç®—: {resolution} + {aspect_ratio} = {dimensions[0]}x{dimensions[1]}")
        return dimensions
    else:
        _log_warning(f"âš ï¸ ä¸æ”¯æŒçš„åˆ†è¾¨ç‡æˆ–å®½é«˜æ¯”ç»„åˆ: {resolution} + {aspect_ratio}")
        # è¿”å›é»˜è®¤å€¼
        default_dimensions = (1248, 704)  # 720p 16:9
        _log_info(f"ğŸ”§ ä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡: {default_dimensions[0]}x{default_dimensions[1]}")
        return default_dimensions

def create_blank_video_object(frames=30, height=512, width=512):
    """åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡ - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åˆ›å»ºVideoFromFile"""
    try:
        _log_info(f"ğŸ¬ åˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶: {frames}å¸§, {width}x{height}")

        # åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶
        temp_video_path = os.path.join(tempfile.gettempdir(), f"blank_video_{int(time.time())}.mp4")

        # ä½¿ç”¨OpenCVåˆ›å»ºç©ºç™½è§†é¢‘æ–‡ä»¶
        if HAS_CV2:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(temp_video_path, fourcc, 30.0, (width, height))

            # åˆ›å»ºé»‘è‰²å¸§
            blank_frame = np.zeros((height, width, 3), dtype=np.uint8)

            for _ in range(frames):
                out.write(blank_frame)

            out.release()
            _log_info(f"âœ… ç©ºç™½è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {temp_video_path}")
        else:
            # å¦‚æœæ²¡æœ‰OpenCVï¼Œåˆ›å»ºä¸€ä¸ªæœ€å°çš„MP4æ–‡ä»¶
            _log_warning("âš ï¸ æ²¡æœ‰OpenCVï¼Œåˆ›å»ºç®€å•çš„ç©ºç™½è§†é¢‘å¯¹è±¡")
            # è¿™é‡Œæˆ‘ä»¬ä»ç„¶éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„
            # ä½œä¸ºå›é€€ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè·¯å¾„
            temp_video_path = "blank_video.mp4"

        # åˆ›å»ºComfyUI VideoFromFileå¯¹è±¡
        video_obj = VideoFromFile(temp_video_path)
        return video_obj

    except Exception as e:
        _log_error(f"åˆ›å»ºç©ºç™½è§†é¢‘å¯¹è±¡å¤±è´¥: {e}")
        # æœ€åçš„å›é€€ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„VideoFromFileå¯¹è±¡
        return VideoFromFile("blank_video.mp4")


    """è°ƒç”¨Comfly API"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    # è°ƒè¯•ä¿¡æ¯
    _log_info(f"ğŸ” Comfly APIè°ƒç”¨:")
    _log_info(f"   - ç«¯ç‚¹: {api_url}/images/generations")
    _log_info(f"   - æ¨¡å‹: {payload.get('model', 'N/A')}")
    _log_info(f"   - åŒ…å«å›¾åƒ: {'image' in payload and bool(payload.get('image'))}")
    if 'image' in payload and payload.get('image'):
        _log_info(f"   - å›¾åƒæ•°é‡: {len(payload['image'])}")
        _log_info(f"   - ç¬¬ä¸€å¼ å›¾åƒé•¿åº¦: {len(payload['image'][0]) if payload['image'] else 0}")

    try:
        # ä½¿ç”¨SSLå…¼å®¹çš„session
        session = create_ssl_compatible_session()
        response = session.post(
            f"{api_url}/images/generations",
            headers=headers,
            json=payload,
            timeout=timeout
        )
        return response
    except Exception as e:
        _log_error(f"Comfly APIè°ƒç”¨å¤±è´¥: {e}")
        return None


    """è°ƒç”¨OpenAIå…¼å®¹API - æ”¯æŒT8å›¾åƒç¼–è¾‘"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯T8é•œåƒç«™
        if "t8star.cn" in api_url or "ai.t8star.cn" in api_url:
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒè¾“å…¥
            has_images = "image" in payload and payload["image"]

            # å¯¹äºT8ï¼Œå›¾ç”Ÿå›¾ä¹Ÿä½¿ç”¨images/generationsç«¯ç‚¹ï¼Œè€Œä¸æ˜¯chat/completions
            # åªæœ‰ç‰¹å®šçš„å›¾åƒç¼–è¾‘ä»»åŠ¡æ‰ä½¿ç”¨chat/completions
            use_chat_endpoint = False  # æš‚æ—¶ç¦ç”¨chatç«¯ç‚¹ï¼Œç»Ÿä¸€ä½¿ç”¨images/generations

            if has_images and use_chat_endpoint:
                # å›¾åƒç¼–è¾‘ï¼šä½¿ç”¨chat/completionsç«¯ç‚¹ï¼ˆæš‚æ—¶ç¦ç”¨ï¼‰
                url = "https://ai.t8star.cn/v1/chat/completions"
                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘ç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç¼–è¾‘çš„payloadæ ¼å¼
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": payload.get("prompt", "")
                            }
                        ]
                    }
                ]

                # æ·»åŠ å›¾åƒåˆ°æ¶ˆæ¯ä¸­
                image_urls = payload.get("image", [])
                if isinstance(image_urls, str):
                    image_urls = [image_urls]

                for image_url in image_urls:
                    messages[0]["content"].append({
                        "type": "image_url",
                        "image_url": {
                            "url": image_url
                        }
                    })

                t8_payload = {
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "messages": messages,
                    "max_tokens": 4096,
                    "temperature": 0.7
                }

                _log_info(f"ğŸ¨ T8å›¾åƒç¼–è¾‘è¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æ¶ˆæ¯æ•°={len(t8_payload.get('messages', []))}")

            else:
                # å›¾åƒç”Ÿæˆï¼šä½¿ç”¨images/generationsç«¯ç‚¹
                url = "https://ai.t8star.cn/v1/images/generations"
                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")

                # æ„å»ºT8å›¾åƒç”Ÿæˆçš„payloadæ ¼å¼
                t8_payload = {
                    "prompt": payload.get("prompt", ""),
                    "model": payload.get("model", "doubao-seedream-4-0-250828"),
                    "response_format": payload.get("response_format", "url")
                }

                # æ·»åŠ å¯é€‰å‚æ•°
                if "size" in payload:
                    t8_payload["size"] = payload["size"]
                if "n" in payload:
                    t8_payload["n"] = payload["n"]
                if "seed" in payload and payload["seed"] != -1:
                    t8_payload["seed"] = payload["seed"]
                if "watermark" in payload:
                    t8_payload["watermark"] = payload["watermark"]
                if "tail_on_partial" in payload:
                    t8_payload["tail_on_partial"] = payload["tail_on_partial"]

                # æ·»åŠ å›¾åƒè¾“å…¥æ”¯æŒï¼ˆå›¾ç”Ÿå›¾ï¼‰
                if has_images:
                    t8_payload["image"] = payload["image"]
                    _log_info(f"ğŸ–¼ï¸ T8å›¾ç”Ÿå›¾è¯·æ±‚: åŒ…å« {len(payload['image'])} å¼ è¾“å…¥å›¾åƒ")
                    _log_info(f"ğŸ” å›¾åƒæ•°æ®ç±»å‹: {type(payload['image'])}")
                    if payload['image']:
                        _log_info(f"ğŸ” ç¬¬ä¸€å¼ å›¾åƒæ•°æ®é•¿åº¦: {len(payload['image'][0]) if payload['image'][0] else 0} å­—ç¬¦")

                _log_info(f"ğŸ–¼ï¸ T8å›¾åƒç”Ÿæˆè¯·æ±‚: æ¨¡å‹={t8_payload.get('model')}, æç¤ºè¯é•¿åº¦={len(t8_payload.get('prompt', ''))}")

        elif api_url.endswith('/v1/chat/completions'):
            url = api_url.replace('/v1/chat/completions', '/v1/images/generations')
            _log_info(f"ğŸ”— è½¬æ¢èŠå¤©ç«¯ç‚¹ä¸ºå›¾åƒç”Ÿæˆç«¯ç‚¹: {url}")
            t8_payload = payload
        else:
            # å…¶ä»–OpenAIå…¼å®¹API
            url = f"{api_url}/v1/images/generations"
            _log_info(f"ğŸ”— ä½¿ç”¨æ ‡å‡†OpenAIç«¯ç‚¹: {url}")
            t8_payload = payload

        # å°è¯•å¤šç§è¿æ¥æ–¹å¼è§£å†³SSLé—®é¢˜
        response = None
        last_error = None

        # æ–¹æ³•1ï¼šç¦ç”¨æ‰€æœ‰SSLéªŒè¯çš„ç®€å•æ–¹å¼
        try:
            import urllib3
            urllib3.disable_warnings()

            # è®¾ç½®ç¯å¢ƒå˜é‡ç¦ç”¨SSLéªŒè¯
            import os
            os.environ['PYTHONHTTPSVERIFY'] = '0'
            os.environ['CURL_CA_BUNDLE'] = ''

            response = requests.post(
                url,
                headers=headers,
                json=t8_payload,
                timeout=timeout,
                verify=False,
                stream=False
            )
            _log_info(f"âœ… ç®€å•SSLç¦ç”¨æ–¹å¼æˆåŠŸ")

        except Exception as simple_error:
            last_error = simple_error
            _log_warning(f"ç®€å•SSLç¦ç”¨å¤±è´¥: {simple_error}")

            # æ–¹æ³•2ï¼šä½¿ç”¨SSLå…¼å®¹çš„session
            try:
                session = create_ssl_compatible_session()
                response = session.post(
                    url,
                    headers=headers,
                    json=t8_payload,
                    timeout=timeout
                )
                _log_info(f"âœ… SSLå…¼å®¹sessionæˆåŠŸ")

            except Exception as ssl_error:
                last_error = ssl_error
                _log_warning(f"SSLå…¼å®¹sessionå¤±è´¥: {ssl_error}")

                # æ–¹æ³•3ï¼šä½¿ç”¨curlä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
                try:
                    import subprocess
                    import tempfile

                    # å°†payloadå†™å…¥ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                        json.dump(t8_payload, f)
                        temp_file = f.name

                    # æ„å»ºcurlå‘½ä»¤
                    curl_cmd = [
                        'curl', '-k', '-X', 'POST',
                        '-H', 'Content-Type: application/json',
                        '-H', f'Authorization: Bearer {headers["Authorization"].split(" ")[1]}',
                        '-d', f'@{temp_file}',
                        '--connect-timeout', '30',
                        '--max-time', str(timeout),
                        url
                    ]

                    result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=timeout)

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(temp_file)

                    if result.returncode == 0:
                        # åˆ›å»ºæ¨¡æ‹Ÿresponseå¯¹è±¡
                        class MockResponse:
                            def __init__(self, text, status_code=200):
                                self.text = text
                                self.status_code = status_code
                            def json(self):
                                return json.loads(self.text)

                        response = MockResponse(result.stdout)
                        _log_info(f"âœ… curlå¤‡ç”¨æ–¹æ¡ˆæˆåŠŸ")
                    else:
                        raise Exception(f"curlå¤±è´¥: {result.stderr}")

                except Exception as curl_error:
                    _log_warning(f"curlå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {curl_error}")
                    raise last_error  # æŠ›å‡ºæœ€åä¸€ä¸ªé”™è¯¯

        _log_info(f"ğŸ” T8 APIå“åº”çŠ¶æ€: {response.status_code}")
        if response.status_code != 200:
            _log_error(f"âŒ T8 APIé”™è¯¯: {response.status_code} - {response.text}")

        return response

    except Exception as e:
        _log_error(f"OpenAIå…¼å®¹APIè°ƒç”¨å¤±è´¥: {e}")
        return None


    """Doubao-Seedanceå¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆèŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        config = get_seedream4_config()
        mirror_sites = config.get('mirror_sites', {})
        mirror_options = list(mirror_sites.keys())

        return {
            "required": {
                "prompt": ("STRING", {"multiline": True, "default": "ä¸€ä¸ªç¾ä¸½çš„åœºæ™¯ï¼ŒåŒ…å«[å›¾1]å’Œ[å›¾2]çš„å…ƒç´ "}),
                "mirror_site": (mirror_options, {"default": mirror_options[0]}),
                "model": (["doubao-seedance-1-0-lite-i2v-250428"], {"default": "doubao-seedance-1-0-lite-i2v-250428"}),
                "duration": (["3s", "5s", "10s", "12s"], {"default": "5s"}),
                "resolution": (["480p", "720p"], {"default": "720p"}),
                "aspect_ratio": (["16:9", "4:3", "1:1", "3:4", "9:16", "21:9", "adaptive"], {"default": "16:9"}),
                "fps": ([24, 30], {"default": 30}),
                "watermark": ("BOOLEAN", {"default": False}),
                "camera_fixed": ("BOOLEAN", {"default": False}),
                "api_key": ("STRING", {"default": ""}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2147483647}),
            },
            "optional": {
                "reference_image_1": ("IMAGE",),
                "reference_image_2": ("IMAGE",),
                "reference_image_3": ("IMAGE",),
                "reference_image_4": ("IMAGE",),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "STRING", "STRING", "VIDEO")
    RETURN_NAMES = ("video", "video_url", "response_text", "video_info", "AFVIDEO")
    FUNCTION = "generate_multi_ref_video"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 900  # 15åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘ç”Ÿæˆéœ€è¦æ›´é•¿æ—¶é—´
        self.max_retries = 3

    def generate_multi_ref_video(self, prompt, mirror_site, model, duration, resolution, aspect_ratio, fps, watermark=False, camera_fixed=False, api_key="", seed=-1,
                                reference_image_1=None, reference_image_2=None, reference_image_3=None, reference_image_4=None):
        """ç”Ÿæˆå¤šå›¾å‚è€ƒè§†é¢‘"""

        # æ”¶é›†å‚è€ƒå›¾ç‰‡
        reference_images = []
        if reference_image_1 is not None:
            reference_images.append(reference_image_1)
        if reference_image_2 is not None:
            reference_images.append(reference_image_2)
        if reference_image_3 is not None:
            reference_images.append(reference_image_3)
        if reference_image_4 is not None:
            reference_images.append(reference_image_4)

        if not reference_images:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦æä¾›ä¸€å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        if len(reference_images) > 4:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœ€å¤šæ”¯æŒ4å¼ å‚è€ƒå›¾ç‰‡", "", blank_video_path)

        _log_info(f"ğŸ” å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆ: å‚è€ƒå›¾ç‰‡æ•°é‡={len(reference_images)}")

        # è·å–é•œåƒç«™é…ç½®
        site_config = get_mirror_site_config(mirror_site)
        api_url = site_config.get("url", "").strip()
        api_format = site_config.get("api_format", "comfly")

        # å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™çš„APIæ ¼å¼ï¼ˆç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®ï¼‰
        if mirror_site == "t8_mirror" or "t8star.cn" in api_url:
            api_format = "volcengine"
            _log_info(f"ğŸ”§ å¼ºåˆ¶ä¿®æ­£T8é•œåƒç«™APIæ ¼å¼ä¸º: {api_format}")

        # ä½¿ç”¨é•œåƒç«™çš„API keyï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
        if site_config.get("api_key") and not api_key.strip():
            api_key = site_config["api_key"]
            _log_info(f"ğŸ”‘ è‡ªåŠ¨ä½¿ç”¨é•œåƒç«™API Key: {api_key[:8]}...")

        if not api_key.strip():
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ é”™è¯¯ï¼šæœªæä¾›API Key", "", blank_video_path)

        try:
            # å¤šå›¾å‚è€ƒæ”¯æŒç«å±±å¼•æ“æ ¼å¼å’ŒComflyå®˜æ–¹æ ¼å¼
            if api_format not in ["volcengine", "comfly"]:
                _log_warning(f"âš ï¸ å¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å’ŒComflyæ ¼å¼ï¼Œå½“å‰æ ¼å¼: {api_format}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šå¤šå›¾å‚è€ƒåŠŸèƒ½ä»…æ”¯æŒç«å±±å¼•æ“å®˜æ–¹ã€T8é•œåƒç«™å’ŒComflyé•œåƒç«™", "", blank_video_path)

            # æ„å»ºç»Ÿä¸€çš„contentæ•°ç»„æ ¼å¼ï¼ˆç«å±±å¼•æ“å’ŒComflyå®˜æ–¹æ ¼å¼ç›¸åŒï¼‰
            _log_info(f"ğŸ”§ æ„å»ºå¤šå›¾å‚è€ƒ{api_format}æ ¼å¼payload")

            # æ„å»ºæ–‡æœ¬å†…å®¹
            if api_format == "volcengine":
                # ç«å±±å¼•æ“æ ¼å¼ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
                text_content = f"{prompt} --rt {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")
            else:  # api_format == "comfly"
                # Comflyå®˜æ–¹æ ¼å¼ï¼šä¹Ÿä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆä¸ç«å±±å¼•æ“ç›¸åŒï¼‰
                text_content = f"{prompt} --ratio {aspect_ratio} --dur {duration.replace('s', '')} --fps {fps} --rs {resolution}"
                if seed != -1:
                    text_content += f" --seed {seed}"
                # æ·»åŠ watermarkå’Œcamera_fixedå‚æ•°
                text_content += f" --wm {str(watermark).lower()} --cf {str(camera_fixed).lower()}"
                _log_info(f"ğŸ”§ Comflyå®˜æ–¹å¤šå›¾å‚è€ƒæ–‡æœ¬å†…å®¹: {text_content}")

            content = [
                {
                    "type": "text",
                    "text": text_content
                }
            ]

            # æ·»åŠ å‚è€ƒå›¾ç‰‡åˆ°contentæ•°ç»„
            for i, ref_image in enumerate(reference_images, 1):
                _log_info(f"ğŸ” å¤„ç†å‚è€ƒå›¾ç‰‡ {i}: {ref_image.shape}")

                # ç»Ÿä¸€ä½¿ç”¨å®Œæ•´çš„Data URLæ ¼å¼
                image_data_url = image_to_base64(ref_image, return_data_url=True)
                if image_data_url:
                    image_content = {
                        "type": "image_url",
                        "image_url": {
                            "url": image_data_url
                        }
                    }

                    # å¤šå›¾å‚è€ƒç»Ÿä¸€ä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ï¼Œéƒ½éœ€è¦roleå­—æ®µ
                    image_content["role"] = "reference_image"

                    content.append(image_content)
                    _log_info(f"ğŸ”§ æ·»åŠ å‚è€ƒå›¾ç‰‡{i}åˆ°content (Data URLé•¿åº¦: {len(image_data_url)})")
                else:
                    _log_error(f"âŒ å‚è€ƒå›¾ç‰‡{i} Data URLç¼–ç å¤±è´¥")

            # æ„å»ºpayload
            payload = {
                "model": model,
                "content": content
            }

            _log_info(f"ğŸ” å¤šå›¾å‚è€ƒpayloadæ„å»ºå®Œæˆ: æ ¼å¼={api_format}, æ¨¡å‹={model}, contentæ•°é‡={len(content)}")

            # è°ƒç”¨å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆAPIï¼ˆä½¿ç”¨ç«å±±å¼•æ“æ ¼å¼ç«¯ç‚¹ï¼‰
            response = call_multi_ref_video_api(api_url, api_key, payload, api_format, self.timeout)

            if not response or response.status_code != 200:
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", "âŒ é”™è¯¯ï¼šè§†é¢‘ç”Ÿæˆä»»åŠ¡åˆ›å»ºå¤±è´¥", "", blank_video_path)

            # ä»å“åº”ä¸­æå–ä»»åŠ¡ID
            try:
                result = response.json()
                task_id = None

                # ç«å±±å¼•æ“æ ¼å¼çš„ä»»åŠ¡IDæå–
                if "id" in result:
                    task_id = result["id"]
                elif "task_id" in result:
                    task_id = result["task_id"]
                elif "data" in result and isinstance(result["data"], dict):
                    if "id" in result["data"]:
                        task_id = result["data"]["id"]
                    elif "task_id" in result["data"]:
                        task_id = result["data"]["task_id"]

                if not task_id:
                    _log_error(f"âŒ æ— æ³•ä»å“åº”ä¸­æå–ä»»åŠ¡ID: {result}")
                    blank_video = create_blank_video_object()
                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                    return (blank_video, "", "âŒ é”™è¯¯ï¼šæ— æ³•è·å–ä»»åŠ¡ID", "", blank_video_path)

                _log_info(f"ğŸ¬ å¤šå›¾å‚è€ƒè§†é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_id}")

            except Exception as e:
                _log_error(f"âŒ è§£æä»»åŠ¡åˆ›å»ºå“åº”å¤±è´¥: {e}")
                blank_video = create_blank_video_object()
                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                return (blank_video, "", f"âŒ é”™è¯¯ï¼šè§£æå“åº”å¤±è´¥: {str(e)}", "", blank_video_path)

            # è½®è¯¢ä»»åŠ¡çŠ¶æ€
            max_polls = 90  # 15åˆ†é’Ÿï¼Œæ¯10ç§’è½®è¯¢ä¸€æ¬¡
            poll_interval = 10

            for poll_count in range(1, max_polls + 1):
                _log_info(f"ğŸ” è½®è¯¢ä»»åŠ¡çŠ¶æ€ ({poll_count}/{max_polls})")

                status_response = call_video_task_status(api_url, api_key, task_id, api_format)
                status_result = None
                if status_response and status_response.status_code == 200:
                    status_result = status_response.json()
                    _log_info(f"ğŸ” ä»»åŠ¡çŠ¶æ€å“åº”: {str(status_result)[:200]}...")

                if status_result:
                    status = status_result.get('status', 'unknown')
                    _log_info(f"ğŸ” å½“å‰ä»»åŠ¡çŠ¶æ€: '{status}' (ç±»å‹: {type(status)})")

                    if status.lower() in ["completed", "success", "finished", "succeeded"] or status in ["SUCCESS", "COMPLETED", "FINISHED", "SUCCEEDED"]:
                        _log_info(f"âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ")

                        # è·å–è§†é¢‘URL - æ”¯æŒå¤šç§å“åº”æ ¼å¼
                        video_url = None

                        # æ ¼å¼1: data.content.video_url (Comflyå¤šå›¾å‚è€ƒæ ¼å¼)
                        if 'data' in status_result and isinstance(status_result['data'], dict):
                            if 'content' in status_result['data'] and isinstance(status_result['data']['content'], dict):
                                if 'video_url' in status_result['data']['content']:
                                    video_url = status_result['data']['content']['video_url']

                        # æ ¼å¼2: content.video_url (ç«å±±å¼•æ“å¤šå›¾å‚è€ƒæ ¼å¼)
                        if not video_url and 'content' in status_result and isinstance(status_result['content'], dict):
                            if 'video_url' in status_result['content']:
                                video_url = status_result['content']['video_url']

                        # æ ¼å¼3: video_resultæ•°ç»„æ ¼å¼
                        if not video_url and 'video_result' in status_result and status_result['video_result']:
                            video_result = status_result['video_result'][0] if isinstance(status_result['video_result'], list) else status_result['video_result']
                            video_url = video_result.get('url')

                        # æ ¼å¼4: ç›´æ¥video_urlå­—æ®µ
                        if not video_url and 'video_url' in status_result:
                            video_url = status_result['video_url']

                        # æ ¼å¼4: result.video_urlæ ¼å¼
                        if not video_url and 'result' in status_result and status_result['result']:
                            result = status_result['result']
                            if isinstance(result, dict) and 'video_url' in result:
                                video_url = result['video_url']
                                _log_info(f"ğŸ” ä»result.video_urlæå–è§†é¢‘URL")

                        if video_url:
                            _log_info(f"ğŸ¬ è·å–åˆ°è§†é¢‘URL: {video_url}")

                            # ä¸‹è½½å¹¶è½¬æ¢è§†é¢‘
                            video_path = download_video_from_url(video_url)
                            if video_path:
                                _log_info(f"ğŸ¬ å¼€å§‹è½¬æ¢è§†é¢‘ä¸ºComfyUIå¯¹è±¡...")
                                video_obj = video_to_comfyui_video(video_path)
                                if video_obj is not None:
                                    video_info = f"æ¨¡å‹: {model}, å‚è€ƒå›¾ç‰‡: {len(reference_images)}å¼ , æ—¶é•¿: {duration}, åˆ†è¾¨ç‡: {resolution}, å®½é«˜æ¯”: {aspect_ratio}, å¸§ç‡: {fps}fps, ä»»åŠ¡ID: {task_id}"
                                    return (video_obj, video_url, "âœ… å¤šå›¾å‚è€ƒè§†é¢‘ç”ŸæˆæˆåŠŸ", video_info, video_path)
                                else:
                                    _log_error("âŒ è§†é¢‘è½¬æ¢å¤±è´¥")
                                    blank_video = create_blank_video_object()
                                    blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                    return (blank_video, video_url, "âŒ è§†é¢‘è½¬æ¢å¤±è´¥", "", blank_video_path)
                            else:
                                _log_error("âŒ è§†é¢‘ä¸‹è½½å¤±è´¥")
                                blank_video = create_blank_video_object()
                                blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                                return (blank_video, video_url, "âŒ è§†é¢‘ä¸‹è½½å¤±è´¥", "", blank_video_path)
                        else:
                            _log_error("âŒ æœªè·å–åˆ°è§†é¢‘URL")
                            blank_video = create_blank_video_object()
                            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                            return (blank_video, "", "âŒ æœªè·å–åˆ°è§†é¢‘URL", "", blank_video_path)

                    elif status.lower() in ["failed", "error"] or status in ["FAILED", "ERROR"]:
                        fail_reason = status_result.get('fail_reason', 'æœªçŸ¥é”™è¯¯')
                        _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}")
                        blank_video = create_blank_video_object()
                        blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
                        return (blank_video, "", f"âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥: {fail_reason}", "", blank_video_path)

                    elif status.lower() in ["running", "processing", "in_progress", "not_start", "queued"] or status in ["RUNNING", "PROCESSING", "IN_PROGRESS", "NOT_START", "QUEUED"]:
                        _log_info(f"â³ ä»»åŠ¡è¿›è¡Œä¸­ï¼ŒçŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                    else:
                        _log_warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {status}")
                        if poll_count < max_polls:
                            time.sleep(poll_interval)
                        continue
                else:
                    _log_warning(f"âš ï¸ æ— æ³•è·å–ä»»åŠ¡çŠ¶æ€ï¼Œå“åº”: {status_response}")
                    if poll_count < max_polls:
                        time.sleep(poll_interval)
                    continue

            # è¶…æ—¶å¤„ç†
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆè¶…æ—¶")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", "âŒ è§†é¢‘ç”Ÿæˆè¶…æ—¶", "", blank_video_path)

        except Exception as e:
            _log_error(f"âŒ å¤šå›¾å‚è€ƒè§†é¢‘ç”Ÿæˆå¼‚å¸¸: {e}")
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            return (blank_video, "", f"âŒ é”™è¯¯ï¼š{str(e)}", "", blank_video_path)

class VideoStitchingNode:
    """è§†é¢‘æ‹¼æ¥èŠ‚ç‚¹ - æœ€å¤šå¯ä»¥å°†8ä¸ªè§†é¢‘æ‹¼æ¥åœ¨ä¸€èµ·"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video1": ("VIDEO",),
            },
            "optional": {
                "video2": ("VIDEO",),
                "video3": ("VIDEO",),
                "video4": ("VIDEO",),
                "video5": ("VIDEO",),
                "video6": ("VIDEO",),
                "video7": ("VIDEO",),
                "video8": ("VIDEO",),
                "output_filename": ("STRING", {"default": ""}),
                "stitch_method": (["concat", "concat_crossfade", "concat_advanced", "concat_morph", "concat_optical_flow", "hstack", "vstack", "grid2x2", "grid2x3", "grid2x4"], {"default": "concat"}),
                "output_quality": (["high", "medium", "low"], {"default": "high"}),
                "scale_videos": ("BOOLEAN", {"default": True}),
                "smooth_transitions": ("BOOLEAN", {"default": True}),
                "transition_duration": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 2.0, "step": 0.1}),
                "force_keyframes": ("BOOLEAN", {"default": True}),
                "transition_type": (["fade", "wipeleft", "wiperight", "wipeup", "wipedown", "slideleft", "slideright", "slideup", "slidedown", "smoothleft", "smoothright", "smoothup", "smoothdown", "circleopen", "circleclose", "vertopen", "vertclose", "horzopen", "horzclose", "dissolve", "pixelize", "radial", "smoothradial"], {"default": "fade"}),
                "motion_compensation": ("BOOLEAN", {"default": False}),
                "edge_enhancement": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING", "VIDEO")
    RETURN_NAMES = ("stitched_video", "video_path", "AFVIDEO")
    FUNCTION = "stitch_videos"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 300  # 5åˆ†é’Ÿè¶…æ—¶ï¼Œè§†é¢‘å¤„ç†éœ€è¦æ›´é•¿æ—¶é—´

    def stitch_videos(self, video1, video2=None, video3=None, video4=None, video5=None, video6=None, video7=None, video8=None,
                     output_filename="", stitch_method="concat", output_quality="high", scale_videos=True,
                     smooth_transitions=True, transition_duration=0.5, force_keyframes=True, transition_type="fade",
                     motion_compensation=False, edge_enhancement=False):
        """
        æ‹¼æ¥å¤šä¸ªè§†é¢‘

        Args:
            video1-video8: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            stitch_method: æ‹¼æ¥æ–¹æ³•
            output_quality: è¾“å‡ºè´¨é‡
            scale_videos: æ˜¯å¦ç¼©æ”¾è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸

        Returns:
            tuple: (æ‹¼æ¥åçš„VIDEOå¯¹è±¡, è§†é¢‘æ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹è§†é¢‘æ‹¼æ¥...")

            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„è§†é¢‘
            videos = [video1]
            for video in [video2, video3, video4, video5, video6, video7, video8]:
                if video is not None:
                    videos.append(video)

            if len(videos) < 2:
                error_msg = "è‡³å°‘éœ€è¦2ä¸ªè§†é¢‘æ‰èƒ½è¿›è¡Œæ‹¼æ¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            _log_info(f"ğŸ“Š å°†æ‹¼æ¥{len(videos)}ä¸ªè§†é¢‘ï¼Œä½¿ç”¨{stitch_method}æ–¹æ³•")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„
            video_paths = []
            for i, video in enumerate(videos):
                _log_info(f"ğŸ” å¤„ç†ç¬¬{i+1}ä¸ªè§†é¢‘...")
                video_path = self._extract_video_path(video)
                if not video_path:
                    error_msg = f"æ— æ³•è·å–ç¬¬{i+1}ä¸ªè§†é¢‘çš„æœ‰æ•ˆè·¯å¾„: {video_path}"
                    _log_error(error_msg)
                    _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                    return self._create_error_result(error_msg)

                if not os.path.exists(video_path):
                    error_msg = f"ç¬¬{i+1}ä¸ªè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                    _log_error(error_msg)
                    return self._create_error_result(error_msg)

                video_paths.append(video_path)
                _log_info(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                output_filename = f"stitched_video_{stitch_method}_{int(time.time())}.mp4"

            if not output_filename.lower().endswith('.mp4'):
                output_filename += '.mp4'

            # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•è€Œä¸æ˜¯ç³»ç»Ÿä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                output_dir = folder_paths.get_output_directory()
                _log_info(f"ğŸ“ ä½¿ç”¨ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
            except ImportError:
                # å¦‚æœåœ¨ComfyUIç¯å¢ƒå¤–ï¼Œå°è¯•æ¨æ–­ComfyUIè·¯å¾„
                current_dir = os.path.dirname(os.path.abspath(__file__))
                comfyui_root = None

                # å‘ä¸ŠæŸ¥æ‰¾ComfyUIæ ¹ç›®å½•
                path_parts = current_dir.split(os.sep)
                for i in range(len(path_parts) - 1, -1, -1):
                    potential_root = os.sep.join(path_parts[:i+1])
                    if os.path.exists(os.path.join(potential_root, "main.py")) and \
                       os.path.exists(os.path.join(potential_root, "nodes.py")):
                        comfyui_root = potential_root
                        break

                if comfyui_root:
                    output_dir = os.path.join(comfyui_root, "output")
                    os.makedirs(output_dir, exist_ok=True)
                    _log_info(f"ğŸ“ æ¨æ–­ComfyUIè¾“å‡ºç›®å½•: {output_dir}")
                else:
                    import tempfile
                    output_dir = tempfile.gettempdir()
                    _log_info(f"ğŸ“ å›é€€åˆ°ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir}")
            except Exception as e:
                import tempfile
                output_dir = tempfile.gettempdir()
                _log_info(f"ğŸ“ å¼‚å¸¸ï¼Œä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•: {output_dir} (é”™è¯¯: {e})")

            output_path = os.path.join(output_dir, output_filename)

            # æ ¹æ®æ‹¼æ¥æ–¹æ³•æ‰§è¡Œä¸åŒçš„å¤„ç†
            success = False
            if stitch_method == "concat":
                success = self._concat_videos(video_paths, output_path, output_quality, smooth_transitions, transition_duration, force_keyframes)
            elif stitch_method == "concat_crossfade":
                if len(video_paths) <= 2:
                    success = self._concat_with_crossfade_transitions(video_paths, output_path, output_quality, transition_duration)
                else:
                    success = self._concat_with_xfade_multiple(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "concat_advanced":
                success = self._concat_with_advanced_transitions(video_paths, output_path, output_quality, transition_duration, transition_type, motion_compensation, edge_enhancement)
            elif stitch_method == "concat_morph":
                success = self._concat_with_morphing_transitions(video_paths, output_path, output_quality, transition_duration, motion_compensation)
            elif stitch_method == "concat_optical_flow":
                success = self._concat_with_optical_flow_transitions(video_paths, output_path, output_quality, transition_duration)
            elif stitch_method == "hstack":
                success = self._hstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "vstack":
                success = self._vstack_videos(video_paths, output_path, output_quality, scale_videos)
            elif stitch_method == "grid2x2":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x2", scale_videos)
            elif stitch_method == "grid2x3":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x3", scale_videos)
            elif stitch_method == "grid2x4":
                success = self._grid_videos(video_paths, output_path, output_quality, "2x4", scale_videos)

            if not success:
                error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥ï¼Œæ–¹æ³•: {stitch_method}"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

            # è½¬æ¢ä¸ºComfyUI VIDEOå¯¹è±¡
            stitched_video = video_to_comfyui_video(output_path)
            if stitched_video:
                stitched_video.file_path = output_path
                _log_info(f"âœ… è§†é¢‘æ‹¼æ¥æˆåŠŸ: {output_path}")

                # AFVIDEOä½¿ç”¨è·¯å¾„åŒ…è£…å™¨ï¼Œä¸æ ‡å‡†è§†é¢‘èŠ‚ç‚¹ä¿æŒä¸€è‡´
                afvideo = create_video_path_wrapper(output_path) if output_path else create_blank_video_object()

                return (stitched_video, output_path, afvideo)
            else:
                error_msg = "æ‹¼æ¥è§†é¢‘è½¬æ¢ä¸ºComfyUIå¯¹è±¡å¤±è´¥"
                _log_error(error_msg)
                return self._create_error_result(error_msg)

        except Exception as e:
            error_msg = f"è§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            return self._create_error_result(error_msg)

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _get_quality_params(self, quality):
        """è·å–è´¨é‡å‚æ•°"""
        quality_settings = {
            "high": ["-crf", "18", "-preset", "medium"],
            "medium": ["-crf", "23", "-preset", "fast"],
            "low": ["-crf", "28", "-preset", "faster"]
        }
        return quality_settings.get(quality, quality_settings["high"])

    def _concat_videos(self, video_paths, output_path, quality, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """è¿ç»­æ‹¼æ¥è§†é¢‘ï¼ˆæ—¶é—´è½´ä¸Šè¿æ¥ï¼‰- æ”¹è¿›ç‰ˆæœ¬å‡å°‘é—ªçƒ"""
        try:
            import subprocess
            import tempfile

            _log_info("ğŸ”— ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            # é¦–å…ˆæ£€æŸ¥è§†é¢‘å±æ€§ä¸€è‡´æ€§
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§")
                return False

            # åˆ›å»ºconcatæ–‡ä»¶åˆ—è¡¨ - ä½¿ç”¨åˆé€‚çš„ä¸´æ—¶ç›®å½•
            try:
                import folder_paths
                temp_dir = folder_paths.get_temp_directory()
            except:
                import tempfile
                temp_dir = tempfile.gettempdir()
            concat_file = os.path.join(temp_dir, f"concat_list_{int(time.time())}.txt")

            with open(concat_file, 'w', encoding='utf-8') as f:
                for video_path in video_paths:
                    # ä½¿ç”¨ç»å¯¹è·¯å¾„å¹¶è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
                    abs_path = os.path.abspath(video_path).replace('\\', '/')
                    f.write(f"file '{abs_path}'\n")

            # æ ¹æ®è§†é¢‘å±æ€§ä¸€è‡´æ€§é€‰æ‹©å¤„ç†æ–¹å¼
            if video_info['consistent']:
                # å±æ€§ä¸€è‡´ï¼Œå°è¯•ç›´æ¥å¤åˆ¶æµï¼ˆæœ€å¿«ï¼Œæ— è´¨é‡æŸå¤±ï¼‰
                success = self._concat_with_copy(concat_file, output_path)
                if success:
                    self._cleanup_temp_file(concat_file)
                    return True
                _log_info("ğŸ”„ ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œå°è¯•é‡æ–°ç¼–ç ...")

            # å±æ€§ä¸ä¸€è‡´æˆ–ç›´æ¥å¤åˆ¶å¤±è´¥ï¼Œä½¿ç”¨æ”¹è¿›çš„é‡æ–°ç¼–ç æ–¹æ³•
            success = self._concat_with_smooth_transitions(concat_file, output_path, quality, video_info, smooth_transitions, transition_duration, force_keyframes)

            self._cleanup_temp_file(concat_file)
            return success

        except Exception as e:
            _log_error(f"concatæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _analyze_video_properties(self, video_paths):
        """åˆ†æè§†é¢‘å±æ€§ï¼Œæ£€æŸ¥ä¸€è‡´æ€§"""
        try:
            import subprocess
            import json

            _log_info("ğŸ” åˆ†æè§†é¢‘å±æ€§...")

            video_props = []
            for video_path in video_paths:
                # ä½¿ç”¨ffprobeè·å–è§†é¢‘ä¿¡æ¯
                cmd = [
                    'ffprobe',
                    '-v', 'quiet',
                    '-print_format', 'json',
                    '-show_streams',
                    '-select_streams', 'v:0',
                    video_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                if result.returncode != 0:
                    _log_error(f"æ— æ³•è·å–è§†é¢‘ä¿¡æ¯: {video_path}")
                    return None

                try:
                    info = json.loads(result.stdout)
                    if 'streams' in info and len(info['streams']) > 0:
                        stream = info['streams'][0]
                        props = {
                            'width': stream.get('width', 0),
                            'height': stream.get('height', 0),
                            'fps': eval(stream.get('r_frame_rate', '0/1')),
                            'codec': stream.get('codec_name', ''),
                            'pix_fmt': stream.get('pix_fmt', '')
                        }
                        video_props.append(props)
                        _log_info(f"ğŸ“Š {os.path.basename(video_path)}: {props['width']}x{props['height']} @{props['fps']:.2f}fps {props['codec']}")
                    else:
                        _log_error(f"æ— æ³•è§£æè§†é¢‘æµä¿¡æ¯: {video_path}")
                        return None
                except json.JSONDecodeError:
                    _log_error(f"æ— æ³•è§£æffprobeè¾“å‡º: {video_path}")
                    return None

            # æ£€æŸ¥å±æ€§ä¸€è‡´æ€§
            if not video_props:
                return None

            first_props = video_props[0]
            consistent = all(
                props['width'] == first_props['width'] and
                props['height'] == first_props['height'] and
                abs(props['fps'] - first_props['fps']) < 0.1 and
                props['codec'] == first_props['codec'] and
                props['pix_fmt'] == first_props['pix_fmt']
                for props in video_props
            )

            _log_info(f"âœ… è§†é¢‘å±æ€§ä¸€è‡´æ€§: {'æ˜¯' if consistent else 'å¦'}")

            return {
                'consistent': consistent,
                'properties': video_props,
                'target_width': first_props['width'],
                'target_height': first_props['height'],
                'target_fps': first_props['fps'],
                'target_codec': first_props['codec'],
                'target_pix_fmt': first_props['pix_fmt']
            }

        except Exception as e:
            _log_error(f"åˆ†æè§†é¢‘å±æ€§å¤±è´¥: {str(e)}")
            return None

    def _concat_with_copy(self, concat_file, output_path):
        """ä½¿ç”¨æµå¤åˆ¶æ–¹å¼æ‹¼æ¥ï¼ˆæœ€å¿«ï¼Œé€‚ç”¨äºå±æ€§ä¸€è‡´çš„è§†é¢‘ï¼‰"""
        try:
            import subprocess

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c', 'copy',  # ç›´æ¥å¤åˆ¶æµ
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œæµå¤åˆ¶å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… æµå¤åˆ¶æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_info(f"âš ï¸ æµå¤åˆ¶å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"æµå¤åˆ¶æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_smooth_transitions(self, concat_file, output_path, quality, video_info, smooth_transitions=True, transition_duration=0.5, force_keyframes=True):
        """ä½¿ç”¨å¹³æ»‘è¿‡æ¸¡çš„é‡æ–°ç¼–ç æ–¹å¼æ‹¼æ¥"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            # æ„å»ºæ”¹è¿›çš„FFmpegå‘½ä»¤ï¼Œå‡å°‘é—ªçƒ
            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',  # å¼ºåˆ¶ä½¿ç”¨H.264ç¼–ç å™¨
                '-pix_fmt', 'yuv420p',  # ç»Ÿä¸€åƒç´ æ ¼å¼
                '-r', str(int(video_info['target_fps'])),  # ç»Ÿä¸€å¸§ç‡
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",  # ç»Ÿä¸€åˆ†è¾¨ç‡
                '-vsync', 'cfr',  # æ’å®šå¸§ç‡
                '-bf', '2',  # Bå¸§æ•°é‡
                '-sc_threshold', '0',  # ç¦ç”¨åœºæ™¯åˆ‡æ¢æ£€æµ‹
                '-avoid_negative_ts', 'make_zero',  # é¿å…è´Ÿæ—¶é—´æˆ³
                '-fflags', '+genpts',  # ç”ŸæˆPTS
            ]

            # æ ¹æ®å‚æ•°æ·»åŠ å…³é”®å¸§æ§åˆ¶
            if force_keyframes:
                keyframe_interval = max(1, int(video_info['target_fps'] * 2))  # æ¯2ç§’ä¸€ä¸ªå…³é”®å¸§
                cmd.extend([
                    '-force_key_frames', f'expr:gte(t,n_forced*2)',
                    '-g', str(keyframe_interval),
                ])

            # æ·»åŠ å¹³æ»‘è¿‡æ¸¡æ»¤é•œï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if smooth_transitions and transition_duration > 0:
                # ä½¿ç”¨minterpolateæ»¤é•œè¿›è¡Œå¸§æ’å€¼ï¼Œå‡å°‘è·³è·ƒæ„Ÿ
                cmd.extend([
                    '-vf', f'minterpolate=fps={video_info["target_fps"]}:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1'
                ])

            cmd.extend(quality_params + ['-y', output_path])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¹³æ»‘è¿‡æ¸¡ç¼–ç : {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å¦‚æœé«˜çº§æ»¤é•œå¤±è´¥ï¼Œå°è¯•åŸºç¡€æ–¹æ³•
                if smooth_transitions:
                    _log_info("ğŸ”„ å°è¯•åŸºç¡€å¹³æ»‘æ–¹æ³•...")
                    return self._concat_with_basic_smooth(concat_file, output_path, quality, video_info)
                return False

        except Exception as e:
            _log_error(f"å¹³æ»‘è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_basic_smooth(self, concat_file, output_path, quality, video_info):
        """åŸºç¡€å¹³æ»‘æ‹¼æ¥æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰"""
        try:
            import subprocess

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg',
                '-f', 'concat',
                '-safe', '0',
                '-i', concat_file,
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-s', f"{video_info['target_width']}x{video_info['target_height']}",
                '-vsync', 'cfr',
                '-bf', '2',
                '-g', str(int(video_info['target_fps'] * 2)),
                '-sc_threshold', '0',
                '-avoid_negative_ts', 'make_zero',
                '-fflags', '+genpts',
            ] + quality_params + [
                '-y',
                output_path
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"åŸºç¡€å¹³æ»‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _cleanup_temp_file(self, temp_file):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if os.path.exists(temp_file):
                os.remove(temp_file)
        except Exception as e:
            _log_error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

    def _concat_with_crossfade_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, False, 0, True)

            _log_info(f"ğŸ¬ ä½¿ç”¨äº¤å‰æ·¡åŒ–è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # å¯¹äºäº¤å‰æ·¡åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨æ›´ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼š
            # 1. å…ˆç”¨concatæ­£å¸¸æ‹¼æ¥
            # 2. ç„¶ååœ¨æ‹¼æ¥ç‚¹æ·»åŠ æ·¡åŒ–æ•ˆæœ

            # é¦–å…ˆè·å–è§†é¢‘ä¿¡æ¯ä»¥è®¡ç®—æ€»æ—¶é•¿
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # è®¡ç®—æ¯ä¸ªè§†é¢‘çš„æ—¶é•¿å’Œç´¯ç§¯æ—¶é•¿
            video_durations = []
            cumulative_time = 0

            for video_path in video_paths:
                try:
                    cmd_duration = [
                        'ffprobe',
                        '-v', 'quiet',
                        '-show_entries', 'format=duration',
                        '-of', 'csv=p=0',
                        video_path
                    ]
                    result = subprocess.run(cmd_duration, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        video_durations.append(duration)
                        cumulative_time += duration
                    else:
                        video_durations.append(2.0)  # é»˜è®¤2ç§’
                        cumulative_time += 2.0
                except:
                    video_durations.append(2.0)
                    cumulative_time += 2.0

            _log_info(f"ğŸ“Š è§†é¢‘æ—¶é•¿: {[f'{d:.1f}s' for d in video_durations]}, æ€»æ—¶é•¿: {cumulative_time:.1f}s")

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºç®€åŒ–çš„äº¤å‰æ·¡åŒ–æ»¤é•œ
            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•äº¤å‰æ·¡åŒ–
                filter_complex = self._build_simple_crossfade_filter(video_durations, transition_duration)
            else:
                # å¤šä¸ªè§†é¢‘ä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•
                _log_info("ğŸ”„ å¤šè§†é¢‘äº¤å‰æ·¡åŒ–ï¼Œä½¿ç”¨æ”¹è¿›çš„concatæ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œäº¤å‰æ·¡åŒ–å‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… äº¤å‰æ·¡åŒ–æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {result.stderr}")
                # å›é€€åˆ°æ™®é€šæ‹¼æ¥
                _log_info("ğŸ”„ å›é€€åˆ°æ™®é€šæ‹¼æ¥æ–¹æ³•...")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

        except Exception as e:
            _log_error(f"äº¤å‰æ·¡åŒ–æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°æ™®é€šæ‹¼æ¥
            return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

    def _build_simple_crossfade_filter(self, video_durations, transition_duration):
        """æ„å»ºç®€å•çš„ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–æ»¤é•œ"""
        if len(video_durations) != 2:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        duration1, duration2 = video_durations

        # ç¡®ä¿è¿‡æ¸¡æ—¶é—´ä¸è¶…è¿‡è¾ƒçŸ­è§†é¢‘çš„ä¸€åŠ
        max_transition = min(duration1, duration2) / 2
        actual_transition = min(transition_duration, max_transition)

        if actual_transition <= 0:
            return "[0:v][1:v]concat=n=2:v=1[output]"

        # ä½¿ç”¨xfadeæ»¤é•œè¿›è¡Œäº¤å‰æ·¡åŒ–ï¼ˆæ›´ä¸“ä¸šçš„æ–¹æ³•ï¼‰
        # xfadeæ»¤é•œä¼šè‡ªåŠ¨å¤„ç†æ—¶é—´å¯¹é½
        offset_time = duration1 - actual_transition

        filter_complex = f"[0:v][1:v]xfade=transition=fade:duration={actual_transition}:offset={offset_time}[output]"

        return filter_complex

    def _concat_with_xfade_multiple(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥å¤šä¸ªè§†é¢‘ï¼ˆæ”¹è¿›ç‰ˆæœ¬ï¼‰"""
        try:
            import subprocess
            import tempfile

            _log_info(f"ğŸ¬ ä½¿ç”¨xfadeæ»¤é•œæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨xfade
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

            # å¤šä¸ªè§†é¢‘éœ€è¦é€’å½’å¤„ç†
            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"intermediate_{i}.mp4")

                    # ä½¿ç”¨ä¸¤è§†é¢‘äº¤å‰æ·¡åŒ–
                    success = self._concat_with_crossfade_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘xfadeæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_advanced_transitions(self, video_paths, output_path, quality, transition_duration=0.5, transition_type="fade", motion_compensation=False, edge_enhancement=False):
        """ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥è§†é¢‘"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ¨ ä½¿ç”¨é«˜çº§è¿‡æ¸¡æ•ˆæœæ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘ï¼Œè¿‡æ¸¡ç±»å‹: {transition_type}")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°æ™®é€šæ‹¼æ¥")
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            # æ„å»ºè¾“å…¥
            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            # æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ
            if len(video_paths) == 2:
                filter_complex = self._build_advanced_transition_filter(video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨é€’å½’å¤„ç†
                return self._concat_advanced_multiple(video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement)

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œé«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout * 2  # é«˜çº§å¤„ç†éœ€è¦æ›´å¤šæ—¶é—´
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                # å›é€€åˆ°äº¤å‰æ·¡åŒ–
                _log_info("ğŸ”„ å›é€€åˆ°äº¤å‰æ·¡åŒ–æ–¹æ³•...")
                return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

        except Exception as e:
            _log_error(f"é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°äº¤å‰æ·¡åŒ–
            return self._concat_with_crossfade_transitions(video_paths, output_path, quality, transition_duration)

    def _build_advanced_transition_filter(self, video_paths, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œ"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # é¢„å¤„ç†æ»¤é•œ
            preprocess_filters = []

            # è¾¹ç¼˜å¢å¼º
            if edge_enhancement:
                preprocess_filters.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                input_labels = ["[v0enhanced]", "[v1enhanced]"]
            else:
                input_labels = ["[0:v]", "[1:v]"]

            # è¿åŠ¨è¡¥å¿ï¼ˆä½¿ç”¨minterpolateè¿›è¡Œå¸§æ’å€¼ï¼‰
            if motion_compensation:
                preprocess_filters.extend([
                    f"{input_labels[0]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    f"{input_labels[1]}minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                input_labels = ["[v0smooth]", "[v1smooth]"]

            # æ„å»ºxfadeè¿‡æ¸¡
            xfade_filter = f"{input_labels[0]}{input_labels[1]}xfade=transition={transition_type}:duration={actual_transition}:offset={offset_time}[output]"

            # ç»„åˆæ‰€æœ‰æ»¤é•œ
            if preprocess_filters:
                filter_complex = ";".join(preprocess_filters) + ";" + xfade_filter
            else:
                filter_complex = xfade_filter

            return filter_complex

        except Exception as e:
            _log_error(f"æ„å»ºé«˜çº§è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            return f"[0:v][1:v]xfade=transition=fade:duration={transition_duration}:offset={max(0, durations[0] - transition_duration)}[output]"

    def _concat_advanced_multiple(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—é—®é¢˜"""
        try:
            # å¯¹äºå¤šè§†é¢‘ï¼Œä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾è€Œä¸æ˜¯é€’å½’æ‹¼æ¥
            # è¿™æ ·å¯ä»¥é¿å…é‡å¤å‡å»è¿‡æ¸¡æ—¶é—´çš„é—®é¢˜

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘ç›´æ¥ä½¿ç”¨åŸæ–¹æ³•
                return self._concat_with_advanced_transitions(
                    video_paths, output_path, quality, transition_duration,
                    transition_type, motion_compensation, edge_enhancement
                )

            # å¤šäº2ä¸ªè§†é¢‘æ—¶ï¼Œæ„å»ºä¸€æ¬¡æ€§æ»¤é•œé“¾
            return self._concat_advanced_multiple_chain(
                video_paths, output_path, quality, transition_duration,
                transition_type, motion_compensation, edge_enhancement
            )

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_advanced_multiple_chain(self, video_paths, output_path, quality, transition_duration, transition_type, motion_compensation, edge_enhancement):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾æ‹¼æ¥å¤šä¸ªè§†é¢‘ - æ­£ç¡®çš„æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾
            filter_complex = self._build_multiple_xfade_chain(video_paths, durations, actual_transition, transition_type)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘é«˜çº§è¿‡æ¸¡å‘½ä»¤...")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘é«˜çº§è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_xfade_chain(self, video_paths, durations, transition_duration, transition_type):
        """æ„å»ºå¤šè§†é¢‘xfadeæ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration
                return f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[output]"

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            filter_parts.append(f"[0:v][1:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[v01]")
            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration
                filter_parts.append(f"[{input_label}][{i}:v]xfade=transition={transition_type}:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _simple_concat_multiple(self, video_paths, output_path):
        """ç®€å•çš„å¤šè§†é¢‘æ‹¼æ¥ï¼ˆæ— è¿‡æ¸¡ï¼‰"""
        try:
            import subprocess
            import tempfile

            with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
                for video_path in video_paths:
                    f.write(f"file '{video_path}'\n")
                concat_file = f.name

            try:
                cmd = [
                    'ffmpeg',
                    '-f', 'concat',
                    '-safe', '0',
                    '-i', concat_file,
                    '-c', 'copy',
                    '-y',
                    output_path
                ]

                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)

                if result.returncode == 0 and os.path.exists(output_path):
                    return True
                else:
                    return False

            finally:
                try:
                    os.unlink(concat_file)
                except:
                    pass

        except Exception as e:
            _log_error(f"ç®€å•å¤šè§†é¢‘æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _concat_with_morphing_transitions(self, video_paths, output_path, quality, transition_duration=0.5, motion_compensation=False):
        """ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆå®éªŒæ€§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸ§¬ ä½¿ç”¨å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "fade", motion_compensation, False)

            # å¯¹äºå½¢æ€å­¦è¿‡æ¸¡ï¼Œæˆ‘ä»¬ä½¿ç”¨blendæ»¤é•œå’Œmorphologicalæ“ä½œ
            if len(video_paths) == 2:
                filter_complex = self._build_morphing_filter(video_paths, transition_duration, motion_compensation)
            else:
                # å¤šè§†é¢‘ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾ï¼Œé¿å…æ—¶é•¿è®¡ç®—é”™è¯¯
                return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # å¤§å¹…ç¼©çŸ­è¶…æ—¶æ—¶é—´ - å½¢æ€å­¦è¿‡æ¸¡ä¹Ÿåº”è¯¥å¿«é€Ÿå¤„ç†
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

        except Exception as e:
            _log_error(f"å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡
            return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "dissolve", motion_compensation, True)

    def _build_morphing_filter(self, video_paths, transition_duration, motion_compensation):
        """æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ - æ›´ç¨³å®šçš„å®ç°
            filter_parts = []

            # è¿åŠ¨è¡¥å¿ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]"
                ])
                # ä½¿ç”¨é«˜è´¨é‡dissolveè¿‡æ¸¡
                filter_parts.append(
                    f"[v0smooth][v1smooth]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )
            else:
                # ä¸ä½¿ç”¨è¿åŠ¨è¡¥å¿æ—¶ï¼Œä½¿ç”¨è¾¹ç¼˜å¢å¼ºçš„dissolve
                filter_parts.extend([
                    "[0:v]unsharp=5:5:1.0:5:5:0.0[v0enhanced]",
                    "[1:v]unsharp=5:5:1.0:5:5:0.0[v1enhanced]"
                ])
                filter_parts.append(
                    f"[v0enhanced][v1enhanced]xfade=transition=dissolve:duration={actual_transition}:offset={offset_time}[output]"
                )

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå½¢æ€å­¦è¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°ç®€å•çš„dissolveè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=dissolve:duration={transition_duration}:offset={offset_time}[output]"

    def _concat_with_optical_flow_transitions(self, video_paths, output_path, quality, transition_duration=0.5):
        """ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥è§†é¢‘ï¼ˆæœ€é«˜çº§ï¼‰"""
        try:
            import subprocess

            if len(video_paths) < 2:
                return self._concat_videos(video_paths, output_path, quality, True, transition_duration, True)

            _log_info(f"ğŸŒŠ ä½¿ç”¨å…‰æµè¿‡æ¸¡æ‹¼æ¥ {len(video_paths)} ä¸ªè§†é¢‘...")

            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = self._analyze_video_properties(video_paths)
            if not video_info:
                _log_error("æ— æ³•åˆ†æè§†é¢‘å±æ€§ï¼Œå›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

            # ç°åœ¨FFmpegå‚æ•°å·²ä¿®å¤ï¼Œå¯ä»¥æ”¯æŒå„ç§åˆ†è¾¨ç‡çš„å…‰æµè¿‡æ¸¡
            # ä½†å¯¹äºè¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ï¼Œä»ç„¶å»ºè®®ä½¿ç”¨å¿«é€Ÿæ–¹æ³•ä»¥ä¿è¯ç”¨æˆ·ä½“éªŒ
            if 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (å¦‚1920x1080)ï¼Œæé†’ç”¨æˆ·ä½†ä¸å¼ºåˆ¶è·³è¿‡
                    _log_info(f"âš ï¸ æ£€æµ‹åˆ°è¶…å¤§åˆ†è¾¨ç‡è§†é¢‘ ({video_info['target_width']}x{video_info['target_height']})ï¼Œå…‰æµè¿‡æ¸¡å¯èƒ½è¾ƒæ…¢")
                    _log_info("ğŸ’¡ å¦‚éœ€å¿«é€Ÿå¤„ç†ï¼Œå»ºè®®ä½¿ç”¨concat_advancedæ–¹æ³•")
                    # ä¸å†å¼ºåˆ¶è·³è¿‡ï¼Œè®©ç”¨æˆ·é€‰æ‹©

            # å°è¯•çœŸæ­£çš„å…‰æµè¿‡æ¸¡å¤„ç†
            if len(video_paths) == 2:
                filter_complex = self._build_optical_flow_filter(video_paths, transition_duration)
            else:
                # å¤šè§†é¢‘å…‰æµè¿‡æ¸¡ï¼šä½¿ç”¨é“¾å¼å…‰æµå¤„ç†
                _log_info("ğŸŒŠ æ‰§è¡Œå¤šè§†é¢‘å…‰æµè¿‡æ¸¡å¤„ç†...")
                filter_complex = self._build_optical_flow_multiple_filter(video_paths, transition_duration)

                # å¦‚æœå¤šè§†é¢‘å…‰æµæ»¤é•œæ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡
                if filter_complex is None:
                    _log_info("ğŸ”„ å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
                    return self._concat_with_advanced_transitions(video_paths, output_path, quality, transition_duration, "radial", False, False)

            inputs = []
            for video_path in video_paths:
                inputs.extend(['-i', video_path])

            quality_params = self._get_quality_params(quality)

            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-r', str(int(video_info['target_fps'])),
                '-vsync', 'cfr',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡Œå…‰æµè¿‡æ¸¡å‘½ä»¤...")

            # ä¸ºçœŸæ­£çš„å…‰æµè¿‡æ¸¡è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                    timeout_seconds = 600  # 10åˆ†é’Ÿï¼Œè½»é‡çº§å…‰æµ
                elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                    timeout_seconds = 480  # 8åˆ†é’Ÿï¼Œæ ‡å‡†å…‰æµ
                else:
                    timeout_seconds = 300  # 5åˆ†é’Ÿï¼Œé«˜è´¨é‡å…‰æµ
            else:
                timeout_seconds = 300  # é»˜è®¤5åˆ†é’Ÿ

            _log_info(f"â±ï¸ å…‰æµè¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (çœŸæ­£å…‰æµå¤„ç†)")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout_seconds
            )

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å…‰æµè¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"âŒ å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥")
                if result.stderr:
                    _log_error(f"FFmpegé”™è¯¯: {result.stderr[:300]}...")
                # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
                _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
                return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except subprocess.TimeoutExpired:
            _log_error(f"â° å…‰æµè¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            _log_info("ğŸ”„ å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•...")
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

        except Exception as e:
            _log_error(f"å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            # å›é€€åˆ°å½¢æ€å­¦è¿‡æ¸¡
            return self._concat_with_morphing_transitions(video_paths, output_path, quality, transition_duration, True)

    def _build_optical_flow_filter(self, video_paths, transition_duration):
        """æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œï¼ˆç®€åŒ–ç‰ˆï¼Œæ›´ç¨³å®šï¼‰"""
        try:
            # è·å–è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            duration1, duration2 = durations[0], durations[1]
            max_transition = min(duration1, duration2) / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                return "[0:v][1:v]concat=n=2:v=1[output]"

            offset_time = duration1 - actual_transition

            # ç°åœ¨æä¾›çœŸæ­£çš„å…‰æµè¿‡æ¸¡é€‰é¡¹
            # ç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒçº§åˆ«çš„å…‰æµå¤„ç†

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯
            pixels = 1248 * 704  # é»˜è®¤å€¼
            if len(video_paths) >= 2:
                try:
                    # å°è¯•è·å–å®é™…åˆ†è¾¨ç‡
                    cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                    if result.returncode == 0 and 'x' in result.stdout:
                        width, height = map(int, result.stdout.strip().split('x'))
                        pixels = width * height
                except:
                    pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ ä½¿ç”¨è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                # è½»é‡çº§å…‰æµï¼šä»…ä½¿ç”¨åŸºç¡€è¿åŠ¨è¡¥å¿
                filter_parts = [
                    "[0:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v0flow]",
                    "[1:v]minterpolate=fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ ä½¿ç”¨æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆå¹³è¡¡è´¨é‡ä¸é€Ÿåº¦ï¼‰")
                # æ ‡å‡†å…‰æµï¼šä¸­ç­‰å¤æ‚åº¦
                filter_parts = [
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v0flow]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]
            else:
                _log_info("ğŸŒŠ ä½¿ç”¨é«˜è´¨é‡å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                # é«˜è´¨é‡å…‰æµï¼šå®Œæ•´ç®—æ³•
                filter_parts = [
                    "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v0flow]",
                    "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1:scd=fdiff[v1flow]",
                    f"[v0flow][v1flow]xfade=transition=radial:duration={actual_transition}:offset={offset_time}[output]"
                ]

            return ";".join(filter_parts)

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜è´¨é‡çš„smoothleftè¿‡æ¸¡
            offset_time = max(0, durations[0] - transition_duration) if durations else 0
            return f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"

    def _build_optical_flow_multiple_filter(self, video_paths, transition_duration):
        """æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œé“¾"""
        try:
            # è·å–æ‰€æœ‰è§†é¢‘æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        duration = float(result.stdout.strip())
                        durations.append(duration)
                    else:
                        _log_error(f"ffprobeå¤±è´¥: {video_path}, è¿”å›ç : {result.returncode}")
                        _log_error(f"stderr: {result.stderr}")
                        durations.append(4.0)
                except Exception as e:
                    _log_error(f"ffprobeå¼‚å¸¸: {video_path}, é”™è¯¯: {str(e)}")
                    durations.append(4.0)

            if len(durations) < 2:
                return "[0:v]concat=n=1:v=1[output]"

            # è·å–è§†é¢‘åˆ†è¾¨ç‡ä¿¡æ¯ç”¨äºé€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            pixels = 1248 * 704  # é»˜è®¤å€¼
            try:
                cmd = ['ffprobe', '-v', 'quiet', '-select_streams', 'v:0', '-show_entries', 'stream=width,height', '-of', 'csv=s=x:p=0', video_paths[0]]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=5)
                if result.returncode == 0 and 'x' in result.stdout:
                    width, height = map(int, result.stdout.strip().split('x'))
                    pixels = width * height
            except:
                pass

            # æ ¹æ®åˆ†è¾¨ç‡é€‰æ‹©å…‰æµç®—æ³•å¤æ‚åº¦
            if pixels > 2073600:  # å¤§äº2MP (1920x1080)
                _log_info("ğŸŒŠ å¤šè§†é¢‘è½»é‡çº§å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå¤§åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"
            elif pixels > 800000:  # å¤§äº0.8MP (1248x704)
                _log_info("ğŸŒŠ å¤šè§†é¢‘å¿«é€Ÿå…‰æµè¿‡æ¸¡ï¼ˆä¼˜åŒ–å¤„ç†é€Ÿåº¦ï¼‰")
                minterpolate_params = "fps=30:mi_mode=mci:mc_mode=aobmc:me_mode=bidir"  # é™ä½fpsæé«˜é€Ÿåº¦
            else:
                _log_info("ğŸŒŠ å¤šè§†é¢‘æ ‡å‡†å…‰æµè¿‡æ¸¡ï¼ˆé€‚åˆå°åˆ†è¾¨ç‡ï¼‰")
                minterpolate_params = "fps=48:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1"

            filter_parts = []

            # é¦–å…ˆå¯¹æ‰€æœ‰è¾“å…¥è§†é¢‘åº”ç”¨å…‰æµå¤„ç†
            for i in range(len(video_paths)):
                filter_parts.append(f"[{i}:v]minterpolate={minterpolate_params}[v{i}flow]")

            # ä½¿ç”¨æ­£ç¡®çš„å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ–¹æ³•ï¼šé“¾å¼å¤„ç†ï¼Œä½†éœ€è¦æ­£ç¡®è®¡ç®—æ¯ä¸ªè¿‡æ¸¡çš„æ—¶é•¿
            #
            # å…³é”®ç†è§£ï¼šxfadeçš„offsetæ˜¯ç›¸å¯¹äºç¬¬ä¸€ä¸ªè¾“å…¥çš„æ—¶é•¿ï¼Œè€Œä¸æ˜¯ç»å¯¹æ—¶é—´
            # æ¯ä¸ªxfadeè¾“å‡ºçš„é•¿åº¦ = offset + transition_duration

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡ï¼švideo1 + video2
            offset_time = durations[0] - transition_duration  # 11.5ç§’
            filter_parts.append(f"[v0flow][v1flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[v01]")
            # v01çš„é•¿åº¦ = durations[0] + durations[1] - transition_duration = 23.5ç§’

            # åç»­è¿‡æ¸¡éœ€è¦é‡æ–°æ€è€ƒï¼šæˆ‘ä»¬éœ€è¦å°†v01å’Œåç»­è§†é¢‘æ‹¼æ¥
            # ä½†v01å·²ç»æ˜¯23.5ç§’çš„å®Œæ•´è§†é¢‘ï¼Œæˆ‘ä»¬éœ€è¦åœ¨å…¶æœ«å°¾æ·»åŠ æ–°è§†é¢‘

            current_video_length = durations[0] + durations[1] - transition_duration  # v01çš„é•¿åº¦

            for i in range(2, len(video_paths)):
                if i == 2:
                    input_label = "v01"
                    output_label = "v02" if i < len(video_paths) - 1 else "output"
                else:
                    input_label = f"v0{i-1}"
                    output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # å¯¹äºåç»­è¿‡æ¸¡ï¼Œoffsetåº”è¯¥æ˜¯å½“å‰è§†é¢‘é•¿åº¦å‡å»è¿‡æ¸¡æ—¶é—´
                offset_time = current_video_length - transition_duration
                filter_parts.append(f"[{input_label}][v{i}flow]xfade=transition=radial:duration={transition_duration}:offset={offset_time}[{output_label}]")

                # æ›´æ–°å½“å‰è§†é¢‘é•¿åº¦ï¼šåŠ ä¸Šæ–°è§†é¢‘é•¿åº¦ï¼Œå‡å»è¿‡æ¸¡æ—¶é—´
                current_video_length += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ»¤é•œå¤±è´¥: {str(e)}")
            # å›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•
            _log_info("ğŸ”„ å…‰æµè¿‡æ¸¡å¤±è´¥ï¼Œå›é€€åˆ°é«˜çº§è¿‡æ¸¡æ–¹æ³•...")
            return None  # è¿”å›Noneè¡¨ç¤ºéœ€è¦å›é€€

    def _concat_morphing_multiple(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿ç•™æ—§æ–¹æ³•ä½œä¸ºå¤‡ç”¨"""
        _log_info("ğŸ”„ ä½¿ç”¨æ—§çš„é€’å½’å½¢æ€å­¦è¿‡æ¸¡æ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰")
        return self._concat_morphing_multiple_chain(video_paths, output_path, quality, transition_duration, motion_compensation)

    def _concat_morphing_multiple_chain(self, video_paths, output_path, quality, transition_duration, motion_compensation):
        """ä½¿ç”¨ä¸€æ¬¡æ€§æ»¤é•œé“¾çš„å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥ - ä¿®å¤æ—¶é•¿è®¡ç®—"""
        try:
            import subprocess

            # è·å–æ‰€æœ‰è§†é¢‘çš„æ—¶é•¿
            durations = []
            for video_path in video_paths:
                try:
                    cmd = ['ffprobe', '-v', 'quiet', '-show_entries', 'format=duration', '-of', 'csv=p=0', video_path]
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        durations.append(float(result.stdout.strip()))
                    else:
                        durations.append(4.0)  # é»˜è®¤4ç§’
                except:
                    durations.append(4.0)

            if len(durations) < 2:
                return False

            # è®¡ç®—è¿‡æ¸¡å‚æ•°
            min_duration = min(durations)
            max_transition = min_duration / 2
            actual_transition = min(transition_duration, max_transition)

            if actual_transition <= 0:
                # æ— è¿‡æ¸¡ï¼Œä½¿ç”¨ç®€å•concat
                return self._simple_concat_multiple(video_paths, output_path)

            # æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾
            filter_complex = self._build_multiple_morphing_chain(video_paths, durations, actual_transition, motion_compensation)

            if not filter_complex:
                _log_error("æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥")
                return False

            # æ‰§è¡ŒFFmpegå‘½ä»¤
            cmd = ['ffmpeg']

            # æ·»åŠ è¾“å…¥æ–‡ä»¶
            for video_path in video_paths:
                cmd.extend(['-i', video_path])

            # æ·»åŠ æ»¤é•œå’Œè¾“å‡ºå‚æ•°
            cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[output]',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-y',
                output_path
            ])

            _log_info(f"ğŸ”§ æ‰§è¡Œå¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡å‘½ä»¤...")

            # æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡è°ƒæ•´è¶…æ—¶æ—¶é—´
            video_info = self._analyze_video_properties(video_paths)
            base_timeout = 20  # åŸºç¡€20ç§’è¶…æ—¶

            if video_info and 'target_width' in video_info and 'target_height' in video_info:
                pixels = video_info['target_width'] * video_info['target_height']
                if pixels > 1000000:  # å¤§äº1MP (å¦‚1248x704)
                    timeout_seconds = 45  # æœ€å¤š45ç§’
                elif pixels > 500000:  # å¤§äº0.5MP
                    timeout_seconds = 30  # 30ç§’
                else:
                    timeout_seconds = 20  # 20ç§’
            else:
                timeout_seconds = 20

            _log_info(f"â±ï¸ å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶è®¾ç½®: {timeout_seconds}ç§’ (å¿«é€Ÿå¤„ç†ç­–ç•¥)")

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout_seconds)

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info("âœ… å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥æˆåŠŸ")
                return True
            else:
                _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            _log_error(f"â° å½¢æ€å­¦è¿‡æ¸¡è¶…æ—¶ ({timeout_seconds}ç§’)")
            return False
        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å½¢æ€å­¦è¿‡æ¸¡æ‹¼æ¥å¼‚å¸¸: {str(e)}")
            return False

    def _build_multiple_morphing_chain(self, video_paths, durations, transition_duration, motion_compensation):
        """æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾"""
        try:
            if len(video_paths) < 2:
                return None

            if len(video_paths) == 2:
                # ä¸¤ä¸ªè§†é¢‘çš„ç®€å•æƒ…å†µ
                offset_time = durations[0] - transition_duration

                # ç®€åŒ–çš„å½¢æ€å­¦è¿‡æ¸¡æ»¤é•œ
                if motion_compensation:
                    # å¸¦è¿åŠ¨è¡¥å¿çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                        "[1:v]minterpolate=fps=60:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                        f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]
                else:
                    # ç®€å•çš„å½¢æ€å­¦è¿‡æ¸¡
                    filter_parts = [
                        "[0:v]edgedetect=low=0.1:high=0.4[v0edge]",
                        "[1:v]edgedetect=low=0.1:high=0.4[v1edge]",
                        f"[v0edge][v1edge]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[output]"
                    ]

                return ";".join(filter_parts)

            # å¤šä¸ªè§†é¢‘çš„å¤æ‚æƒ…å†µ - ä½¿ç”¨ç®€åŒ–çš„è¿‡æ¸¡æ•ˆæœ
            filter_parts = []
            current_offset = 0

            # ç¬¬ä¸€ä¸ªè¿‡æ¸¡
            offset_time = durations[0] - transition_duration
            if motion_compensation:
                filter_parts.extend([
                    "[0:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v0smooth]",
                    "[1:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v1smooth]",
                    f"[v0smooth][v1smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]"
                ])
            else:
                filter_parts.append(f"[0:v][1:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[v01]")

            current_offset = durations[0] + durations[1] - transition_duration

            # åç»­è¿‡æ¸¡
            for i in range(2, len(video_paths)):
                input_label = f"v0{i-1}" if i == 2 else f"v0{i-1}"
                output_label = f"v0{i}" if i < len(video_paths) - 1 else "output"

                # è®¡ç®—è¿™ä¸ªè¿‡æ¸¡çš„åç§»æ—¶é—´
                offset_time = current_offset - transition_duration

                if motion_compensation and i == 2:  # åªå¯¹ç¬¬äºŒä¸ªè¿‡æ¸¡ä½¿ç”¨è¿åŠ¨è¡¥å¿ï¼Œé¿å…è¿‡äºå¤æ‚
                    filter_parts.extend([
                        f"[{i}:v]minterpolate=fps=48:mi_mode=mci:mc_mode=aobmc[v{i}smooth]",
                        f"[{input_label}][v{i}smooth]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]"
                    ])
                else:
                    filter_parts.append(f"[{input_label}][{i}:v]xfade=transition=smoothleft:duration={transition_duration}:offset={offset_time}[{output_label}]")

                current_offset += durations[i] - transition_duration

            return ";".join(filter_parts)

        except Exception as e:
            _log_error(f"æ„å»ºå¤šè§†é¢‘å½¢æ€å­¦æ»¤é•œé“¾å¤±è´¥: {str(e)}")
            return None

    def _concat_optical_flow_multiple(self, video_paths, output_path, quality, transition_duration):
        """å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥"""
        try:
            import tempfile

            temp_dir = tempfile.mkdtemp()
            intermediate_files = []

            try:
                current_video = video_paths[0]

                for i in range(1, len(video_paths)):
                    next_video = video_paths[i]
                    temp_output = os.path.join(temp_dir, f"flow_intermediate_{i}.mp4")

                    success = self._concat_with_optical_flow_transitions(
                        [current_video, next_video],
                        temp_output,
                        quality,
                        transition_duration
                    )

                    if not success:
                        _log_error(f"å…‰æµè¿‡æ¸¡ä¸­é—´æ­¥éª¤ {i} å¤±è´¥")
                        return False

                    intermediate_files.append(temp_output)
                    current_video = temp_output

                # å¤åˆ¶æœ€ç»ˆç»“æœ
                if intermediate_files:
                    final_temp = intermediate_files[-1]
                    if os.path.exists(final_temp):
                        import shutil
                        shutil.copy2(final_temp, output_path)
                        return os.path.exists(output_path)

                return False

            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_file in intermediate_files:
                    try:
                        if os.path.exists(temp_file):
                            os.remove(temp_file)
                    except:
                        pass
                try:
                    os.rmdir(temp_dir)
                except:
                    pass

        except Exception as e:
            _log_error(f"å¤šè§†é¢‘å…‰æµè¿‡æ¸¡æ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _hstack_videos(self, video_paths, output_path, quality, scale_videos):
        """æ°´å¹³æ‹¼æ¥è§†é¢‘ï¼ˆå¹¶æ’æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†”ï¸ ä½¿ç”¨hstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("hstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†æ°´å¹³æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                hstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]hstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + hstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "hstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"hstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _vstack_videos(self, video_paths, output_path, quality, scale_videos):
        """å‚ç›´æ‹¼æ¥è§†é¢‘ï¼ˆä¸Šä¸‹æ˜¾ç¤ºï¼‰"""
        try:
            import subprocess

            _log_info("â†•ï¸ ä½¿ç”¨vstackæ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if len(video_paths) > 8:
                _log_error("vstackæ–¹æ³•æœ€å¤šæ”¯æŒ8ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # æ„å»ºç¼©æ”¾å’Œæ‹¼æ¥æ»¤é•œ
            if scale_videos:
                # å…ˆç¼©æ”¾åˆ°ç»Ÿä¸€å°ºå¯¸ï¼Œå†å‚ç›´æ‹¼æ¥
                scale_filters = []
                for i in range(len(video_paths)):
                    scale_filters.append(f"[{i}:v]scale=640:480[v{i}]")

                vstack_filter = "[" + "][".join([f"v{i}" for i in range(len(video_paths))]) + "]vstack=inputs=" + str(len(video_paths)) + "[outv]"
                filter_complex = ";".join(scale_filters) + ";" + vstack_filter
            else:
                # ç›´æ¥æ‹¼æ¥
                input_labels = "[" + "][".join([f"{i}:v" for i in range(len(video_paths))]) + "]"
                filter_complex = input_labels + "vstack=inputs=" + str(len(video_paths)) + "[outv]"

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"vstackæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _grid_videos(self, video_paths, output_path, quality, grid_type, scale_videos):
        """ç½‘æ ¼æ‹¼æ¥è§†é¢‘ï¼ˆ2x2ã€2x3æˆ–2x4å¸ƒå±€ï¼‰"""
        try:
            import subprocess

            _log_info(f"ğŸ”² ä½¿ç”¨{grid_type}ç½‘æ ¼æ–¹æ³•æ‹¼æ¥è§†é¢‘...")

            if grid_type == "2x2":
                max_videos = 4
            elif grid_type == "2x3":
                max_videos = 6
            elif grid_type == "2x4":
                max_videos = 8
            else:
                max_videos = 4

            if len(video_paths) > max_videos:
                _log_error(f"{grid_type}ç½‘æ ¼æœ€å¤šæ”¯æŒ{max_videos}ä¸ªè§†é¢‘")
                return False

            # æ„å»ºFFmpeg filter_complex
            inputs = []
            for i, video_path in enumerate(video_paths):
                inputs.extend(['-i', video_path])

            # ä¸ºä¸è¶³çš„ä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
            while len(video_paths) < max_videos:
                video_paths.append(None)

            # æ„å»ºç½‘æ ¼æ»¤é•œ
            if scale_videos:
                # ç¼©æ”¾æ‰€æœ‰è§†é¢‘åˆ°ç»Ÿä¸€å°ºå¯¸
                scale_filters = []
                for i in range(len([v for v in video_paths if v is not None])):
                    scale_filters.append(f"[{i}:v]scale=320:240[v{i}]")

                # ä¸ºç©ºä½ç½®åˆ›å»ºé»‘è‰²è§†é¢‘
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:320x240:d=1[v{i}]")

                if grid_type == "2x2":
                    # 2x2ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    # 2x3ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[top];[v2][v3]hstack[middle];[v4][v5]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    # 2x4ç½‘æ ¼å¸ƒå±€
                    grid_filter = "[v0][v1]hstack[row1];[v2][v3]hstack[row2];[v4][v5]hstack[row3];[v6][v7]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                all_filters = scale_filters + black_filters + [grid_filter]
                filter_complex = ";".join(all_filters)
            else:
                # ä¸ç¼©æ”¾ï¼Œç›´æ¥ç½‘æ ¼æ‹¼æ¥ï¼ˆå¯èƒ½ä¼šæœ‰å°ºå¯¸ä¸åŒ¹é…é—®é¢˜ï¼‰
                black_filters = []
                actual_videos = len([v for v in video_paths if v is not None])
                for i in range(actual_videos, max_videos):
                    black_filters.append(f"color=black:640x480:d=1[v{i}]")

                if grid_type == "2x2":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[bottom];[top][bottom]vstack[outv]"
                elif grid_type == "2x3":
                    grid_filter = f"[0:v][1:v]hstack[top];[2:v][3:v]hstack[middle];[4:v][5:v]hstack[bottom];[top][middle]vstack[temp];[temp][bottom]vstack[outv]"
                else:  # 2x4
                    grid_filter = f"[0:v][1:v]hstack[row1];[2:v][3:v]hstack[row2];[4:v][5:v]hstack[row3];[6:v][7:v]hstack[row4];[row1][row2]vstack[temp1];[row3][row4]vstack[temp2];[temp1][temp2]vstack[outv]"

                filter_complex = ";".join(black_filters + [grid_filter])

            quality_params = self._get_quality_params(quality)
            cmd = [
                'ffmpeg'
            ] + inputs + [
                '-filter_complex', filter_complex,
                '-map', '[outv]',
                '-map', '0:a?',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„éŸ³é¢‘
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd)}")

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            return result.returncode == 0 and os.path.exists(output_path)

        except Exception as e:
            _log_error(f"gridæ‹¼æ¥å¤±è´¥: {str(e)}")
            return False

    def _create_error_result(self, error_msg):
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        try:
            blank_video = create_blank_video_object()
            blank_video_path = getattr(blank_video, 'file_path', '') if blank_video else ''
            afvideo = create_video_path_wrapper(blank_video_path) if blank_video_path else create_blank_video_object()
            return (blank_video, f"âŒ {error_msg}", afvideo)
        except:
            return (None, f"âŒ {error_msg}", None)


class GetLastFrameNode:
    """æå–ä»»æ„è§†é¢‘å°¾å¸§çš„ç‹¬ç«‹èŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
            },
            "optional": {
                "output_filename": ("STRING", {"default": ""}),
                "image_quality": (["high", "medium", "low"], {"default": "high"}),
                "offset_from_last": ("INT", {"default": 0, "min": 0, "max": 100000, "step": 1}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("last_frame_image", "frame_path")
    FUNCTION = "extract_last_frame"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 60  # 1åˆ†é’Ÿè¶…æ—¶

    def extract_last_frame(self, video, output_filename="", image_quality="high", offset_from_last=0):
        """
        æå–è§†é¢‘çš„æœ€åä¸€å¸§æˆ–ä»å°¾éƒ¨èµ·ç¬¬Nå¸§ï¼ˆ0è¡¨ç¤ºå°¾å¸§ï¼‰

        Args:
            video: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            image_quality: å›¾åƒè´¨é‡è®¾ç½®
            offset_from_last: ä»å°¾éƒ¨èµ·çš„åç§»å¸§æ•°ï¼ˆ0=å°¾å¸§ï¼Œ1=å€’æ•°ç¬¬2å¸§...ï¼‰

        Returns:
            tuple: (å›¾åƒå¼ é‡, å›¾åƒæ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹æå–è§†é¢‘å°¾å¸§...")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ”¹è¿›çš„æå–æ–¹æ³•
            video_path = self._extract_video_path(video)

            if not video_path:
                error_msg = f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}"
                _log_error(error_msg)
                _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                # è¿”å›ç©ºç™½å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            if not os.path.exists(video_path):
                error_msg = f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"ğŸ“¹ è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                if offset_from_last and offset_from_last > 0:
                    output_filename = f"{video_name}_last_minus_{offset_from_last}.jpg"
                else:
                    output_filename = f"{video_name}_last_frame.jpg"

            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
            if not output_filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                output_filename += '.jpg'

            # ä½¿ç”¨ä¸´æ—¶ç›®å½•
            import tempfile
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{int(time.time())}_{output_filename}")

            # è®¾ç½®å›¾åƒè´¨é‡å‚æ•°
            quality_settings = {
                "high": ["-q:v", "2"],      # é«˜è´¨é‡
                "medium": ["-q:v", "5"],    # ä¸­ç­‰è´¨é‡
                "low": ["-q:v", "8"]        # ä½è´¨é‡
            }
            quality_params = quality_settings.get(image_quality, quality_settings["high"])

            # æå–æŒ‡å®šå¸§ï¼ˆæ”¯æŒä»å°¾éƒ¨åç§»ï¼‰
            frame_path = None
            try:
                # ä¼˜å…ˆå°è¯•ä½¿ç”¨å¸§åºå·æ–¹å¼
                total_frames = self._get_total_frames(video_path)
                if isinstance(total_frames, int) and total_frames > 0:
                    target_index = max(total_frames - 1 - max(0, int(offset_from_last or 0)), 0)
                    frame_path = self._extract_frame_by_index(video_path, output_path, quality_params, target_index)
                else:
                    frame_path = None
            except Exception:
                frame_path = None

            # é€€å›ç­–ç•¥ï¼šå½“ä¸èƒ½ç²¾ç¡®æŒ‰å¸§ç´¢å¼•æ—¶ï¼Œä½¿ç”¨æ—¶é—´ä¼°ç®—æˆ–å°¾å¸§æ–¹å¼
            if not frame_path:
                if offset_from_last and offset_from_last > 0:
                    # ä½¿ç”¨æ—¶é•¿å’Œfpsä¼°ç®—å®šä½
                    duration, fps = self._get_duration_and_fps(video_path)
                    if duration and fps:
                        seek_time = max(0.0, float(duration) - (float(offset_from_last) + 1.0) / float(fps))
                        frame_path = self._extract_frame_by_time(video_path, output_path, quality_params, seek_time)
                # æœ€åå…œåº•ä¸ºå°¾å¸§
                if not frame_path:
                    frame_path = self._extract_frame_with_ffmpeg(video_path, output_path, quality_params)

            if not frame_path:
                error_msg = "å°¾å¸§æå–å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            # å°†å›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼
            image_tensor = self._load_image_as_tensor(frame_path)

            if image_tensor is None:
                error_msg = "å›¾åƒåŠ è½½å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"âœ… å°¾å¸§æå–æˆåŠŸ: {frame_path}")
            return (image_tensor, frame_path)

        except Exception as e:
            error_msg = f"æå–è§†é¢‘å°¾å¸§å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            blank_image = self._create_blank_image()
            return (blank_image, f"âŒ {error_msg}")

    def _extract_frame_by_index(self, video_path, output_path, quality_params, frame_index):
        """ä½¿ç”¨å¸§ç´¢å¼•æå–æŒ‡å®šå¸§ï¼ˆ0-basedï¼‰"""
        try:
            import subprocess
            # ä½¿ç”¨select=eq(n,frame_index) ç²¾ç¡®é€‰å¸§
            vf_expr = f"select='eq(n,{int(frame_index)})'"
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-vf', vf_expr,
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰ç´¢å¼•æå–å¸§: index={frame_index}, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰ç´¢å¼•æå–å¤±è´¥: {str(e)}")
            return None

    def _extract_frame_by_time(self, video_path, output_path, quality_params, seek_time):
        """æŒ‰æ—¶é—´å®šä½æå–å•å¸§ï¼ˆseek_timeä¸ºç§’ï¼‰"""
        try:
            import subprocess
            cmd = [
                'ffmpeg',
                '-ss', f"{seek_time}",
                '-i', video_path,
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰æ—¶é—´æå–å¸§: t={seek_time:.3f}s, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰æ—¶é—´æå–å¤±è´¥: {str(e)}")
            return None

    def _get_total_frames(self, video_path):
        """ä½¿ç”¨ffprobeå°½å¯èƒ½è·å–æ€»å¸§æ•°ï¼Œå¤±è´¥è¿”å›None"""
        try:
            import subprocess, json
            # æ–¹æ¡ˆ1ï¼šcount_frames
            cmd1 = [
                'ffprobe',
                '-v', 'error',
                '-count_frames',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=nb_read_frames',
                '-of', 'default=nokey=1:noprint_wrappers=1',
                video_path
            ]
            res1 = subprocess.run(cmd1, capture_output=True, text=True, timeout=20)
            if res1.returncode == 0:
                val = res1.stdout.strip()
                if val.isdigit():
                    return int(val)

            # æ–¹æ¡ˆ2ï¼šè¯»å–nb_frames
            cmd2 = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=nb_frames',
                '-of', 'default=nokey=1:noprint_wrappers=1',
                video_path
            ]
            res2 = subprocess.run(cmd2, capture_output=True, text=True, timeout=20)
            if res2.returncode == 0:
                val = res2.stdout.strip()
                if val.isdigit():
                    return int(val)
        except Exception as e:
            _log_warning(f"æ— æ³•è·å–æ€»å¸§æ•°: {str(e)}")
        return None

    def _get_duration_and_fps(self, video_path):
        """è¿”å›(duration_seconds, fps) æˆ– (None, None)"""
        try:
            import subprocess, json
            # è·å–æ—¶é•¿
            cmd = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=avg_frame_rate:format=duration',
                '-of', 'json',
                video_path
            ]
            res = subprocess.run(cmd, capture_output=True, text=True, timeout=20)
            if res.returncode == 0 and res.stdout:
                data = json.loads(res.stdout)
                duration = None
                fps = None
                if 'format' in data and 'duration' in data['format']:
                    try:
                        duration = float(data['format']['duration'])
                    except:
                        duration = None
                if 'streams' in data and data['streams']:
                    afr = data['streams'][0].get('avg_frame_rate')
                    if afr and afr != '0/0':
                        try:
                            num, den = afr.split('/')
                            num = float(num)
                            den = float(den) if float(den) != 0 else 1.0
                            fps = num / den if den else None
                        except:
                            fps = None
                return duration, fps
        except Exception as e:
            _log_warning(f"æ— æ³•è·å–æ—¶é•¿ä¸FPS: {str(e)}")
        return None, None

    def _extract_frame_with_ffmpeg(self, video_path, output_path, quality_params):
        """ä½¿ç”¨FFmpegæå–å°¾å¸§"""
        try:
            import subprocess

            # æ–¹æ³•1ï¼šä½¿ç”¨select=eofè¿‡æ»¤å™¨
            cmd1 = [
                'ffmpeg',
                '-i', video_path,
                '-vf', 'select=eof',
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]

            _log_info(f"ğŸ”§ æ‰§è¡ŒFFmpegå‘½ä»¤: {' '.join(cmd1)}")

            result = subprocess.run(
                cmd1,
                capture_output=True,
                text=True,
                timeout=self.timeout
            )

            if result.returncode == 0 and os.path.exists(output_path):
                return output_path

            # æ–¹æ³•2ï¼šå¤‡ç”¨æ—¶é•¿è®¡ç®—æ–¹æ³•
            _log_info("ğŸ”„ å°è¯•å¤‡ç”¨æ–¹æ³•...")

            # è·å–è§†é¢‘æ—¶é•¿
            duration_cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                video_path
            ]

            duration_result = subprocess.run(
                duration_cmd,
                capture_output=True,
                text=True,
                timeout=30
            )

            if duration_result.returncode == 0:
                try:
                    duration = float(duration_result.stdout.strip())
                    seek_time = max(0, duration - 0.1)

                    cmd2 = [
                        'ffmpeg',
                        '-ss', str(seek_time),
                        '-i', video_path,
                        '-frames:v', '1',
                    ] + quality_params + [
                        '-y',
                        output_path
                    ]

                    result = subprocess.run(
                        cmd2,
                        capture_output=True,
                        text=True,
                        timeout=self.timeout
                    )

                    if result.returncode == 0 and os.path.exists(output_path):
                        return output_path
                except:
                    pass

            return None

        except Exception as e:
            _log_error(f"FFmpegæå–å¤±è´¥: {str(e)}")
            return None

    def _load_image_as_tensor(self, image_path):
        """å°†å›¾åƒæ–‡ä»¶åŠ è½½ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        try:
            from PIL import Image
            import numpy as np
            import torch

            # ä½¿ç”¨PILåŠ è½½å›¾åƒ
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img).astype(np.float32) / 255.0

                # æ·»åŠ batchç»´åº¦ [H, W, C] -> [1, H, W, C]
                img_array = np.expand_dims(img_array, axis=0)

                # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
                img_tensor = torch.from_numpy(img_array)

                _log_info(f"âœ… å›¾åƒå¼ é‡æ ¼å¼: {img_tensor.shape}, dtype: {img_tensor.dtype}")
                return img_tensor

        except Exception as e:
            _log_error(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
            return None

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _create_blank_image(self):
        """åˆ›å»ºç©ºç™½å›¾åƒå¼ é‡"""
        try:
            import numpy as np
            import torch
            # åˆ›å»º512x512çš„é»‘è‰²å›¾åƒ
            blank_array = np.zeros((1, 512, 512, 3), dtype=np.float32)
            # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
            blank_tensor = torch.from_numpy(blank_array)
            return blank_tensor
        except:
            return None


class GetFirstFrameNode:
    """æå–ä»»æ„è§†é¢‘é¦–å¸§çš„ç‹¬ç«‹èŠ‚ç‚¹"""

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
            },
            "optional": {
                "output_filename": ("STRING", {"default": ""}),
                "image_quality": (["high", "medium", "low"], {"default": "high"}),
                "offset_from_first": ("INT", {"default": 0, "min": 0, "max": 100000, "step": 1, "tooltip": "ä»é¦–å¸§å¼€å§‹çš„åç§»å¸§æ•°ï¼ˆ0=é¦–å¸§ï¼Œ1=ç¬¬2å¸§ï¼Œ2=ç¬¬3å¸§...ï¼‰"}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("first_frame_image", "frame_path")
    FUNCTION = "extract_first_frame"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def __init__(self):
        self.timeout = 60  # 1åˆ†é’Ÿè¶…æ—¶

    def extract_first_frame(self, video, output_filename="", image_quality="high", offset_from_first=0):
        """
        æå–è§†é¢‘çš„ç¬¬ä¸€å¸§æˆ–ä»é¦–å¸§èµ·ç¬¬Nå¸§ï¼ˆ0è¡¨ç¤ºé¦–å¸§ï¼‰

        Args:
            video: ComfyUI VIDEOå¯¹è±¡
            output_filename: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            image_quality: å›¾åƒè´¨é‡è®¾ç½®
            offset_from_first: ä»é¦–å¸§èµ·çš„åç§»å¸§æ•°ï¼ˆ0=é¦–å¸§ï¼Œ1=ç¬¬2å¸§ï¼Œ2=ç¬¬3å¸§...ï¼‰

        Returns:
            tuple: (å›¾åƒå¼ é‡, å›¾åƒæ–‡ä»¶è·¯å¾„)
        """
        try:
            _log_info("ğŸ¬ å¼€å§‹æå–è§†é¢‘é¦–å¸§...")

            # è·å–è§†é¢‘æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨æ”¹è¿›çš„æå–æ–¹æ³•
            video_path = self._extract_video_path(video)

            if not video_path:
                error_msg = f"æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}"
                _log_error(error_msg)
                _log_error(f"è§†é¢‘å¯¹è±¡è¯¦æƒ…: type={type(video)}, repr={repr(video)}")
                # è¿”å›ç©ºç™½å›¾åƒå’Œé”™è¯¯ä¿¡æ¯
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            if not os.path.exists(video_path):
                error_msg = f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"ğŸ“¹ è§†é¢‘æ–‡ä»¶è·¯å¾„: {video_path}")

            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if not output_filename:
                video_name = os.path.splitext(os.path.basename(video_path))[0]
                if offset_from_first and offset_from_first > 0:
                    output_filename = f"{video_name}_frame_{offset_from_first}.jpg"
                else:
                    output_filename = f"{video_name}_first_frame.jpg"

            # ç¡®ä¿è¾“å‡ºæ–‡ä»¶åæœ‰æ­£ç¡®çš„æ‰©å±•å
            if not output_filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                output_filename += '.jpg'

            # ä½¿ç”¨ä¸´æ—¶ç›®å½•
            import tempfile
            temp_dir = tempfile.gettempdir()
            output_path = os.path.join(temp_dir, f"{int(time.time())}_{output_filename}")

            # è®¾ç½®å›¾åƒè´¨é‡å‚æ•°
            quality_settings = {
                "high": ["-q:v", "2"],      # é«˜è´¨é‡
                "medium": ["-q:v", "5"],    # ä¸­ç­‰è´¨é‡
                "low": ["-q:v", "8"]        # ä½è´¨é‡
            }
            quality_params = quality_settings.get(image_quality, quality_settings["high"])

            # æå–æŒ‡å®šå¸§ï¼ˆä»é¦–å¸§å¼€å§‹åç§»ï¼‰
            frame_index = max(0, int(offset_from_first or 0))
            frame_path = self._extract_frame_by_index(video_path, output_path, quality_params, frame_index)

            # å¦‚æœæŒ‰ç´¢å¼•æå–å¤±è´¥ï¼Œå°è¯•æŒ‰æ—¶é—´æå–
            if not frame_path and offset_from_first and offset_from_first > 0:
                # ä½¿ç”¨fpsä¼°ç®—æ—¶é—´å®šä½
                _, fps = self._get_duration_and_fps(video_path)
                if fps:
                    seek_time = float(offset_from_first) / float(fps)
                    frame_path = self._extract_frame_by_time(video_path, output_path, quality_params, seek_time)

            # æœ€åå…œåº•ï¼šæå–é¦–å¸§ï¼ˆæ—¶é—´0ï¼‰
            if not frame_path:
                frame_path = self._extract_frame_by_time(video_path, output_path, quality_params, 0.0)

            if not frame_path:
                error_msg = "é¦–å¸§æå–å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            # å°†å›¾åƒè½¬æ¢ä¸ºComfyUIå¼ é‡æ ¼å¼
            image_tensor = self._load_image_as_tensor(frame_path)

            if image_tensor is None:
                error_msg = "å›¾åƒåŠ è½½å¤±è´¥"
                _log_error(error_msg)
                blank_image = self._create_blank_image()
                return (blank_image, f"âŒ {error_msg}")

            _log_info(f"âœ… é¦–å¸§æå–æˆåŠŸ: {frame_path}")
            return (image_tensor, frame_path)

        except Exception as e:
            error_msg = f"æå–è§†é¢‘é¦–å¸§å¤±è´¥: {str(e)}"
            _log_error(error_msg)
            blank_image = self._create_blank_image()
            return (blank_image, f"âŒ {error_msg}")

    def _extract_frame_by_index(self, video_path, output_path, quality_params, frame_index):
        """ä½¿ç”¨å¸§ç´¢å¼•æå–æŒ‡å®šå¸§ï¼ˆ0-basedï¼‰"""
        try:
            import subprocess
            # ä½¿ç”¨select=eq(n,frame_index) ç²¾ç¡®é€‰å¸§
            vf_expr = f"select='eq(n,{int(frame_index)})'"
            cmd = [
                'ffmpeg',
                '-i', video_path,
                '-vf', vf_expr,
                '-vsync', 'vfr',
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰ç´¢å¼•æå–å¸§: index={frame_index}, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰ç´¢å¼•æå–å¤±è´¥: {str(e)}")
            return None

    def _extract_frame_by_time(self, video_path, output_path, quality_params, seek_time):
        """æŒ‰æ—¶é—´å®šä½æå–å•å¸§ï¼ˆseek_timeä¸ºç§’ï¼‰"""
        try:
            import subprocess
            cmd = [
                'ffmpeg',
                '-ss', f"{seek_time}",
                '-i', video_path,
                '-frames:v', '1',
            ] + quality_params + [
                '-y',
                output_path
            ]
            _log_info(f"ğŸ”§ æŒ‰æ—¶é—´æå–å¸§: t={seek_time:.3f}s, cmd={' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=self.timeout)
            if result.returncode == 0 and os.path.exists(output_path):
                return output_path
            return None
        except Exception as e:
            _log_error(f"æŒ‰æ—¶é—´æå–å¤±è´¥: {str(e)}")
            return None

    def _get_duration_and_fps(self, video_path):
        """è¿”å›(duration_seconds, fps) æˆ– (None, None)"""
        try:
            import subprocess, json
            # è·å–æ—¶é•¿å’Œå¸§ç‡
            cmd = [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'v:0',
                '-show_entries', 'stream=avg_frame_rate:format=duration',
                '-of', 'json',
                video_path
            ]
            res = subprocess.run(cmd, capture_output=True, text=True, timeout=20)
            if res.returncode == 0 and res.stdout:
                data = json.loads(res.stdout)
                duration = None
                fps = None
                if 'format' in data and 'duration' in data['format']:
                    try:
                        duration = float(data['format']['duration'])
                    except:
                        duration = None
                if 'streams' in data and data['streams']:
                    afr = data['streams'][0].get('avg_frame_rate')
                    if afr and afr != '0/0':
                        try:
                            num, den = afr.split('/')
                            num = float(num)
                            den = float(den) if float(den) != 0 else 1.0
                            fps = num / den if den else None
                        except:
                            fps = None
                return duration, fps
        except Exception as e:
            _log_warning(f"æ— æ³•è·å–æ—¶é•¿ä¸FPS: {str(e)}")
        return None, None

    def _load_image_as_tensor(self, image_path):
        """å°†å›¾åƒæ–‡ä»¶åŠ è½½ä¸ºComfyUIå¼ é‡æ ¼å¼"""
        try:
            from PIL import Image
            import numpy as np
            import torch

            # ä½¿ç”¨PILåŠ è½½å›¾åƒ
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºRGBæ ¼å¼
                if img.mode != 'RGB':
                    img = img.convert('RGB')

                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                img_array = np.array(img).astype(np.float32) / 255.0

                # æ·»åŠ batchç»´åº¦ [H, W, C] -> [1, H, W, C]
                img_array = np.expand_dims(img_array, axis=0)

                # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
                img_tensor = torch.from_numpy(img_array)

                _log_info(f"âœ… å›¾åƒå¼ é‡æ ¼å¼: {img_tensor.shape}, dtype: {img_tensor.dtype}")
                return img_tensor

        except Exception as e:
            _log_error(f"å›¾åƒåŠ è½½å¤±è´¥: {str(e)}")
            return None

    def _extract_video_path(self, video):
        """ä»VIDEOå¯¹è±¡æå–æ–‡ä»¶è·¯å¾„"""
        _log_info(f"ğŸ” å°è¯•ä»VIDEOå¯¹è±¡æå–è·¯å¾„: {type(video)}")

        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
        if isinstance(video, str):
            _log_info(f"âœ… ç›´æ¥å­—ç¬¦ä¸²è·¯å¾„: {video}")
            return video

        # å°è¯•å¸¸è§çš„æ–‡ä»¶è·¯å¾„å±æ€§
        path_attributes = [
            'file_path',    # æˆ‘ä»¬è‡ªå·±çš„VideoFromFileå¯¹è±¡
            'filename',     # ä¸€äº›èŠ‚ç‚¹ä½¿ç”¨è¿™ä¸ª
            'file',         # å‘åå…¼å®¹
            'path',         # é€šç”¨è·¯å¾„å±æ€§
            'filepath',     # æ–‡ä»¶è·¯å¾„
            'video_path',   # è§†é¢‘è·¯å¾„
            'source',       # æºæ–‡ä»¶
            'url',          # URLè·¯å¾„
            'video_file',   # è§†é¢‘æ–‡ä»¶
            'file_name',    # æ–‡ä»¶å
        ]

        for attr in path_attributes:
            if hasattr(video, attr):
                value = getattr(video, attr)
                if value and isinstance(value, str):
                    _log_info(f"âœ… ä»å±æ€§ {attr} è·å–è·¯å¾„: {value}")
                    return value
                elif value:
                    _log_info(f"âš ï¸ å±æ€§ {attr} å­˜åœ¨ä½†ä¸æ˜¯å­—ç¬¦ä¸²: {type(value)} = {value}")

        # å¦‚æœæ˜¯å­—å…¸ç±»å‹ï¼Œå°è¯•ä»å­—å…¸ä¸­è·å–è·¯å¾„
        if isinstance(video, dict):
            for key in ['file_path', 'filename', 'path', 'url', 'source']:
                if key in video and isinstance(video[key], str):
                    _log_info(f"âœ… ä»å­—å…¸é”® {key} è·å–è·¯å¾„: {video[key]}")
                    return video[key]

        # å¦‚æœæœ‰__dict__å±æ€§ï¼Œæ‰“å°æ‰€æœ‰å±æ€§ç”¨äºè°ƒè¯•
        if hasattr(video, '__dict__'):
            _log_info(f"ğŸ” VIDEOå¯¹è±¡å±æ€§: {list(video.__dict__.keys())}")
            for key, value in video.__dict__.items():
                if isinstance(value, str) and ('path' in key.lower() or 'file' in key.lower() or 'url' in key.lower()):
                    _log_info(f"âœ… ä»__dict__å±æ€§ {key} è·å–è·¯å¾„: {value}")
                    return value

        # æœ€åå°è¯•ï¼šå¦‚æœå¯¹è±¡å¯ä»¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä¸”çœ‹èµ·æ¥åƒè·¯å¾„
        try:
            str_repr = str(video)
            if str_repr and ('/' in str_repr or '\\' in str_repr or str_repr.endswith('.mp4')):
                _log_info(f"âœ… ä»å­—ç¬¦ä¸²è¡¨ç¤ºè·å–è·¯å¾„: {str_repr}")
                return str_repr
        except:
            pass

        _log_error(f"âŒ æ— æ³•ä»VIDEOå¯¹è±¡æå–è·¯å¾„ï¼Œå¯¹è±¡ç±»å‹: {type(video)}")
        return None

    def _create_blank_image(self):
        """åˆ›å»ºç©ºç™½å›¾åƒå¼ é‡"""
        try:
            import numpy as np
            import torch
            # åˆ›å»º512x512çš„é»‘è‰²å›¾åƒ
            blank_array = np.zeros((1, 512, 512, 3), dtype=np.float32)
            # è½¬æ¢ä¸ºtorchå¼ é‡ï¼ˆComfyUIæœŸæœ›çš„æ ¼å¼ï¼‰
            blank_tensor = torch.from_numpy(blank_array)
            return blank_tensor
        except:
            return None




# ä¸UtilNodes-ComfyUIå®Œå…¨ä¸€è‡´çš„èŠ‚ç‚¹ï¼šVideoUtilitiesGetVHSFilePath
class VideoUtilitiesGetVHSFilePath:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "filenames": ("VHS_FILENAMES",),
                "sleep": ("INT", {"default": 3, "min": 0, "max": 60, "step": 1}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Get video file path from Video Combine node output"

    RETURN_TYPES = ("VIDEO",)
    RETURN_NAMES = ("AFVIDEO",)

    OUTPUT_NODE = False

    FUNCTION = "get_video_path"

    def get_video_path(self, filenames, sleep):
        import time, os, shutil

        if sleep > 0:
            time.sleep(sleep)

        # ä½¿ç”¨ComfyUIçš„è¾“å‡ºç›®å½•
        try:
            import folder_paths
            output_dir = folder_paths.get_output_directory()
        except Exception:
            output_dir = tempfile.gettempdir()

        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        # åªå¤„ç†å…ƒç»„æˆ–åˆ—è¡¨ä¸”ç¬¬äºŒé¡¹ä¸ºåˆ—è¡¨çš„æƒ…å†µ
        if isinstance(filenames, (tuple, list)) and len(filenames) >= 2 and isinstance(filenames[1], list):
            file_paths = filenames[1]
            # é€†åºæŸ¥æ‰¾æœ€åä¸€ä¸ªå­˜åœ¨çš„è§†é¢‘æ–‡ä»¶
            for path in reversed(file_paths):
                if isinstance(path, str) and path.lower().endswith((".mp4", ".webm", ".mkv", ".avi")) and os.path.exists(path):
                    # æ‹·è´åˆ°outputç›®å½•
                    new_path = os.path.join(output_dir, os.path.basename(path))
                    try:
                        shutil.copy2(path, new_path)
                    except Exception:
                        # æ‹·è´å¤±è´¥å°±è¿”å›åŸè·¯å¾„
                        return (path,)
                    return (new_path,)
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å­˜åœ¨çš„è§†é¢‘æ–‡ä»¶ï¼Œä¹Ÿå¯ä»¥åªè¿”å›æœ€åä¸€ä¸ªè§†é¢‘æ–‡ä»¶åï¼ˆä¸åˆ¤æ–­å­˜åœ¨æ€§ï¼‰
            for path in reversed(file_paths):
                if isinstance(path, str) and path.lower().endswith((".mp4", ".webm", ".mkv", ".avi")):
                    return (path,)
        # å…œåº•ï¼šè¿”å›ç©ºå­—ç¬¦ä¸²
        return ("",)

# å°†è§†é¢‘è½¬ä¸ºGIFçš„èŠ‚ç‚¹
class VideoToGIFNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video": ("VIDEO",),
                "fps": ("INT", {"default": 12, "min": 1, "max": 60, "step": 1}),
                "max_width": ("INT", {"default": 512, "min": 64, "max": 4096, "step": 16}),
                "max_size_mb": ("INT", {"default": 8, "min": 1, "max": 200, "step": 1}),
                "colors": ("INT", {"default": 128, "min": 2, "max": 256, "step": 1}),
                "dither": (["floyd_steinberg", "bayer", "none"], {"default": "floyd_steinberg"}),
                "loop": ("INT", {"default": 0, "min": 0, "max": 1000, "step": 1}),
            },
            "optional": {
                "keep_aspect": ("BOOLEAN", {"default": True}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Convert a video file to GIF with controllable quality and size"

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("GIF_PATH", "STATUS")

    OUTPUT_NODE = False

    FUNCTION = "convert_to_gif"

    def _extract_video_path(self, video):
        try:
            if isinstance(video, str):
                return video
            for attr in ["file_path", "filename", "file", "path", "filepath", "video_path"]:
                if hasattr(video, attr):
                    val = getattr(video, attr)
                    if isinstance(val, str) and val:
                        return val
            if isinstance(video, dict):
                for k in ["file_path", "filename", "path", "url", "source"]:
                    if k in video and isinstance(video[k], str):
                        return video[k]
            s = str(video)
            if s and ("/" in s or "\\" in s) and s.lower().endswith((".mp4", ".webm", ".mkv", ".avi")):
                return s
        except:
            pass
        return None

    def _ensure_output_dir(self):
        try:
            import folder_paths
            out_dir = folder_paths.get_output_directory()
        except Exception:
            out_dir = tempfile.gettempdir()
        os.makedirs(out_dir, exist_ok=True)
        return out_dir

    def _run_ffmpeg_gif(self, src, dst, fps, width, colors, dither, loop):
        palette = dst + ".palette.png"
        vf_scale = f"scale={width}:-1:flags=lanczos"
        palettegen = [
            "-vf", f"fps={fps},{vf_scale},palettegen=max_colors={colors}:stats_mode=full"
        ]
        paletteuse = [
            "-lavfi", f"fps={fps},{vf_scale} [x]; [x][1:v] paletteuse=dither={dither}:diff_mode=rectangle"
        ]
        # ç”Ÿæˆè°ƒè‰²æ¿
        cmd1 = [
            "ffmpeg", "-y", "-i", src,
        ] + palettegen + [palette]
        # ä½¿ç”¨è°ƒè‰²æ¿ç”Ÿæˆgif
        cmd2 = [
            "ffmpeg", "-y", "-i", src, "-i", palette,
            "-loop", str(loop),
        ] + paletteuse + [dst]

        r1 = subprocess.run(cmd1, capture_output=True)
        if r1.returncode != 0:
            return False, f"palettegen failed: {r1.stderr.decode(errors='ignore')[:200]}"
        r2 = subprocess.run(cmd2, capture_output=True)
        try:
            os.unlink(palette)
        except:
            pass
        if r2.returncode != 0:
            return False, f"gif encode failed: {r2.stderr.decode(errors='ignore')[:200]}"
        return True, "ok"

    def convert_to_gif(self, video, fps, max_width, max_size_mb, colors, dither, loop, keep_aspect=True):
        try:
            _log_info("[Video_To_GIF] start")
            src = self._extract_video_path(video)
            if not src or not os.path.exists(src):
                _log_error(f"[Video_To_GIF] source not found: {src}")
                return {"ui": {}, "result": ("", f"Video not found: {src}")}

            out_dir = self._ensure_output_dir()
            base = os.path.splitext(os.path.basename(src))[0]
            dst = os.path.join(out_dir, f"{base}_{int(time.time())}.gif")

            # è‡ªé€‚åº”å‹ç¼©å¾ªç¯
            attempt_fps = int(max(1, fps))
            attempt_width = int(max(64, min(max_width, 4096)))
            min_width = 64
            status = ""

            for _ in range(12):
                ok, msg = self._run_ffmpeg_gif(src, dst, attempt_fps, attempt_width, int(colors), dither, int(loop))
                if not ok:
                    status = msg
                    break
                size_mb = os.path.getsize(dst) / (1024 * 1024)
                if size_mb <= max_size_mb:
                    status = f"OK {size_mb:.2f}MB @ {attempt_fps}fps {attempt_width}px {colors}c dither={dither}"
                    video_name = os.path.basename(dst)
                    video_path_name = os.path.basename(os.path.dirname(dst))
                    _log_info(f"[Video_To_GIF] success {video_name} {size_mb:.2f}MB")
                    return {"ui": {"video": [video_name, video_path_name]}, "result": (dst, status)}
                # è¿‡å¤§åˆ™è°ƒæ•´ï¼šä¼˜å…ˆé™fpsï¼Œå…¶æ¬¡é™å®½åº¦
                if attempt_fps > 6:
                    attempt_fps = max(6, int(attempt_fps * 0.8))
                elif attempt_width > min_width:
                    attempt_width = max(min_width, int(attempt_width * 0.85))
                else:
                    break

            # è‹¥å¤±è´¥ï¼Œç»™å‡ºçŠ¶æ€
            if os.path.exists(dst):
                size_mb = os.path.getsize(dst) / (1024 * 1024)
                status = status or f"Exceeded target: {size_mb:.2f}MB (target {max_size_mb}MB)"
                video_name = os.path.basename(dst)
                video_path_name = os.path.basename(os.path.dirname(dst))
                _log_info(f"[Video_To_GIF] finished with warnings {video_name} {size_mb:.2f}MB")
                return {"ui": {"video": [video_name, video_path_name]}, "result": (dst, status)}
            _log_error(f"[Video_To_GIF] failed: {status}")
            return {"ui": {}, "result": ("", status or "GIF conversion failed")}
        except Exception as e:
            _log_error(f"[Video_To_GIF] exception: {e}")
            return {"ui": {}, "result": ("", f"Error: {str(e)}")}

class PreviewGIFNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "gif_path": ("STRING", {"default": ""}),
                "copy_to_output": ("BOOLEAN", {"default": True}),
            }
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Preview a GIF file in browser or external media player"

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("file_path",)
    OUTPUT_NODE = True
    FUNCTION = "preview"

    def _ensure_output_dir(self):
        try:
            import folder_paths
            out_dir = folder_paths.get_output_directory()
        except Exception:
            out_dir = tempfile.gettempdir()
        os.makedirs(out_dir, exist_ok=True)
        return out_dir

    def preview(self, gif_path, copy_to_output=True):
        if not gif_path or not os.path.exists(gif_path):
            return {"ui": {}, "result": ("",)}

        final_path = gif_path
        if copy_to_output:
            out_dir = self._ensure_output_dir()
            new_path = os.path.join(out_dir, os.path.basename(gif_path))
            if os.path.abspath(new_path) != os.path.abspath(gif_path):
                try:
                    shutil.copy2(gif_path, new_path)
                    final_path = new_path
                except Exception:
                    final_path = gif_path

        # å¯ç”¨ UI é¢„è§ˆï¼Œå¤ç”¨ç»Ÿä¸€å‰ç«¯ï¼ˆvideo_preview.jsï¼‰
        video_name = os.path.basename(final_path)
        video_path_name = os.path.basename(os.path.dirname(final_path))
        return {"ui": {"video": [video_name, video_path_name]}, "result": (final_path,)}


    def _open_in_browser(self, file_path):
        """åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ–‡ä»¶"""
        try:
            import webbrowser
            import urllib.parse
            # å°†æ–‡ä»¶è·¯å¾„è½¬æ¢ä¸º file:// URL
            file_url = urllib.parse.urljoin('file:', urllib.request.pathname2url(os.path.abspath(file_path)))
            webbrowser.open(file_url)
            _log_info(f"ğŸŒ å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€: {file_path}")
        except Exception as e:
            _log_error(f"âŒ æ— æ³•åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æ–‡ä»¶: {e}")

    def _open_in_media_player(self, file_path):
        """åœ¨ç³»ç»Ÿé»˜è®¤åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€æ–‡ä»¶"""
        try:
            import subprocess
            import platform
            
            system = platform.system()
            if system == "Windows":
                os.startfile(file_path)
            elif system == "Darwin":  # macOS
                subprocess.run(["open", file_path])
            elif system == "Linux":
                subprocess.run(["xdg-open", file_path])
            else:
                # é€šç”¨æ–¹æ³•
                subprocess.run(["open", file_path])
            
            _log_info(f"ğŸ¬ å·²åœ¨åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€: {file_path}")
        except Exception as e:
            _log_error(f"âŒ æ— æ³•åœ¨åª’ä½“æ’­æ”¾å™¨ä¸­æ‰“å¼€æ–‡ä»¶: {e}")

class VideoPreviewNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {"required":{
            "video":("VIDEO",),
        }}
    
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Preview video with clear previous content"

    RETURN_TYPES = ()

    OUTPUT_NODE = True

    FUNCTION = "load_video"

    def load_video(self, video):
        # ä» VIDEO å¯¹è±¡ä¸­æå–å®é™…çš„æ–‡ä»¶è·¯å¾„
        video_path = extract_video_path(video)

        if not video_path:
            _log_error("âŒ VideoPreviewNode: æ— æ³•ä» VIDEO å¯¹è±¡ä¸­æå–æ–‡ä»¶è·¯å¾„")
            return {"ui": {"text": ["Error: Cannot extract video path"]}}

        if not os.path.exists(video_path):
            _log_error(f"âŒ VideoPreviewNode: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return {"ui": {"text": [f"Error: Video file not found: {os.path.basename(video_path)}"]}}

        # æ£€æŸ¥è§†é¢‘ç¼–ç æ ¼å¼ï¼Œç‰¹åˆ«æ˜¯ Topaz å¤„ç†çš„ MPEG-4 è§†é¢‘
        codec_warning = None
        try:
            import subprocess
            probe_cmd = [
                "ffprobe", "-v", "quiet", "-select_streams", "v:0",
                "-show_entries", "stream=codec_name", "-of", "csv=p=0", video_path
            ]
            probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
            if probe_result.returncode == 0:
                codec_name = probe_result.stdout.strip()
                _log_info(f"ğŸ¬ VideoPreviewNode: æ£€æµ‹åˆ°è§†é¢‘ç¼–ç : {codec_name}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ MPEG-4 part 2 ç¼–ç ï¼ˆTopaz å¸¸ç”¨ï¼‰
                if codec_name == "mpeg4":
                    is_topaz = "topaz" in os.path.basename(video_path).lower()
                    if is_topaz:
                        _log_warning(f"âš ï¸ VideoPreviewNode: æ£€æµ‹åˆ° Topaz Video AI å¤„ç†çš„ MPEG-4 è§†é¢‘ï¼Œæµè§ˆå™¨é¢„è§ˆå¯èƒ½æœ‰é—®é¢˜")
                        codec_warning = "topaz_mpeg4"
                    else:
                        _log_warning(f"âš ï¸ VideoPreviewNode: æ£€æµ‹åˆ° MPEG-4 part 2 ç¼–ç ï¼Œæµè§ˆå™¨é¢„è§ˆå¯èƒ½æœ‰é—®é¢˜")
                        codec_warning = "mpeg4"
        except Exception as e:
            _log_warning(f"âš ï¸ VideoPreviewNode: æ— æ³•æ£€æµ‹è§†é¢‘ç¼–ç : {e}")

        video_name = os.path.basename(video_path)
        video_dir = os.path.dirname(video_path)
        video_path_name = os.path.basename(video_dir)

        _log_info(f"ğŸ¬ VideoPreviewNode è·¯å¾„ä¿¡æ¯:")
        _log_info(f"   - video_path: {video_path}")
        _log_info(f"   - video_dir: {video_dir}")
        _log_info(f"   - video_name: {video_name}")
        _log_info(f"   - video_path_name: {video_path_name}")

        # æ„å»ºè¿”å›çš„ UI æ•°æ®
        ui_data = {"video": [video_name, video_path_name]}

        # å¦‚æœæ£€æµ‹åˆ°ç¼–ç é—®é¢˜ï¼Œæ·»åŠ è­¦å‘Šä¿¡æ¯
        if codec_warning:
            ui_data["codec_warning"] = codec_warning
            ui_data["video_path"] = video_path  # æ·»åŠ å®Œæ•´è·¯å¾„ç”¨äºå‰ç«¯åˆ¤æ–­

        _log_info(f"ğŸ¬ VideoPreviewNode è¿”å›æ•°æ®: {ui_data}")

        # ä½¿ç”¨clearå‚æ•°æ¥æ¸…é™¤ä¹‹å‰çš„è§†é¢‘é¢„è§ˆ
        result = {"ui": ui_data, "clear": True}
        _log_info(f"ğŸ¬ VideoPreviewNode å®Œæ•´è¿”å›: {result}")
        return result

class VideoUtilitiesUploadLiveVideo:
    @classmethod
    def INPUT_TYPES(s):
        # è·å–è§†é¢‘æ–‡ä»¶æ‰©å±•å
        video_extensions = ["mp4", "webm", "mkv", "avi"]

        # æ”¶é›†æ‰€æœ‰è§†é¢‘æ–‡ä»¶åŠå…¶ä¿®æ”¹æ—¶é—´
        all_files = []

        # æ‰«æ input ç›®å½•
        if os.path.exists(input_dir):
            for f in os.listdir(input_dir):
                if os.path.isfile(os.path.join(input_dir, f)) and f.split('.')[-1].lower() in video_extensions:
                    file_path = os.path.join(input_dir, f)
                    mtime = os.path.getmtime(file_path)
                    all_files.append((f, mtime))

        # æ‰«æ output ç›®å½•ï¼ˆè·³è¿‡åŒåæ–‡ä»¶ï¼‰
        if os.path.exists(output_dir):
            existing_names = {f for f, _ in all_files}
            for f in os.listdir(output_dir):
                if os.path.isfile(os.path.join(output_dir, f)) and f.split('.')[-1].lower() in video_extensions:
                    if f not in existing_names:  # é¿å…é‡å¤
                        file_path = os.path.join(output_dir, f)
                        mtime = os.path.getmtime(file_path)
                        all_files.append((f, mtime))

        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        all_files.sort(key=lambda x: x[1], reverse=True)

        # æå–æ–‡ä»¶åï¼ˆä¸å¸¦å‰ç¼€ï¼‰
        files = [f for f, _ in all_files]

        if not files:
            files = ["No video files found"]

        return {"required":{
            "video":(files,),
        },
        "optional":{
            "upload":("VIDEOPLOAD_LIVE",),
        },
        }
    
    @classmethod
    def VALIDATE_INPUTS(s, video, **kwargs):
        """éªŒè¯è¾“å…¥ï¼Œå…è®¸åŠ¨æ€æ–‡ä»¶åï¼ˆå¦‚ä¸Šä¼ çš„æ–‡ä»¶ï¼‰"""
        # å¦‚æœæ˜¯é»˜è®¤é€‰é¡¹ï¼Œç›´æ¥é€šè¿‡éªŒè¯
        if video == "No video files found":
            return True

        # å°è¯•åœ¨ input å’Œ output ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        input_path = os.path.join(input_dir, video)
        output_path = os.path.join(output_dir, video)

        # å¦‚æœæ–‡ä»¶å­˜åœ¨äºä»»ä¸€ç›®å½•ï¼ŒéªŒè¯é€šè¿‡
        if os.path.exists(input_path) or os.path.exists(output_path):
            return True

        # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿè¿”å› Trueï¼Œå…è®¸ä¸Šä¼ åŠŸèƒ½
        # ä¸Šä¼ åæ–‡ä»¶ä¼šå‡ºç°åœ¨ input ç›®å½•
        return True
    
    @classmethod
    def IS_CHANGED(s, **kwargs):
        # åªè¦æœ‰å‚æ•°å˜åŒ–å°±å¼ºåˆ¶åˆ·æ–°ä¸‹æ‹‰é€‰é¡¹
        import random
        return random.random()
    
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Upload and live video loader with preview functionality"

    RETURN_TYPES = ("IMAGE", "AUDIO", "VHS_FILENAMES", "INT", "INT", "STRING",)
    RETURN_NAMES = ("IMAGE", "AUDIO", "FILENAMES", "FILE_AGE", "FRAME_COUNT", "STATUS",)

    OUTPUT_NODE = False

    FUNCTION = "load_video"

    def load_video(self, video, **kwargs):
        # å…¼å®¹ç›´æ¥ä¼ å…¥hashæ–‡ä»¶å
        if video.startswith("[Output] "):
            actual_filename = video[9:]  # ç§»é™¤ "[Output] " å‰ç¼€
            video_path = os.path.join(output_dir, actual_filename)
        elif video.startswith("[Input] "):
            actual_filename = video[8:]  # ç§»é™¤ "[Input] " å‰ç¼€
            video_path = os.path.join(input_dir, actual_filename)
        elif os.path.exists(os.path.join(input_dir, video)):
            actual_filename = video
            video_path = os.path.join(input_dir, video)
        elif os.path.exists(os.path.join(output_dir, video)):
            actual_filename = video
            video_path = os.path.join(output_dir, video)
        elif video.startswith("--- ") or video == "No video files found":
            # åˆ†ç±»æ ‡ç­¾æˆ–æ— æ–‡ä»¶æƒ…å†µ
            return (None, None, "", 0, "Please select a valid video file")
        else:
            # å…¼å®¹æ—§æ ¼å¼ï¼Œé»˜è®¤ä»inputç›®å½•
            actual_filename = video
            video_path = os.path.join(input_dir, video)
        
        video_filename = os.path.basename(video_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            return (None, None, (False, []), 0, f"Video file not found: {video_filename}")
        
        # è®¡ç®—æ–‡ä»¶å¹´é¾„ï¼ˆç§’ï¼‰
        file_age = int(time.time() - os.path.getmtime(video_path))
        
        # æå–éŸ³é¢‘
        try:
            import subprocess
            # æ ¹æ®è§†é¢‘æ¥æºé€‰æ‹©ä¸´æ—¶æ–‡ä»¶ç›®å½•
            temp_dir = output_dir if video.startswith("[Output] ") else input_dir
            with tempfile.NamedTemporaryFile(suffix=".wav", dir=temp_dir, delete=False) as aud:
                cmd = [
                    "ffmpeg", "-nostdin", "-hide_banner", "-loglevel", "error",
                    "-i", video_path, "-vn", "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "1",
                    aud.name, "-y"
                ]
                proc = subprocess.run(cmd, capture_output=True)
            if proc.returncode == 0 and os.path.exists(aud.name) and os.path.getsize(aud.name) > 0:
                waveform, sample_rate = torchaudio.load(aud.name)
                audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
            else:
                audio = None
            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            try:
                os.unlink(aud.name)
            except:
                pass
        except:
            audio = None
        
        # æå–è§†é¢‘å¸§ä½œä¸ºå›¾åƒåºåˆ—
        try:
            cap = cv2.VideoCapture(video_path)
            
            # è·å–è§†é¢‘çš„æ€»å¸§æ•°
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            
            print(f"[VideoUtilitiesUploadLiveVideo] Video info: {total_frames} frames, {fps:.2f} fps")
            
            frames = []
            frame_count = 0
            
            # è¯»å–æ‰€æœ‰å¸§
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è½¬æ¢BGRåˆ°RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # éªŒè¯frame_rgbçš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹
                print(f"[VideoUtilitiesUploadLiveVideo] Frame RGB shape: {frame_rgb.shape}, dtype: {frame_rgb.dtype}")
                
                # ç›´æ¥è½¬æ¢ä¸ºtorch tensor
                frame_tensor = torch.from_numpy(frame_rgb).float()
                # è½¬æ¢ä¸º0-1èŒƒå›´
                frame_tensor = frame_tensor / 255.0
                
                # ç¡®ä¿ç»´åº¦é¡ºåºæ­£ç¡®ï¼š(H, W, C) -> (C, H, W)
                if frame_tensor.dim() == 3:
                    # éªŒè¯è¾“å…¥æ ¼å¼
                    H, W, C = frame_tensor.shape
                    print(f"[VideoUtilitiesUploadLiveVideo] Frame tensor before permute: H={H}, W={W}, C={C}")
                    
                    if C != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3 channels, got {C}")
                        continue
                    
                    frame_tensor = frame_tensor.permute(2, 0, 1)  # (3, H, W)
                    print(f"[VideoUtilitiesUploadLiveVideo] Frame tensor after permute: {frame_tensor.shape}")
                    
                    # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
                    frame_tensor = frame_tensor.float()
                    
                    # éªŒè¯å€¼èŒƒå›´
                    if frame_tensor.min() < 0.0 or frame_tensor.max() > 1.0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Warning: Values outside [0,1] range: min={frame_tensor.min():.3f}, max={frame_tensor.max():.3f}")
                        frame_tensor = torch.clamp(frame_tensor, 0.0, 1.0)
                    
                    # æœ€ç»ˆéªŒè¯
                    if frame_tensor.shape[0] != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Final tensor should have 3 channels, got {frame_tensor.shape[0]}")
                        continue
                else:
                    print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3D tensor (H, W, C), got {frame_tensor.shape}")
                    continue
                
                frames.append(frame_tensor)
                frame_count += 1
            
            cap.release()
            
            if frames:
                # å †å æ‰€æœ‰å¸§ï¼Œæ ¼å¼ä¸º(batch_size, channels, height, width)
                image_tensor = torch.stack(frames, dim=0)  # (N, 3, H, W) å…¶ä¸­Næ˜¯å®é™…å¸§æ•°
                # ç¡®ä¿æ•°æ®ç±»å‹ä¸ºfloat32
                image_tensor = image_tensor.float()
                
                # éªŒè¯tensoræ ¼å¼
                if len(image_tensor.shape) == 4:
                    N, C, H, W = image_tensor.shape
                    print(f"[VideoUtilitiesUploadLiveVideo] Extracted {N} frames, tensor shape: {image_tensor.shape}")
                    print(f"[VideoUtilitiesUploadLiveVideo] Format: (N={N}, C={C}, H={H}, W={W})")
                    
                    # ç¡®ä¿å€¼èŒƒå›´åœ¨0-1ä¹‹é—´
                    if image_tensor.max() > 1.0 or image_tensor.min() < 0.0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Warning: Values outside [0,1] range: min={image_tensor.min():.3f}, max={image_tensor.max():.3f}")
                        image_tensor = torch.clamp(image_tensor, 0.0, 1.0)
                    
                    # ç¡®ä¿tensoræ ¼å¼å®Œå…¨æ­£ç¡®
                    if C != 3:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Expected 3 channels, got {C}")
                        image_tensor = None
                    elif H <= 0 or W <= 0:
                        print(f"[VideoUtilitiesUploadLiveVideo] Error: Invalid dimensions H={H}, W={W}")
                        image_tensor = None
                    else:
                        # è½¬æ¢ä¸ºVideoHelperSuiteå…¼å®¹æ ¼å¼ï¼š(N, C, H, W) -> (N, H, W, C)
                        image_tensor = image_tensor.permute(0, 2, 3, 1)  # (N, H, W, C)
                        print(f"[VideoUtilitiesUploadLiveVideo] Converted to VideoHelperSuite format: (N={N}, H={H}, W={W}, C={C})")
                else:
                    print(f"[VideoUtilitiesUploadLiveVideo] Error: Unexpected tensor shape: {image_tensor.shape}")
                    image_tensor = None
            else:
                image_tensor = None
        except Exception as e:
            print(f"[VideoUtilitiesUploadLiveVideo] Error extracting image: {e}")
            image_tensor = None
        
        # è¿”å›ç»“æœï¼ŒåŒ…å«çŠ¶æ€ä¿¡æ¯
        if video_path:
            # è·å–æ–‡ä»¶å¤§å°å’Œåˆ›å»ºæ—¶é—´
            try:
                file_size = os.path.getsize(video_path)
                file_size_mb = file_size / (1024 * 1024)
                # è·å–æ–‡ä»¶åˆ›å»ºæ—¶é—´
                create_time = time.localtime(os.path.getctime(video_path))
                create_time_str = time.strftime("%Y-%m-%d %H:%M:%S", create_time)
                status = f"Loaded: {video_filename} ({file_size_mb:.1f}MB, created: {create_time_str})"
            except:
                # å¦‚æœè·å–åˆ›å»ºæ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨ä¿®æ”¹æ—¶é—´
                try:
                    modify_time = time.localtime(os.path.getmtime(video_path))
                    modify_time_str = time.strftime("%Y-%m-%d %H:%M:%S", modify_time)
                    status = f"Loaded: {video_filename} (modified: {modify_time_str})"
                except:
                    status = f"Loaded: {video_filename}"
        else:
            status = "No video found"

        # VHS_FILENAMES å…¼å®¹è¾“å‡ºï¼ˆä¸ Video Combine èŠ‚ç‚¹ä¸€è‡´ï¼‰ï¼š(bool, [full_paths])
        vhs_filenames = (True, [video_path]) if os.path.exists(video_path) else (False, [])
        frame_count = int(total_frames) if 'total_frames' in locals() else 0
        return (image_tensor, audio, vhs_filenames, file_age, frame_count, status)

class VideoUtilitiesLoadAFVideo:
    @classmethod
    def INPUT_TYPES(s):
        # æ‰«æ input å’Œ output ç›®å½•åŠå…¶å­æ–‡ä»¶å¤¹ä¸­çš„è§†é¢‘æ–‡ä»¶
        files = []
        video_extensions = ["mp4", "webm", "mkv", "avi"]

        # æ‰«æ input ç›®å½•
        if os.path.exists(input_dir):
            # æ‰«ææ ¹ç›®å½•
            for f in os.listdir(input_dir):
                file_path = os.path.join(input_dir, f)
                if os.path.isfile(file_path) and f.split('.')[-1].lower() in video_extensions:
                    # ä¸æ·»åŠ å‰ç¼€ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶å
                    if f not in files:
                        files.append(f)

            # æ‰«æå­æ–‡ä»¶å¤¹ï¼ˆä¸€å±‚ï¼‰
            for item in os.listdir(input_dir):
                item_path = os.path.join(input_dir, item)
                if os.path.isdir(item_path):
                    for f in os.listdir(item_path):
                        file_path = os.path.join(item_path, f)
                        if os.path.isfile(file_path) and f.split('.')[-1].lower() in video_extensions:
                            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„æ ¼å¼ï¼šsubfolder/filename
                            relative_path = f"{item}/{f}"
                            if relative_path not in files:
                                files.append(relative_path)

        # æ‰«æ output ç›®å½•
        if os.path.exists(output_dir):
            # æ‰«ææ ¹ç›®å½•
            for f in os.listdir(output_dir):
                file_path = os.path.join(output_dir, f)
                if os.path.isfile(file_path) and f.split('.')[-1].lower() in video_extensions:
                    # ä¸æ·»åŠ å‰ç¼€ï¼Œä½†å¦‚æœ input ç›®å½•å·²æœ‰åŒåæ–‡ä»¶ï¼Œåˆ™è·³è¿‡
                    # è¿™æ ·ä¼˜å…ˆæ˜¾ç¤º input ç›®å½•çš„æ–‡ä»¶
                    if f not in files:
                        files.append(f)

            # æ‰«æå­æ–‡ä»¶å¤¹ï¼ˆä¸€å±‚ï¼‰
            for item in os.listdir(output_dir):
                item_path = os.path.join(output_dir, item)
                if os.path.isdir(item_path):
                    for f in os.listdir(item_path):
                        file_path = os.path.join(item_path, f)
                        if os.path.isfile(file_path) and f.split('.')[-1].lower() in video_extensions:
                            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„æ ¼å¼ï¼šsubfolder/filename
                            relative_path = f"{item}/{f}"
                            if relative_path not in files:
                                files.append(relative_path)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶ï¼Œæ·»åŠ æç¤ºä¿¡æ¯
        if not files:
            files.append("No video files found")

        return {"required":{
            "video":(files,),
        },
        "optional":{
            "upload":("VIDEOPLOAD",),
        },
        }

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Load Audio/Video File with preview functionality"

    RETURN_TYPES = ("VIDEO","AUDIO",)

    OUTPUT_NODE = False

    FUNCTION = "load_video"

    @classmethod
    def VALIDATE_INPUTS(s, video, **kwargs):
        """éªŒè¯è¾“å…¥ï¼Œå…è®¸åŠ¨æ€æ–‡ä»¶åï¼ˆå¦‚ä¸Šä¼ çš„æ–‡ä»¶ï¼‰"""
        # å¦‚æœæ˜¯é»˜è®¤é€‰é¡¹ï¼Œç›´æ¥é€šè¿‡éªŒè¯
        if video == "No video files found":
            return True

        # å°è¯•åœ¨ input å’Œ output ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        input_path = os.path.join(input_dir, video)
        output_path = os.path.join(output_dir, video)

        # å¦‚æœæ–‡ä»¶å­˜åœ¨äºä»»ä¸€ç›®å½•ï¼ŒéªŒè¯é€šè¿‡
        if os.path.exists(input_path) or os.path.exists(output_path):
            return True

        # å³ä½¿æ–‡ä»¶ä¸å­˜åœ¨ä¹Ÿè¿”å› Trueï¼Œå…è®¸ä¸Šä¼ åŠŸèƒ½
        # ä¸Šä¼ åæ–‡ä»¶ä¼šå‡ºç°åœ¨ input ç›®å½•
        return True

    @classmethod
    def IS_CHANGED(s, video):
        # ä¼˜å…ˆåœ¨ input ç›®å½•æŸ¥æ‰¾ï¼Œæ‰¾ä¸åˆ°å†å» output ç›®å½•
        input_path = os.path.join(input_dir, video)
        output_path = os.path.join(output_dir, video)

        if os.path.exists(input_path):
            return os.path.getmtime(input_path)
        elif os.path.exists(output_path):
            return os.path.getmtime(output_path)

        return float("nan")

    def load_video(self, video):
        # ä¼˜å…ˆåœ¨ input ç›®å½•æŸ¥æ‰¾ï¼Œæ‰¾ä¸åˆ°å†å» output ç›®å½•
        input_path = os.path.join(input_dir, video)
        output_path = os.path.join(output_dir, video)

        if os.path.exists(input_path):
            video_path = input_path
            base_dir = input_dir
        elif os.path.exists(output_path):
            video_path = output_path
            base_dir = output_dir
        else:
            # é»˜è®¤ä½¿ç”¨ input ç›®å½•ï¼ˆå¯èƒ½æ˜¯å³å°†ä¸Šä¼ çš„æ–‡ä»¶ï¼‰
            video_path = input_path
            base_dir = input_dir

        _log_info(f"ğŸ¬ Load_AF_Video: video={video}")
        _log_info(f"ğŸ¬ Load_AF_Video: base_dir={base_dir}")
        _log_info(f"ğŸ¬ Load_AF_Video: video_path={video_path}")

        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            _log_error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return (None, None)

        # æ£€æŸ¥è§†é¢‘ç¼–ç æ ¼å¼ï¼Œç‰¹åˆ«æ˜¯ Topaz å¤„ç†çš„ MPEG-4 è§†é¢‘
        try:
            import subprocess
            probe_cmd = [
                "ffprobe", "-v", "quiet", "-print_format", "json",
                "-show_streams", "-select_streams", "v:0", video_path
            ]
            probe_result = subprocess.run(probe_cmd, capture_output=True, text=True)
            if probe_result.returncode == 0:
                import json
                probe_data = json.loads(probe_result.stdout)
                if probe_data.get("streams"):
                    codec_name = probe_data["streams"][0].get("codec_name", "unknown")
                    _log_info(f"ğŸ¬ æ£€æµ‹åˆ°è§†é¢‘ç¼–ç : {codec_name}")

                    # å¦‚æœæ˜¯ MPEG-4 part 2 ç¼–ç ï¼ˆTopaz å¸¸ç”¨ï¼‰ï¼Œè®°å½•è­¦å‘Š
                    if codec_name == "mpeg4":
                        _log_warning(f"âš ï¸ æ£€æµ‹åˆ° MPEG-4 part 2 ç¼–ç ï¼ˆå¯èƒ½æ¥è‡ª Topaz Video AIï¼‰ï¼ŒæŸäº›æµè§ˆå™¨å¯èƒ½ä¸æ”¯æŒé¢„è§ˆ")
        except Exception as e:
            _log_warning(f"âš ï¸ æ— æ³•æ£€æµ‹è§†é¢‘ç¼–ç : {e}")

        # ç›´æ¥è¿”å›è·¯å¾„å­—ç¬¦ä¸²ï¼Œä»¥ä¿æŒä¸å…¶ä»–èŠ‚ç‚¹çš„å…¼å®¹æ€§
        # ä¸ä½¿ç”¨ VideoFromFile å¯¹è±¡ï¼Œå› ä¸ºå¾ˆå¤šèŠ‚ç‚¹ï¼ˆå¦‚ ProPainterï¼‰æœŸæœ›å­—ç¬¦ä¸²è·¯å¾„
        video_obj = video_path
        _log_info(f"âœ… Load AF Video è¿”å›è·¯å¾„å­—ç¬¦ä¸²: {video_path}")

        try:
            import subprocess
            _log_info(f"ğŸµ å¼€å§‹æå–éŸ³é¢‘: {video_path}")

            with tempfile.NamedTemporaryFile(suffix=".wav",dir=input_dir,delete=False) as aud:
                temp_audio_path = aud.name

            cmd = [
                "ffmpeg", "-nostdin", "-hide_banner", "-loglevel", "error",
                "-i", video_path, "-vn", "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "1",
                temp_audio_path, "-y"
            ]
            _log_info(f"ğŸµ FFmpeg å‘½ä»¤: {' '.join(cmd)}")

            proc = subprocess.run(cmd, capture_output=True, text=True)

            if proc.returncode != 0:
                _log_error(f"âŒ FFmpeg æå–éŸ³é¢‘å¤±è´¥ (è¿”å›ç : {proc.returncode})")
                if proc.stderr:
                    _log_error(f"âŒ FFmpeg é”™è¯¯: {proc.stderr}")
                audio = None
            elif not os.path.exists(temp_audio_path):
                _log_error(f"âŒ ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {temp_audio_path}")
                audio = None
            elif os.path.getsize(temp_audio_path) == 0:
                _log_warning(f"âš ï¸ è§†é¢‘æ²¡æœ‰éŸ³é¢‘è½¨é“æˆ–éŸ³é¢‘ä¸ºç©º")
                audio = None
            else:
                _log_info(f"âœ… éŸ³é¢‘æå–æˆåŠŸï¼Œæ–‡ä»¶å¤§å°: {os.path.getsize(temp_audio_path)} bytes")
                try:
                    waveform, sample_rate = torchaudio.load(temp_audio_path)
                    audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
                    _log_info(f"âœ… éŸ³é¢‘åŠ è½½æˆåŠŸï¼Œé‡‡æ ·ç‡: {sample_rate}, æ³¢å½¢å½¢çŠ¶: {waveform.shape}")
                except Exception as e:
                    _log_error(f"âŒ åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                    audio = None

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(temp_audio_path):
                    os.unlink(temp_audio_path)
                    _log_info(f"ğŸ—‘ï¸ å·²åˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶")
            except Exception as e:
                _log_warning(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

        except Exception as e:
            _log_error(f"âŒ éŸ³é¢‘æå–è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            _log_error(traceback.format_exc())
            audio = None
        return (video_obj,audio,)

class VideoUtilitiesPromptTextNode:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "text": ("STRING", {"multiline": True, "dynamicPrompts": True, "tooltip": "The text to be encoded."}),
            }
        }

    RETURN_TYPES = ("STRING",)

    FUNCTION = "encode"

    CATEGORY = "Ken-Chen/Video_Utilities"

    def encode(self, text):
        return (text,)

class VideoUtilitiesLiveVideoMonitor:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "refresh_interval": ("INT", {"default": 2, "min": 1, "max": 60, "step": 1, "tooltip": "Refresh interval in seconds"}),
                "auto_refresh": ("BOOLEAN", {"default": True, "tooltip": "Enable automatic refresh"}),
                "min_file_age": ("INT", {"default": 1, "min": 0, "max": 10, "step": 1, "tooltip": "Minimum file age in seconds to avoid loading incomplete files"}),
            }
        }

    @classmethod
    def IS_CHANGED(s, **kwargs):
        return float("nan")

    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Live video loader that monitors output directory for latest video files"

    RETURN_TYPES = ("IMAGE", "AUDIO", "VHS_FILENAMES", "INT", "INT", "STRING",)
    RETURN_NAMES = ("IMAGE", "AUDIO", "FILENAMES", "FILE_AGE", "FRAME_COUNT", "STATUS",)

    OUTPUT_NODE = True

    FUNCTION = "load_latest_video"

    def load_latest_video(self, refresh_interval, auto_refresh, min_file_age):
        video_extensions = ["*.mp4", "*.webm", "*.mkv", "*.avi"]
        video_files = []
        for ext in video_extensions:
            video_files.extend(glob.glob(os.path.join(output_dir, ext)))
            video_files.extend(glob.glob(os.path.join(output_dir, ext.upper())))

        if not video_files:
            return {"result": (None, None, "", 0, "No video files found")}

        latest_video = max(video_files, key=os.path.getmtime)
        video_filename = os.path.basename(latest_video)

        file_age = int(time.time() - os.path.getmtime(latest_video))
        if file_age < min_file_age:
            return {"result": (None, None, "", file_age, f"File too new (age: {file_age}s)")}

        try:
            import subprocess
            with tempfile.NamedTemporaryFile(suffix=".wav", dir=output_dir, delete=False) as aud:
                cmd = [
                    "ffmpeg", "-nostdin", "-hide_banner", "-loglevel", "error",
                    "-i", latest_video, "-vn", "-acodec", "pcm_s16le", "-ar", "44100", "-ac", "1",
                    aud.name, "-y"
                ]
                proc = subprocess.run(cmd, capture_output=True)
            if proc.returncode == 0 and os.path.exists(aud.name) and os.path.getsize(aud.name) > 0:
                waveform, sample_rate = torchaudio.load(aud.name)
                audio = {"waveform": waveform.unsqueeze(0), "sample_rate": sample_rate}
            else:
                audio = None
            try:
                os.unlink(aud.name)
            except:
                pass
        except:
            audio = None

        try:
            cap = cv2.VideoCapture(latest_video)
            frames = []
            # è·å–æ€»å¸§æ•°
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap else 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_tensor = torch.from_numpy(frame_rgb).float() / 255.0
                if frame_tensor.dim() == 3 and frame_tensor.shape[2] == 3:
                    frame_tensor = frame_tensor.permute(2, 0, 1).float()
                    frame_tensor = torch.clamp(frame_tensor, 0.0, 1.0)
                else:
                    continue
                frames.append(frame_tensor)
            cap.release()

            if frames:
                image_tensor = torch.stack(frames, dim=0).float()
                if len(image_tensor.shape) == 4 and image_tensor.shape[1] == 3:
                    image_tensor = image_tensor.permute(0, 2, 3, 1)
                else:
                    image_tensor = None
            else:
                image_tensor = None
        except Exception:
            image_tensor = None

        if latest_video:
            try:
                file_size_mb = os.path.getsize(latest_video) / (1024 * 1024)
                create_time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(os.path.getctime(latest_video)))
                status = f"Loaded: {video_filename} ({file_size_mb:.1f}MB, created: {create_time_str})"
            except:
                status = f"Loaded: {video_filename}"
        else:
            status = "No video found"

        if latest_video and os.path.exists(latest_video):
            video_path_name = "output"
            vhs_filenames = (1, [latest_video])
            frame_count = int(total_frames) if 'total_frames' in locals() else 0
            return {"ui": {"video": [video_filename, video_path_name]}, "result": (image_tensor, audio, vhs_filenames, file_age, frame_count, status)}
        else:
            vhs_filenames = (0, [])
            frame_count = int(total_frames) if 'total_frames' in locals() else 0
            return {"result": (image_tensor, audio, vhs_filenames, file_age, frame_count, status)}

class VideoUtilitiesRGBEmptyImage:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "width": ("INT", {"default": 512, "min": 128, "max": 1024, "step": 64, "display": "number"}),
                "height": ("INT", {"default": 512, "min": 128, "max": 1024, "step": 64, "display": "number"}),
                "R": ("INT", {"default": 124, "min": 0, "max": 255, "step": 1, "display": "number"}),
                "G": ("INT", {"default": 252, "min": 0, "max": 255, "step": 1, "display": "number"}),
                "B": ("INT", {"default": 0,   "min": 0, "max": 255, "step": 1, "display": "number"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "gen_img"
    CATEGORY = "Ken-Chen/Video_Utilities"

    def gen_img(self, width: int, height: int, R: int, G: int, B: int):
        new_image = Image.new("RGB", (width, height), color=(R, G, B))
        tensor = torch.from_numpy(np.asarray(new_image) / 255.0).unsqueeze(0)
        return (tensor,)

class VideoUtilitiesAudioToSubtitle:
    """å°†è§†é¢‘éŸ³é¢‘è½¬å½•æˆå­—å¹•å¹¶çƒ§å½•åˆ°è§†é¢‘ä¸Š"""

    @classmethod
    def INPUT_TYPES(cls):
        # è·å– Fonts ç›®å½•ä¸‹çš„æ‰€æœ‰å­—ä½“æ–‡ä»¶
        fonts_dir = os.path.join(os.path.dirname(__file__), "Fonts")
        font_files = []

        if os.path.exists(fonts_dir):
            for file in sorted(os.listdir(fonts_dir)):
                if file.lower().endswith(('.ttf', '.ttc', '.otf')):
                    font_files.append(file)

        # å¦‚æœæ²¡æœ‰å­—ä½“æ–‡ä»¶ï¼Œæ·»åŠ æç¤º
        if not font_files:
            font_files = ["è¯·å°†å­—ä½“æ–‡ä»¶æ”¾å…¥ Fonts ç›®å½•"]

        return {
            "required": {
                "video": ("VIDEO",),
                "asr_model": (["SenseVoice", "Whisper"], {"default": "SenseVoice"}),
                "model_size": (["tiny", "base", "small", "medium", "large"], {"default": "medium"}),
                "language": (["auto", "zh", "en", "yue", "ja", "ko", "es", "fr", "de", "ru"], {"default": "auto"}),
                "font_size": ("INT", {"default": 24, "min": 10, "max": 100, "step": 1}),
                "font_file": (font_files, {"default": font_files[0]}),
                "font_color": (["white", "yellow", "black", "red", "green", "blue"], {"default": "yellow"}),
                "text_direction": (["horizontal", "vertical"], {"default": "horizontal"}),
                "position": (["bottom", "top", "middle"], {"default": "bottom"}),
                "background": (["yes", "no"], {"default": "yes"}),
                "animation": ([
                    "none",           # æ— åŠ¨ç”»
                    "fade_in",        # æ·¡å…¥
                    "slide_up",       # ä»ä¸‹æ»‘å…¥
                    "slide_down",     # ä»ä¸Šæ»‘å…¥
                    "zoom_in",        # æ”¾å¤§
                    "typewriter",     # æ‰“å­—æœºæ•ˆæœ
                    "bounce",         # å¼¹è·³
                    "wave",           # æ³¢æµª
                    "glow",           # å‘å…‰
                    "rainbow",        # å½©è™¹è‰²
                    "karaoke"         # å¡æ‹‰OKæ•ˆæœ
                ], {"default": "fade_in"}),
                "animation_duration": ("FLOAT", {"default": 0.3, "min": 0.1, "max": 2.0, "step": 0.1}),
            },
            "optional": {
                "prompt": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "å¯é€‰ï¼šè¾“å…¥æç¤ºæ–‡æœ¬æ¥å¼•å¯¼è½¬å½•ï¼ˆä¾‹å¦‚ï¼šä¸“ä¸šæœ¯è¯­ã€äººåã€åœ°åç­‰ï¼‰"
                }),
                "reference_text": ("STRING", {
                    "default": "",
                    "multiline": True,
                    "placeholder": "å¯é€‰ï¼šè¾“å…¥å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ ¡æ­£è½¬å½•ç»“æœï¼ˆæ¯è¡Œä¸€å¥ï¼‰"
                }),
            }
        }

    RETURN_TYPES = ("VIDEO", "STRING",)
    RETURN_NAMES = ("video_with_subtitle", "srt_path",)
    FUNCTION = "add_subtitle"
    CATEGORY = "Ken-Chen/Video_Utilities"
    DESCRIPTION = "Transcribe audio to subtitle and burn it into video using Whisper ASR"
    OUTPUT_NODE = False

    def add_subtitle(self, video, asr_model, model_size, language, font_size, font_file, font_color, text_direction, position, background, animation, animation_duration, prompt="", reference_text=""):
        """å°†éŸ³é¢‘è½¬å½•æˆå­—å¹•å¹¶çƒ§å½•åˆ°è§†é¢‘ä¸Š"""
        try:
            # æå–è§†é¢‘è·¯å¾„
            video_path = extract_video_path(video)
            if not video_path or not os.path.exists(video_path):
                _log_error("âŒ æ— æ³•è·å–è§†é¢‘è·¯å¾„æˆ–è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
                return (video, "")

            _log_info(f"ğŸ¬ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")

            # 1. æå–éŸ³é¢‘
            _log_info("ğŸµ æ­£åœ¨æå–éŸ³é¢‘...")
            audio_path = self._extract_audio(video_path)
            if not audio_path:
                _log_error("âŒ éŸ³é¢‘æå–å¤±è´¥")
                return (video, "")

            # 2. ä½¿ç”¨é€‰å®šçš„ ASR æ¨¡å‹è½¬å½•éŸ³é¢‘
            if asr_model == "SenseVoice":
                result = self._transcribe_sensevoice(audio_path, language, prompt)
            else:  # Whisper
                result = self._transcribe_whisper(audio_path, model_size, language, prompt)

            if not result:
                _log_error("âŒ éŸ³é¢‘è½¬å½•å¤±è´¥")
                return (video, "")

            # 2.5. å¦‚æœæä¾›äº†å‚è€ƒæ–‡æœ¬ï¼Œè¿›è¡Œæ™ºèƒ½æ ¡æ­£
            if reference_text and reference_text.strip():
                _log_info("ğŸ”§ æ­£åœ¨ä½¿ç”¨å‚è€ƒæ–‡æœ¬æ ¡æ­£è½¬å½•ç»“æœ...")
                result["segments"] = self._correct_segments_with_reference(
                    result["segments"], reference_text
                )

            # 3. ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶
            _log_info("ğŸ“ æ­£åœ¨ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶...")
            srt_path = self._generate_srt(video_path, result["segments"])
            if not srt_path:
                _log_error("âŒ SRT å­—å¹•ç”Ÿæˆå¤±è´¥")
                # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
                try:
                    os.unlink(audio_path)
                except:
                    pass
                return (video, "")

            _log_info(f"âœ… SRT å­—å¹•å·²ä¿å­˜: {srt_path}")

            # 4. å°†å­—å¹•çƒ§å½•åˆ°è§†é¢‘ä¸Š
            _log_info(f"ğŸ”¥ æ­£åœ¨å°†å­—å¹•çƒ§å½•åˆ°è§†é¢‘ï¼ˆæ–¹å‘: {text_direction}, åŠ¨ç”»: {animation}ï¼‰...")
            output_video_path = self._burn_subtitle(
                video_path, srt_path, font_size, font_file, font_color, text_direction, position, background, animation, animation_duration
            )

            # æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
            try:
                os.unlink(audio_path)
            except:
                pass

            if not output_video_path:
                _log_error("âŒ å­—å¹•çƒ§å½•å¤±è´¥")
                return (video, srt_path)

            _log_info(f"âœ… å­—å¹•è§†é¢‘å·²ç”Ÿæˆ: {output_video_path}")

            # è½¬æ¢ä¸º ComfyUI VIDEO å¯¹è±¡
            output_video = video_to_comfyui_video(output_video_path)
            if not output_video:
                _log_error("âŒ è§†é¢‘å¯¹è±¡è½¬æ¢å¤±è´¥")
                return (video, srt_path)

            return (output_video, srt_path)

        except Exception as e:
            _log_error(f"âŒ å­—å¹•å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())
            return (video, "")

    def _transcribe_sensevoice(self, audio_path, language, prompt):
        """ä½¿ç”¨ SenseVoice è½¬å½•éŸ³é¢‘"""
        try:
            from funasr import AutoModel
            from funasr.utils.postprocess_utils import rich_transcription_postprocess
        except ImportError:
            _log_error("âŒ æœªå®‰è£… FunASRï¼Œè¯·è¿è¡Œ: pip install funasr modelscope")
            return None

        try:
            _log_info("ğŸ¤ æ­£åœ¨ä½¿ç”¨ SenseVoice è½¬å½•éŸ³é¢‘...")

            # åŠ è½½ SenseVoice æ¨¡å‹
            model = AutoModel(
                model="iic/SenseVoiceSmall",
                trust_remote_code=True,
                device="cuda:0" if torch.cuda.is_available() else "cpu",
            )

            # è®¾ç½®è¯­è¨€å‚æ•°
            lang_map = {
                "auto": "auto",
                "zh": "zh",
                "en": "en",
                "yue": "yue",  # ç²¤è¯­
                "ja": "ja",
                "ko": "ko",
            }
            lang = lang_map.get(language, "auto")

            # è½¬å½•
            _log_info(f"ğŸ”§ SenseVoice å‚æ•°: language={lang}, use_itn=True")
            res = model.generate(
                input=audio_path,
                cache={},
                language=lang,
                use_itn=True,  # ä½¿ç”¨é€†æ–‡æœ¬å½’ä¸€åŒ–ï¼ˆæ·»åŠ æ ‡ç‚¹ç¬¦å·ï¼‰
                batch_size_s=0,  # ä¸ä½¿ç”¨æ‰¹å¤„ç†
            )

            if not res or len(res) == 0:
                _log_error("âŒ SenseVoice è½¬å½•ç»“æœä¸ºç©º")
                return None

            # å¤„ç†ç»“æœ
            text = rich_transcription_postprocess(res[0]["text"])
            _log_info(f"âœ… SenseVoice è½¬å½•å®Œæˆ: {text[:100]}...")

            # è½¬æ¢ä¸º Whisper æ ¼å¼çš„ç»“æœï¼ˆç”¨äºå…¼å®¹åç»­å¤„ç†ï¼‰
            # SenseVoice è¿”å›çš„æ˜¯å®Œæ•´æ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶åˆ†æ®µ
            segments = []

            _log_info(f"ğŸ” SenseVoice ç»“æœé”®: {res[0].keys()}")

            if "timestamp" in res[0] and res[0]["timestamp"]:
                # å¦‚æœæœ‰æ—¶é—´æˆ³ä¿¡æ¯
                _log_info(f"ğŸ” æ‰¾åˆ° {len(res[0]['timestamp'])} ä¸ªæ—¶é—´æˆ³")
                for i, ts in enumerate(res[0]["timestamp"]):
                    _log_info(f"ğŸ” æ—¶é—´æˆ³ {i}: {ts}")
                    segments.append({
                        "start": ts[0] / 1000.0,  # è½¬æ¢ä¸ºç§’
                        "end": ts[1] / 1000.0,
                        "text": ts[2] if len(ts) > 2 else text
                    })
            else:
                # æ²¡æœ‰æ—¶é—´æˆ³ï¼Œæ™ºèƒ½åˆ†å‰²æ–‡æœ¬
                _log_info("âš ï¸ SenseVoice æ²¡æœ‰è¿”å›æ—¶é—´æˆ³ï¼Œå°†æ™ºèƒ½åˆ†å‰²æ–‡æœ¬")
                # è·å–éŸ³é¢‘æ—¶é•¿
                import wave
                try:
                    with wave.open(audio_path, 'r') as wav_file:
                        frames = wav_file.getnframes()
                        rate = wav_file.getframerate()
                        duration = frames / float(rate)
                        _log_info(f"ğŸ” éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’")
                except:
                    duration = 10.0  # é»˜è®¤ 10 ç§’

                # æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ä¸ºå¤šä¸ªå­—å¹•æ®µ
                segments = self._split_text_to_segments(text, duration)
                _log_info(f"ğŸ“ æ–‡æœ¬å·²åˆ†å‰²ä¸º {len(segments)} ä¸ªå­—å¹•æ®µ")
                for i, seg in enumerate(segments[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                    _log_info(f"   æ®µ{i+1}: {seg['start']:.2f}s - {seg['end']:.2f}s: {seg['text'][:30]}...")

            _log_info(f"ğŸ“ ç”Ÿæˆäº† {len(segments)} ä¸ªå­—å¹•æ®µè½")

            return {"segments": segments}

        except Exception as e:
            _log_error(f"âŒ SenseVoice è½¬å½•å¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())
            return None

    def _correct_segments_with_reference(self, segments, reference_text):
        """ä½¿ç”¨å‚è€ƒæ–‡æœ¬æ ¡æ­£è½¬å½•ç»“æœ

        Args:
            segments: ASR è½¬å½•çš„å­—å¹•æ®µåˆ—è¡¨ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
            reference_text: ç”¨æˆ·æä¾›çš„å‡†ç¡®æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€å¥ï¼‰

        Returns:
            corrected_segments: æ ¡æ­£åçš„å­—å¹•æ®µåˆ—è¡¨
        """
        import re
        from difflib import SequenceMatcher

        # è§£æå‚è€ƒæ–‡æœ¬ï¼ˆæŒ‰è¡Œåˆ†å‰²ï¼‰
        reference_lines = [line.strip() for line in reference_text.strip().split('\n') if line.strip()]

        _log_info(f"ğŸ“ å‚è€ƒæ–‡æœ¬æœ‰ {len(reference_lines)} è¡Œ")
        _log_info(f"ğŸ“ è½¬å½•ç»“æœæœ‰ {len(segments)} ä¸ªæ®µè½")

        # æå–è½¬å½•æ–‡æœ¬ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        transcribed_texts = [seg['text'].strip() for seg in segments]

        # å¦‚æœå‚è€ƒæ–‡æœ¬è¡Œæ•°ä¸è½¬å½•æ®µè½æ•°ç›¸åŒï¼Œç›´æ¥ä¸€ä¸€å¯¹åº”
        if len(reference_lines) == len(segments):
            _log_info("âœ… å‚è€ƒæ–‡æœ¬è¡Œæ•°ä¸è½¬å½•æ®µè½æ•°ç›¸åŒï¼Œç›´æ¥æ›¿æ¢")
            corrected_segments = []
            for i, seg in enumerate(segments):
                corrected_segments.append({
                    "start": seg["start"],
                    "end": seg["end"],
                    "text": reference_lines[i]
                })
                if transcribed_texts[i] != reference_lines[i]:
                    _log_info(f"   æ®µ{i+1} å·²æ ¡æ­£: '{transcribed_texts[i][:30]}...' â†’ '{reference_lines[i][:30]}...'")
            return corrected_segments

        # å¦‚æœæ•°é‡ä¸åŒï¼Œä½¿ç”¨æ™ºèƒ½åŒ¹é…
        _log_info("ğŸ” å‚è€ƒæ–‡æœ¬è¡Œæ•°ä¸è½¬å½•æ®µè½æ•°ä¸åŒï¼Œä½¿ç”¨æ™ºèƒ½åŒ¹é…...")

        # åˆå¹¶æ‰€æœ‰è½¬å½•æ–‡æœ¬
        full_transcribed = ''.join(transcribed_texts)
        full_reference = ''.join(reference_lines)

        # ç§»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹ï¼Œç”¨äºç›¸ä¼¼åº¦å¯¹æ¯”
        def normalize_text(text):
            # ç§»é™¤æ‰€æœ‰ç©ºæ ¼ã€æ ‡ç‚¹ç¬¦å·
            text = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ã€,.!?;ï¼Œ\s]', '', text)
            return text.lower()

        norm_transcribed = normalize_text(full_transcribed)
        norm_reference = normalize_text(full_reference)

        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = SequenceMatcher(None, norm_transcribed, norm_reference).ratio()
        _log_info(f"ğŸ“Š æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity * 100:.1f}%")

        # å¦‚æœç›¸ä¼¼åº¦å¾ˆé«˜ï¼ˆ>80%ï¼‰ï¼Œä½¿ç”¨é€å¥åŒ¹é…
        if similarity > 0.8:
            corrected_segments = self._match_segments_to_reference(
                segments, reference_lines, transcribed_texts
            )
        else:
            # ç›¸ä¼¼åº¦è¾ƒä½ï¼Œè­¦å‘Šç”¨æˆ·ä½†ä»ç„¶å°è¯•åŒ¹é…
            _log_info(f"âš ï¸ æ–‡æœ¬ç›¸ä¼¼åº¦è¾ƒä½ ({similarity * 100:.1f}%)ï¼Œå¯èƒ½åŒ¹é…ä¸å‡†ç¡®")
            corrected_segments = self._match_segments_to_reference(
                segments, reference_lines, transcribed_texts
            )

        return corrected_segments

    def _match_segments_to_reference(self, segments, reference_lines, transcribed_texts):
        """æ™ºèƒ½åŒ¹é…è½¬å½•æ®µè½å’Œå‚è€ƒæ–‡æœ¬

        ç­–ç•¥ï¼š
        1. å¦‚æœå‚è€ƒæ–‡æœ¬è¡Œæ•° <= è½¬å½•æ®µè½æ•°ï¼šåˆå¹¶å¤šä¸ªè½¬å½•æ®µè½
        2. å¦‚æœå‚è€ƒæ–‡æœ¬è¡Œæ•° > è½¬å½•æ®µè½æ•°ï¼šæ‹†åˆ†è½¬å½•æ®µè½çš„æ—¶é—´
        """
        import re
        from difflib import SequenceMatcher

        def normalize_text(text):
            return re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿï¼›ã€,.!?;ï¼Œ\s]', '', text).lower()

        corrected_segments = []

        if len(reference_lines) <= len(segments):
            # æƒ…å†µ1: å‚è€ƒæ–‡æœ¬è¾ƒå°‘ï¼Œåˆå¹¶è½¬å½•æ®µè½
            _log_info(f"ğŸ“ åˆå¹¶æ¨¡å¼: {len(segments)} ä¸ªæ®µè½ â†’ {len(reference_lines)} è¡Œ")

            # è®¡ç®—æ¯è¡Œå‚è€ƒæ–‡æœ¬åº”è¯¥å¯¹åº”å¤šå°‘ä¸ªè½¬å½•æ®µè½
            segments_per_line = len(segments) / len(reference_lines)

            current_seg_idx = 0
            for i, ref_line in enumerate(reference_lines):
                # è®¡ç®—è¿™è¡Œåº”è¯¥ä½¿ç”¨å¤šå°‘ä¸ªè½¬å½•æ®µè½
                start_idx = int(i * segments_per_line)
                end_idx = int((i + 1) * segments_per_line)

                # ç¡®ä¿ä¸è¶…å‡ºèŒƒå›´
                end_idx = min(end_idx, len(segments))
                if i == len(reference_lines) - 1:
                    end_idx = len(segments)

                # åˆå¹¶è¿™äº›æ®µè½çš„æ—¶é—´èŒƒå›´
                if start_idx < len(segments) and end_idx <= len(segments):
                    start_time = segments[start_idx]["start"]
                    end_time = segments[end_idx - 1]["end"]

                    corrected_segments.append({
                        "start": start_time,
                        "end": end_time,
                        "text": ref_line
                    })

                    _log_info(f"   æ®µ{i+1}: {start_time:.2f}s - {end_time:.2f}s: {ref_line[:30]}...")

        else:
            # æƒ…å†µ2: å‚è€ƒæ–‡æœ¬è¾ƒå¤šï¼Œæ‹†åˆ†è½¬å½•æ®µè½çš„æ—¶é—´
            _log_info(f"ğŸ“ æ‹†åˆ†æ¨¡å¼: {len(segments)} ä¸ªæ®µè½ â†’ {len(reference_lines)} è¡Œ")

            # è®¡ç®—æ€»æ—¶é•¿
            total_duration = segments[-1]["end"] - segments[0]["start"]

            # æŒ‰å‚è€ƒæ–‡æœ¬çš„å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
            total_chars = sum(len(line) for line in reference_lines)
            current_time = segments[0]["start"]

            for i, ref_line in enumerate(reference_lines):
                # æŒ‰å­—ç¬¦æ•°æ¯”ä¾‹åˆ†é…æ—¶é—´
                char_ratio = len(ref_line) / total_chars
                segment_duration = total_duration * char_ratio

                # ç¡®ä¿æœ€åä¸€ä¸ªæ®µè½ç»“æŸæ—¶é—´ç­‰äºæ€»æ—¶é•¿
                if i == len(reference_lines) - 1:
                    end_time = segments[-1]["end"]
                else:
                    end_time = current_time + segment_duration

                corrected_segments.append({
                    "start": current_time,
                    "end": end_time,
                    "text": ref_line
                })

                _log_info(f"   æ®µ{i+1}: {current_time:.2f}s - {end_time:.2f}s: {ref_line[:30]}...")

                current_time = end_time

        _log_info(f"âœ… æ ¡æ­£å®Œæˆï¼Œç”Ÿæˆ {len(corrected_segments)} ä¸ªå­—å¹•æ®µ")

        return corrected_segments

    def _split_text_to_segments(self, text, duration):
        """æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ä¸ºå¤šä¸ªå­—å¹•æ®µ

        Args:
            text: å®Œæ•´æ–‡æœ¬
            duration: éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰

        Returns:
            segments: å­—å¹•æ®µåˆ—è¡¨
        """
        import re

        _log_info(f"ğŸ” åŸå§‹æ–‡æœ¬: {text[:100]}...")

        # ç§»é™¤è¡¨æƒ…ç¬¦å·å’Œç‰¹æ®Šæ ‡è®°
        clean_text = re.sub(r'[ğŸ˜ŠğŸ˜¢ğŸ˜¡ğŸ¼ğŸµğŸ¶âœ¨ğŸ’¡ğŸ”¥â­ğŸŒŸğŸ’«ğŸ¯ğŸ¨ğŸ­ğŸªğŸ¬ğŸ¤ğŸ§ğŸ¼ğŸ¹ğŸºğŸ»ğŸ¥ğŸ¸]', '', text)
        clean_text = clean_text.strip()

        _log_info(f"ğŸ” æ¸…ç†åæ–‡æœ¬: {clean_text[:100]}...")

        # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å‰²ï¼ˆä¸­æ–‡å’Œè‹±æ–‡æ ‡ç‚¹ï¼‰
        # æ³¨æ„ï¼šä¸­æ–‡é€—å·æ˜¯ ï¼Œï¼ˆå…¨è§’ï¼‰ï¼Œè‹±æ–‡é€—å·æ˜¯ ,ï¼ˆåŠè§’ï¼‰
        # ä¿ç•™æ ‡ç‚¹ç¬¦å·åœ¨å¥å­æœ«å°¾
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€.!?;,])', clean_text)

        _log_info(f"ğŸ” åˆ†å‰²åç‰‡æ®µæ•°: {len(sentences)}")
        _log_info(f"ğŸ” å‰5ä¸ªç‰‡æ®µ: {sentences[:5]}")

        # é‡æ–°ç»„åˆå¥å­å’Œæ ‡ç‚¹
        combined_sentences = []
        i = 0
        while i < len(sentences):
            if i + 1 < len(sentences) and sentences[i + 1] in 'ã€‚ï¼ï¼Ÿï¼›ï¼Œã€.!?;,':
                combined_sentences.append(sentences[i] + sentences[i + 1])
                i += 2
            elif sentences[i].strip():
                combined_sentences.append(sentences[i])
                i += 1
            else:
                i += 1

        # è¿‡æ»¤ç©ºå¥å­
        combined_sentences = [s.strip() for s in combined_sentences if s.strip()]

        _log_info(f"ğŸ” ç»„åˆåå¥å­æ•°: {len(combined_sentences)}")
        for idx, sent in enumerate(combined_sentences[:3]):
            _log_info(f"   å¥å­{idx+1}: {sent}")

        if not combined_sentences:
            # å¦‚æœæ²¡æœ‰åˆ†å‰²æˆåŠŸï¼Œè¿”å›æ•´æ®µæ–‡æœ¬
            _log_info("âš ï¸ åˆ†å‰²å¤±è´¥ï¼Œè¿”å›æ•´æ®µæ–‡æœ¬")
            return [{
                "start": 0.0,
                "end": duration,
                "text": clean_text
            }]

        # è®¡ç®—æ¯ä¸ªå¥å­çš„æ—¶é•¿
        # ç­–ç•¥ï¼šå¹³å‡åˆ†é…æ—¶é—´ï¼Œæ¯ä¸ªå¥å­æ˜¾ç¤ºç›¸åŒçš„æ—¶é•¿
        # è¿™æ ·æ›´ç¬¦åˆå®é™…è¯´è¯çš„èŠ‚å¥
        num_sentences = len(combined_sentences)
        segment_duration = duration / num_sentences

        segments = []
        current_time = 0.0

        for i, sentence in enumerate(combined_sentences):
            # ç¡®ä¿æœ€åä¸€ä¸ªæ®µè½ç»“æŸæ—¶é—´ç­‰äºæ€»æ—¶é•¿
            if i == num_sentences - 1:
                end_time = duration
            else:
                end_time = current_time + segment_duration

            segments.append({
                "start": current_time,
                "end": end_time,
                "text": sentence
            })

            _log_info(f"   æ®µ{i+1}: {current_time:.2f}s - {end_time:.2f}s: {sentence[:30]}...")

            current_time = end_time

        _log_info(f"âœ… ç”Ÿæˆ {len(segments)} ä¸ªå­—å¹•æ®µï¼ˆå¹³å‡æ¯æ®µ {segment_duration:.2f}ç§’ï¼‰")

        return segments

    def _transcribe_whisper(self, audio_path, model_size, language, prompt):
        """ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘"""
        try:
            import whisper
        except ImportError:
            _log_error("âŒ æœªå®‰è£… openai-whisperï¼Œè¯·è¿è¡Œ: pip install openai-whisper")
            return None

        try:
            _log_info(f"ğŸ¤ æ­£åœ¨ä½¿ç”¨ Whisper ({model_size}) è½¬å½•éŸ³é¢‘...")
            model = whisper.load_model(model_size)

            # è®¾ç½®è½¬å½•å‚æ•°ä»¥æé«˜å‡†ç¡®åº¦
            # æ³¨æ„ï¼šword_timestamps åœ¨æŸäº›ç¯å¢ƒä¸‹å¯èƒ½ä¸ Triton åº“å†²çªï¼Œæš‚æ—¶ç¦ç”¨
            transcribe_options = {
                "verbose": False,
                "temperature": 0.0,
                "beam_size": 5,
                "best_of": 5,
                "patience": 1.0,
                "length_penalty": 1.0,
                "compression_ratio_threshold": 2.4,
                "logprob_threshold": -1.0,
                "no_speech_threshold": 0.6,
                "condition_on_previous_text": True,
                "initial_prompt": prompt.strip() if prompt and prompt.strip() else None,
                "word_timestamps": False,  # ç¦ç”¨ä»¥é¿å… Triton å…¼å®¹æ€§é—®é¢˜
            }

            # è®¾ç½®è¯­è¨€å‚æ•°
            if language != "auto" and language != "yue":  # Whisper ä¸æ”¯æŒç²¤è¯­
                transcribe_options["language"] = language
            else:
                transcribe_options["language"] = None

            if prompt and prompt.strip():
                _log_info(f"ğŸ’¡ ä½¿ç”¨æç¤ºæ–‡æœ¬: {prompt.strip()[:50]}...")
            _log_info(f"ğŸ”§ Whisper å‚æ•°: beam_size=5, best_of=5, word_timestamps=False")

            result = model.transcribe(audio_path, **transcribe_options)

            # è°ƒè¯•ï¼šæ£€æŸ¥ Whisper è¿”å›ç»“æœ
            _log_info(f"ğŸ” Whisper ç»“æœé”®: {result.keys()}")
            if "segments" in result:
                _log_info(f"âœ… Whisper è½¬å½•å®Œæˆ: {result['text'][:100]}...")
                _log_info(f"ğŸ“ Whisper ç”Ÿæˆäº† {len(result['segments'])} ä¸ªå­—å¹•æ®µ")
                for i, seg in enumerate(result['segments'][:3]):
                    _log_info(f"   æ®µ{i+1}: {seg['start']:.2f}s - {seg['end']:.2f}s: {seg['text'][:30]}...")
            else:
                _log_error("âŒ Whisper ç»“æœä¸­æ²¡æœ‰ segments å­—æ®µ")

            return result

        except Exception as e:
            _log_error(f"âŒ Whisper è½¬å½•å¤±è´¥: {str(e)}")
            import traceback
            _log_error(traceback.format_exc())
            return None

    def _extract_audio(self, video_path):
        """æå–è§†é¢‘éŸ³é¢‘ä¸º WAV æ ¼å¼"""
        try:
            # ç”Ÿæˆä¸´æ—¶éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_path = os.path.join(
                tempfile.gettempdir(),
                f"audio_{int(time.time())}_{random.randint(1000, 9999)}.wav"
            )

            cmd = [
                "ffmpeg", "-i", video_path,
                "-vn",  # ä¸å¤„ç†è§†é¢‘
                "-acodec", "pcm_s16le",  # PCM 16-bit
                "-ar", "16000",  # 16kHz é‡‡æ ·ç‡ï¼ˆWhisper æ¨èï¼‰
                "-ac", "1",  # å•å£°é“
                "-y",  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                audio_path
            ]

            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)

            if result.returncode == 0 and os.path.exists(audio_path):
                _log_info(f"âœ… éŸ³é¢‘æå–æˆåŠŸ: {audio_path}")

                # æ£€æŸ¥éŸ³é¢‘æ—¶é•¿
                try:
                    probe_cmd = [
                        "ffprobe",
                        "-v", "error",
                        "-show_entries", "format=duration",
                        "-of", "default=noprint_wrappers=1:nokey=1",
                        audio_path
                    ]
                    probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
                    if probe_result.returncode == 0:
                        audio_duration = float(probe_result.stdout.strip())
                        _log_info(f"ğŸµ éŸ³é¢‘æ—¶é•¿: {audio_duration:.2f} ç§’")
                except Exception as e:
                    _log_info(f"âš ï¸ æ— æ³•æ£€æŸ¥éŸ³é¢‘æ—¶é•¿: {e}")

                return audio_path
            else:
                _log_error(f"âŒ FFmpeg é”™è¯¯: {result.stderr}")
                return None

        except Exception as e:
            _log_error(f"âŒ éŸ³é¢‘æå–å¼‚å¸¸: {str(e)}")
            return None

    def _generate_srt(self, video_path, segments):
        """ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶"""
        try:
            # ç”Ÿæˆ SRT æ–‡ä»¶è·¯å¾„ï¼ˆä¸è§†é¢‘åŒç›®å½•ï¼‰
            video_dir = os.path.dirname(video_path)
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            srt_path = os.path.join(video_dir, f"{video_name}_subtitle.srt")

            with open(srt_path, 'w', encoding='utf-8') as f:
                for i, segment in enumerate(segments, start=1):
                    # SRT æ ¼å¼ï¼š
                    # 1
                    # 00:00:00,000 --> 00:00:02,000
                    # å­—å¹•æ–‡æœ¬
                    start_time = self._format_timestamp(segment['start'])
                    end_time = self._format_timestamp(segment['end'])
                    text = segment['text'].strip()

                    f.write(f"{i}\n")
                    f.write(f"{start_time} --> {end_time}\n")
                    f.write(f"{text}\n\n")

            return srt_path

        except Exception as e:
            _log_error(f"âŒ SRT ç”Ÿæˆå¼‚å¸¸: {str(e)}")
            return None

    def _format_timestamp(self, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,mmm)"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millis = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

    def _apply_animation(self, animation, progress, subtitle_progress, base_x, base_y, base_color, width, height, text_height):
        """åº”ç”¨å­—å¹•åŠ¨ç”»æ•ˆæœ

        Args:
            animation: åŠ¨ç”»ç±»å‹
            progress: åŠ¨ç”»è¿›åº¦ (0.0 åˆ° 1.0)
            subtitle_progress: å­—å¹•æ•´ä½“è¿›åº¦ (0.0 åˆ° 1.0)
            base_x, base_y: åŸºç¡€ä½ç½®
            base_color: åŸºç¡€é¢œè‰² (R, G, B)
            width, height: è§†é¢‘å°ºå¯¸
            text_height: æ–‡å­—é«˜åº¦

        Returns:
            (x, y, alpha, scale, color): è°ƒæ•´åçš„ä½ç½®ã€é€æ˜åº¦ã€ç¼©æ”¾ã€é¢œè‰²
        """
        import math

        x, y = base_x, base_y
        alpha = 1.0
        scale = 1.0
        color = base_color

        if animation == "none":
            pass

        elif animation == "fade_in":
            # æ·¡å…¥æ•ˆæœ
            alpha = progress

        elif animation == "slide_up":
            # ä»ä¸‹æ»‘å…¥
            offset = int(text_height * 2 * (1 - progress))
            y = base_y + offset
            alpha = progress

        elif animation == "slide_down":
            # ä»ä¸Šæ»‘å…¥
            offset = int(text_height * 2 * (1 - progress))
            y = base_y - offset
            alpha = progress

        elif animation == "zoom_in":
            # æ”¾å¤§æ•ˆæœ
            scale = 0.5 + 0.5 * progress
            alpha = progress

        elif animation == "typewriter":
            # æ‰“å­—æœºæ•ˆæœï¼ˆé€šè¿‡é€æ˜åº¦æ¨¡æ‹Ÿï¼‰
            alpha = min(progress * 3, 1.0)

        elif animation == "bounce":
            # å¼¹è·³æ•ˆæœ
            if progress < 0.5:
                bounce = math.sin(progress * math.pi * 4) * 20 * (1 - progress * 2)
            else:
                bounce = 0
            y = base_y - int(bounce)
            alpha = min(progress * 2, 1.0)

        elif animation == "wave":
            # æ³¢æµªæ•ˆæœ
            wave = math.sin(subtitle_progress * math.pi * 4) * 10
            y = base_y + int(wave)

        elif animation == "glow":
            # å‘å…‰æ•ˆæœï¼ˆé€šè¿‡ç¼©æ”¾æ¨¡æ‹Ÿï¼‰
            glow = 1.0 + math.sin(subtitle_progress * math.pi * 6) * 0.05
            scale = glow

        elif animation == "rainbow":
            # å½©è™¹è‰²æ•ˆæœ
            hue = (subtitle_progress * 360) % 360
            # HSV è½¬ RGB
            h = hue / 60
            c = 255
            x_val = int(c * (1 - abs(h % 2 - 1)))

            if 0 <= h < 1:
                color = (c, x_val, 0)
            elif 1 <= h < 2:
                color = (x_val, c, 0)
            elif 2 <= h < 3:
                color = (0, c, x_val)
            elif 3 <= h < 4:
                color = (0, x_val, c)
            elif 4 <= h < 5:
                color = (x_val, 0, c)
            else:
                color = (c, 0, x_val)

        elif animation == "karaoke":
            # å¡æ‹‰OKæ•ˆæœï¼ˆé¢œè‰²æ¸å˜ï¼‰
            if subtitle_progress < 0.5:
                # å‰åŠæ®µï¼šç™½è‰²åˆ°é»„è‰²
                t = subtitle_progress * 2
                color = (
                    int(255 * (1 - t) + 0 * t),      # R
                    int(255 * (1 - t) + 255 * t),    # G
                    int(255 * (1 - t) + 255 * t)     # B
                )
            else:
                # ååŠæ®µï¼šé»„è‰²åˆ°çº¢è‰²
                t = (subtitle_progress - 0.5) * 2
                color = (
                    int(0 * (1 - t) + 0 * t),        # R
                    int(255 * (1 - t) + 0 * t),      # G
                    int(255 * (1 - t) + 255 * t)     # B
                )

        return x, y, alpha, scale, color

    def _draw_vertical_text(self, draw, text, font, x, y, color, alpha):
        """ç»˜åˆ¶ç«–æ’æ–‡å­— - ä½¿ç”¨å›ºå®šé—´è·"""
        # ä½¿ç”¨å­—ä½“å¤§å°ä½œä¸ºè¡Œé«˜ï¼Œç¡®ä¿é—´è·ä¸€è‡´
        try:
            line_height = font.size
        except:
            # å¦‚æœæ— æ³•è·å–å­—ä½“å¤§å°ï¼Œä½¿ç”¨ bbox ä¼°ç®—
            bbox = draw.textbbox((0, 0), "æµ‹", font=font)
            line_height = bbox[3] - bbox[1]

        current_y = y
        for char in text:
            draw.text((x, current_y), char, font=font, fill=(*color, int(255 * alpha)))
            current_y += line_height

    def _get_vertical_text_size(self, draw, text, font):
        """è®¡ç®—ç«–æ’æ–‡å­—çš„å°ºå¯¸ - ä½¿ç”¨å›ºå®šé—´è·"""
        # ä½¿ç”¨å­—ä½“å¤§å°ä½œä¸ºè¡Œé«˜
        try:
            line_height = font.size
        except:
            # å¦‚æœæ— æ³•è·å–å­—ä½“å¤§å°ï¼Œä½¿ç”¨ bbox ä¼°ç®—
            bbox = draw.textbbox((0, 0), "æµ‹", font=font)
            line_height = bbox[3] - bbox[1]

        total_height = line_height * len(text)

        # è®¡ç®—æœ€å¤§å®½åº¦
        max_width = 0
        for char in text:
            bbox = draw.textbbox((0, 0), char, font=font)
            char_width = bbox[2] - bbox[0]
            max_width = max(max_width, char_width)

        return max_width, total_height

    def _burn_subtitle(self, video_path, srt_path, font_size, font_file, font_color, text_direction, position, background, animation="none", animation_duration=0.3):
        """å°†å­—å¹•çƒ§å½•åˆ°è§†é¢‘ä¸Š - ä½¿ç”¨ Python + OpenCV æ–¹æ³•ï¼Œæ”¯æŒåŠ¨ç”»æ•ˆæœå’Œç«–æ’æ–‡å­—"""
        try:
            import cv2
            import numpy as np
            from PIL import Image, ImageDraw, ImageFont
            import re

            # ç”Ÿæˆè¾“å‡ºè§†é¢‘è·¯å¾„
            video_dir = os.path.dirname(video_path)
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            output_path = os.path.join(video_dir, f"{video_name}_with_subtitle.mp4")

            _log_info(f"ğŸ¬ ä½¿ç”¨ OpenCV æ–¹æ³•çƒ§å½•å­—å¹•...")

            # è¯»å– SRT æ–‡ä»¶
            with open(srt_path, 'r', encoding='utf-8') as f:
                srt_content = f.read()

            # è§£æ SRT
            pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:.*\n)*?)(?=\n\d+\n|\Z)'
            matches = re.findall(pattern, srt_content, re.MULTILINE)

            # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ¯«ç§’
            def time_to_ms(time_str):
                h, m, s = time_str.split(':')
                s, ms = s.split(',')
                return int(h) * 3600000 + int(m) * 60000 + int(s) * 1000 + int(ms)

            # æ„å»ºå­—å¹•æ—¶é—´è½´
            subtitles = []
            for match in matches:
                start_ms = time_to_ms(match[1])
                end_ms = time_to_ms(match[2])
                text = match[3].strip().replace('\n', ' ')
                subtitles.append((start_ms, end_ms, text))

            _log_info(f"ğŸ“ è§£æåˆ° {len(subtitles)} æ¡å­—å¹•")
            if len(subtitles) > 0:
                _log_info(f"ğŸ“ ç¬¬ä¸€æ¡å­—å¹•: {subtitles[0][0]}ms - {subtitles[0][1]}ms: {subtitles[0][2][:50]}...")
                if len(subtitles) > 1:
                    _log_info(f"ğŸ“ ç¬¬äºŒæ¡å­—å¹•: {subtitles[1][0]}ms - {subtitles[1][1]}ms: {subtitles[1][2][:50]}...")

            # æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                _log_error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return None

            fps = cap.get(cv2.CAP_PROP_FPS)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

            _log_info(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps}fps, {total_frames} å¸§")

            if width == 0 or height == 0 or fps == 0:
                _log_error(f"âŒ è§†é¢‘å‚æ•°æ— æ•ˆ: {width}x{height} @ {fps}fps")
                cap.release()
                return None

            # åˆ›å»ºä¸´æ—¶è¾“å‡ºè·¯å¾„ï¼ˆä½¿ç”¨ AVI æ ¼å¼ï¼Œæ›´ç¨³å®šï¼‰
            temp_output = os.path.join(video_dir, f"{video_name}_temp.avi")

            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ - ä½¿ç”¨ XVID ç¼–ç å™¨ï¼ˆæ›´å¯é ï¼‰
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))

            if not out.isOpened():
                _log_error("âŒ æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
                return None

            # è®¾ç½®å­—ä½“è·¯å¾„ï¼ˆä» Fonts ç›®å½•ï¼‰
            fonts_dir = os.path.join(os.path.dirname(__file__), "Fonts")
            font_path = os.path.join(fonts_dir, font_file)

            if os.path.exists(font_path):
                _log_info(f"ğŸ”¤ å­—ä½“: {font_file}")
            else:
                _log_info(f"âš ï¸ å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}ï¼Œå°†ä½¿ç”¨ PIL é»˜è®¤å­—ä½“")
                font_path = None

            # è®¾ç½®å­—ä½“é¢œè‰²ï¼ˆRGB æ ¼å¼ï¼Œç”¨äº PILï¼‰
            # æ³¨æ„ï¼šPIL ä½¿ç”¨ RGB æ ¼å¼ï¼Œä¸æ˜¯ BGRï¼
            color_map = {
                "white": (255, 255, 255),
                "yellow": (255, 255, 0),    # RGB: çº¢+ç»¿=é»„
                "black": (0, 0, 0),
                "red": (255, 0, 0),         # RGB: çº¢
                "green": (0, 255, 0),       # RGB: ç»¿
                "blue": (0, 0, 255)         # RGB: è“
            }
            text_color = color_map.get(font_color, (255, 255, 0))  # é»˜è®¤é»„è‰²
            _log_info(f"ğŸ¨ å­—å¹•é¢œè‰²: {font_color} = RGB{text_color}")

            # è®¾ç½®å­—å¹•ä½ç½®
            if position == "bottom":
                y_offset = int(height * 0.85)
            elif position == "top":
                y_offset = int(height * 0.15)
            else:  # middle
                y_offset = int(height * 0.5)

            frame_count = 0
            subtitle_found_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # è®¡ç®—å½“å‰æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
                current_ms = int((frame_count / fps) * 1000)

                # æŸ¥æ‰¾å½“å‰æ—¶é—´çš„å­—å¹•
                current_text = None
                subtitle_start_ms = None
                subtitle_end_ms = None
                for start_ms, end_ms, text in subtitles:
                    if start_ms <= current_ms <= end_ms:
                        current_text = text
                        subtitle_start_ms = start_ms
                        subtitle_end_ms = end_ms
                        if subtitle_found_count < 5:  # åªè®°å½•å‰5æ¬¡
                            _log_info(f"ğŸ¯ å¸§ {frame_count} ({current_ms}ms) åŒ¹é…å­—å¹•: {start_ms}-{end_ms}ms: {text[:30]}...")
                            subtitle_found_count += 1
                        break

                # å¦‚æœæœ‰å­—å¹•ï¼Œç»˜åˆ¶åˆ°å¸§ä¸Š
                if current_text:
                    # è®¡ç®—åŠ¨ç”»è¿›åº¦ï¼ˆ0.0 åˆ° 1.0ï¼‰
                    subtitle_duration_ms = max(subtitle_end_ms - subtitle_start_ms, 1)  # é¿å…é™¤é›¶é”™è¯¯
                    elapsed_ms = current_ms - subtitle_start_ms
                    animation_progress = min(elapsed_ms / (animation_duration * 1000), 1.0)  # åŠ¨ç”»è¿›åº¦
                    subtitle_progress = min(elapsed_ms / subtitle_duration_ms, 1.0)  # å­—å¹•æ•´ä½“è¿›åº¦

                    # ä½¿ç”¨ PIL ç»˜åˆ¶ä¸­æ–‡å­—å¹•
                    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(pil_img, 'RGBA')

                    # åŠ è½½å­—ä½“
                    if font_path and os.path.exists(font_path):
                        try:
                            font = ImageFont.truetype(font_path, font_size)
                        except Exception as e:
                            _log_info(f"âš ï¸ æ— æ³•åŠ è½½å­—ä½“ {font_path}: {e}ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")
                            font = ImageFont.load_default()
                    else:
                        font = ImageFont.load_default()

                    # è®¡ç®—æ–‡å­—ä½ç½®ï¼ˆæ ¹æ®æ–¹å‘ï¼‰
                    if text_direction == "vertical":
                        # ç«–æ’ï¼šè®¡ç®—ç«–æ’æ–‡å­—å°ºå¯¸
                        text_width, text_height = self._get_vertical_text_size(draw, current_text, font)
                        # ç«–æ’æ—¶ï¼Œx ä½ç½®é å³ï¼Œy ä½ç½®å±…ä¸­
                        if position == "bottom":
                            base_x = int(width * 0.9) - text_width // 2
                        elif position == "top":
                            base_x = int(width * 0.9) - text_width // 2
                        else:  # middle
                            base_x = int(width * 0.9) - text_width // 2
                        base_y = (height - text_height) // 2
                    else:
                        # æ¨ªæ’ï¼šè®¡ç®—æ¨ªæ’æ–‡å­—å°ºå¯¸
                        bbox = draw.textbbox((0, 0), current_text, font=font)
                        text_width = bbox[2] - bbox[0]
                        text_height = bbox[3] - bbox[1]
                        base_x = (width - text_width) // 2
                        base_y = y_offset - text_height // 2

                    # åº”ç”¨åŠ¨ç”»æ•ˆæœ
                    x, y, alpha, scale, color = self._apply_animation(
                        animation, animation_progress, subtitle_progress,
                        base_x, base_y, text_color, width, height, text_height
                    )

                    # ç»˜åˆ¶èƒŒæ™¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if background == "yes":
                        padding = 10
                        bg_alpha = int(128 * alpha)
                        draw.rectangle(
                            [x - padding, y - padding, x + text_width * scale + padding, y + text_height * scale + padding],
                            fill=(0, 0, 0, bg_alpha)
                        )

                    # ç»˜åˆ¶æ–‡å­—ï¼ˆæ ¹æ®æ–¹å‘ï¼‰
                    if text_direction == "vertical":
                        # ç«–æ’æ–‡å­—
                        if scale != 1.0 or alpha != 1.0:
                            # åˆ›å»ºä¸´æ—¶å›¾åƒç”¨äºç¼©æ”¾
                            temp_img = Image.new('RGBA', (int(text_width * 1.5), int(text_height * 1.5)), (0, 0, 0, 0))
                            temp_draw = ImageDraw.Draw(temp_img)
                            # ç«–æ’ç»˜åˆ¶
                            self._draw_vertical_text(temp_draw, current_text, font, int(text_width * 0.25), int(text_height * 0.25), color, alpha)

                            if scale != 1.0:
                                new_size = (int(temp_img.width * scale), int(temp_img.height * scale))
                                temp_img = temp_img.resize(new_size, Image.Resampling.LANCZOS)

                            # ç²˜è´´åˆ°ä¸»å›¾åƒ
                            pil_img.paste(temp_img, (int(x - text_width * 0.25 * scale), int(y - text_height * 0.25 * scale)), temp_img)
                        else:
                            # ç›´æ¥ç»˜åˆ¶ç«–æ’æ–‡å­—
                            self._draw_vertical_text(draw, current_text, font, x, y, color, alpha)
                    else:
                        # æ¨ªæ’æ–‡å­—
                        if scale != 1.0 or alpha != 1.0:
                            # åˆ›å»ºä¸´æ—¶å›¾åƒç”¨äºç¼©æ”¾
                            temp_img = Image.new('RGBA', (int(text_width * 1.5), int(text_height * 1.5)), (0, 0, 0, 0))
                            temp_draw = ImageDraw.Draw(temp_img)
                            temp_draw.text((int(text_width * 0.25), int(text_height * 0.25)), current_text, font=font, fill=(*color, int(255 * alpha)))

                            if scale != 1.0:
                                new_size = (int(temp_img.width * scale), int(temp_img.height * scale))
                                temp_img = temp_img.resize(new_size, Image.Resampling.LANCZOS)

                            # ç²˜è´´åˆ°ä¸»å›¾åƒ
                            pil_img.paste(temp_img, (int(x - text_width * 0.25 * scale), int(y - text_height * 0.25 * scale)), temp_img)
                        else:
                            # ç›´æ¥ç»˜åˆ¶æ¨ªæ’æ–‡å­—
                            draw.text((x, y), current_text, font=font, fill=(*color, int(255 * alpha)))

                    # è½¬æ¢å› OpenCV æ ¼å¼
                    frame = cv2.cvtColor(np.array(pil_img.convert('RGB')), cv2.COLOR_RGB2BGR)

                out.write(frame)
                frame_count += 1

                # æ˜¾ç¤ºè¿›åº¦
                if frame_count % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    _log_info(f"â³ å¤„ç†è¿›åº¦: {progress:.1f}% ({frame_count}/{total_frames})")

            cap.release()
            out.release()

            _log_info(f"âœ… ä¸´æ—¶è§†é¢‘å·²ç”Ÿæˆ: {temp_output}")
            _log_info(f"ğŸ“¹ å®é™…å†™å…¥å¸§æ•°: {frame_count}")
            _log_info(f"ğŸ“¹ é¢„æœŸå¸§æ•°: {total_frames}")
            _log_info(f"ğŸ“¹ è§†é¢‘æ—¶é•¿: {frame_count / fps:.2f} ç§’")

            # æ£€æŸ¥å¸§æ•°æ˜¯å¦åŒ¹é…
            if abs(frame_count - total_frames) > 5:
                _log_info(f"âš ï¸ è­¦å‘Š: å†™å…¥å¸§æ•° ({frame_count}) ä¸é¢„æœŸ ({total_frames}) ä¸åŒ¹é…")

            # ä½¿ç”¨ FFmpeg è½¬æ¢ä¸º H.264 MP4ï¼ˆä¿ç•™éŸ³é¢‘ï¼‰
            _log_info(f"ğŸ”„ æ­£åœ¨è½¬æ¢ä¸º H.264 æ ¼å¼...")

            # ä¿®å¤ï¼šä½¿ç”¨ -shortest ç¡®ä¿è§†é¢‘å’ŒéŸ³é¢‘æ—¶é•¿ä¸€è‡´
            # ä½¿ç”¨ -async 1 ç¡®ä¿éŸ³è§†é¢‘åŒæ­¥
            # ä¼˜åŒ–æµåª’ä½“æ’­æ”¾ï¼šfaststart, å…³é”®å¸§é—´éš”
            cmd = [
                "ffmpeg",
                "-i", temp_output,     # å¸¦å­—å¹•çš„è§†é¢‘
                "-i", video_path,      # åŸå§‹è§†é¢‘ï¼ˆç”¨äºæå–éŸ³é¢‘ï¼‰
                "-map", "0:v:0",       # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å…¥çš„è§†é¢‘æµ
                "-map", "1:a:0?",      # ä½¿ç”¨ç¬¬äºŒä¸ªè¾“å…¥çš„éŸ³é¢‘æµï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                "-c:v", "libx264",     # H.264 ç¼–ç 
                "-preset", "medium",
                "-crf", "23",
                "-c:a", "aac",         # é‡æ–°ç¼–ç éŸ³é¢‘ï¼ˆè€Œä¸æ˜¯ copyï¼‰
                "-b:a", "192k",        # éŸ³é¢‘æ¯”ç‰¹ç‡
                "-shortest",           # ä½¿ç”¨æœ€çŸ­çš„æµä½œä¸ºè¾“å‡ºæ—¶é•¿
                "-async", "1",         # éŸ³è§†é¢‘åŒæ­¥
                "-vsync", "cfr",       # æ’å®šå¸§ç‡
                "-movflags", "+faststart",  # ä¼˜åŒ–æµåª’ä½“æ’­æ”¾
                "-g", "30",            # å…³é”®å¸§é—´éš”ï¼ˆæ¯ç§’ä¸€ä¸ªå…³é”®å¸§ï¼‰
                "-keyint_min", "30",   # æœ€å°å…³é”®å¸§é—´éš”
                "-sc_threshold", "0",  # ç¦ç”¨åœºæ™¯åˆ‡æ¢æ£€æµ‹
                "-y",
                output_path
            ]

            _log_info(f"ğŸ¬ FFmpeg å‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(temp_output)
            except:
                pass

            if result.returncode == 0 and os.path.exists(output_path):
                _log_info(f"âœ… å­—å¹•çƒ§å½•æˆåŠŸ: {output_path}")
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤§å°
                file_size = os.path.getsize(output_path)
                _log_info(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
                if file_size < 1024:
                    _log_error(f"âš ï¸ è¾“å‡ºæ–‡ä»¶å¤ªå° ({file_size} bytes)ï¼Œå¯èƒ½æœ‰é—®é¢˜")

                # æ£€æŸ¥è¾“å‡ºè§†é¢‘æ—¶é•¿
                try:
                    check_cap = cv2.VideoCapture(output_path)
                    if check_cap.isOpened():
                        output_fps = check_cap.get(cv2.CAP_PROP_FPS)
                        output_frames = int(check_cap.get(cv2.CAP_PROP_FRAME_COUNT))
                        output_duration = output_frames / output_fps if output_fps > 0 else 0
                        _log_info(f"ğŸ“¹ è¾“å‡ºè§†é¢‘: {output_frames} å¸§ @ {output_fps:.2f}fps = {output_duration:.2f} ç§’")

                        # ä¸åŸå§‹è§†é¢‘å¯¹æ¯”
                        original_duration = total_frames / fps if fps > 0 else 0
                        _log_info(f"ğŸ“¹ åŸå§‹è§†é¢‘: {total_frames} å¸§ @ {fps:.2f}fps = {original_duration:.2f} ç§’")

                        if abs(output_duration - original_duration) > 0.5:
                            _log_info(f"âš ï¸ è­¦å‘Š: è¾“å‡ºè§†é¢‘æ—¶é•¿ ({output_duration:.2f}s) ä¸åŸå§‹ ({original_duration:.2f}s) ä¸åŒ¹é…")
                        check_cap.release()
                except Exception as e:
                    _log_info(f"âš ï¸ æ— æ³•æ£€æŸ¥è¾“å‡ºè§†é¢‘æ—¶é•¿: {e}")

                return output_path
            else:
                _log_error(f"âŒ FFmpeg è½¬æ¢å¤±è´¥ (è¿”å›ç : {result.returncode})")
                _log_error(f"âŒ FFmpeg stderr: {result.stderr}")
                _log_error(f"âŒ FFmpeg stdout: {result.stdout}")
                # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_output):
                    os.rename(temp_output, output_path)
                    _log_info(f"âš ï¸ ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä½œä¸ºè¾“å‡º: {output_path}")
                    return output_path
                return None

        except Exception as e:
            _log_error(f"âŒ å­—å¹•çƒ§å½•å¼‚å¸¸: {str(e)}")
            import traceback
            _log_error(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    def _convert_srt_to_ass(self, srt_path, ass_path, font_size, font_color, position, background):
        """å°† SRT å­—å¹•è½¬æ¢ä¸º ASS æ ¼å¼å¹¶åº”ç”¨æ ·å¼"""
        try:
            # è¯»å– SRT æ–‡ä»¶
            with open(srt_path, 'r', encoding='utf-8') as f:
                srt_content = f.read()

            # è§£æ SRT
            import re
            pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n((?:.*\n)*?)(?=\n\d+\n|\Z)'
            matches = re.findall(pattern, srt_content, re.MULTILINE)

            # è®¾ç½®å¯¹é½æ–¹å¼
            if position == "bottom":
                alignment = 2  # åº•éƒ¨å±…ä¸­
                margin_v = 20
            elif position == "top":
                alignment = 8  # é¡¶éƒ¨å±…ä¸­
                margin_v = 20
            else:  # middle
                alignment = 5  # ä¸­é—´å±…ä¸­
                margin_v = 0

            # è·å–é¢œè‰²ä»£ç 
            color_code = self._get_color_code(font_color)

            # è®¾ç½®èƒŒæ™¯
            if background == "yes":
                outline = 1
                shadow = 2
                back_color = "&H80000000"  # åŠé€æ˜é»‘è‰²
            else:
                outline = 1
                shadow = 0
                back_color = "&H00000000"  # é€æ˜

            # åˆ›å»º ASS æ–‡ä»¶å¤´
            ass_content = f"""[Script Info]
Title: Generated Subtitle
ScriptType: v4.00+
WrapStyle: 0
PlayResX: 384
PlayResY: 288
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,{font_size},&H{color_code},&H000000FF,&H00000000,{back_color},0,0,0,0,100,100,0,0,1,{outline},{shadow},{alignment},10,10,{margin_v},1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

            # è½¬æ¢æ—¶é—´æ ¼å¼ä» SRT åˆ° ASS
            def srt_time_to_ass(srt_time):
                # SRT: 00:00:00,000 -> ASS: 0:00:00.00
                return srt_time.replace(',', '.')[:-1]

            # æ·»åŠ å­—å¹•äº‹ä»¶
            for match in matches:
                start_time = srt_time_to_ass(match[1])
                end_time = srt_time_to_ass(match[2])
                text = match[3].strip().replace('\n', '\\N')
                ass_content += f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}\n"

            # å†™å…¥ ASS æ–‡ä»¶
            with open(ass_path, 'w', encoding='utf-8') as f:
                f.write(ass_content)

            _log_info(f"âœ… ASS å­—å¹•å·²ç”Ÿæˆ: {ass_path}")

        except Exception as e:
            _log_error(f"âŒ SRT è½¬ ASS å¤±è´¥: {str(e)}")
            raise

    def _get_color_code(self, color_name):
        """è·å– ASS å­—å¹•é¢œè‰²ä»£ç ï¼ˆAABBGGRR æ ¼å¼ï¼‰"""
        color_map = {
            "white": "FFFFFF",
            "yellow": "00FFFF",
            "black": "000000",
            "red": "0000FF",
            "green": "00FF00",
            "blue": "FF0000",
        }
        return color_map.get(color_name, "00FFFF")  # é»˜è®¤é»„è‰²

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "VideoStitchingNode": VideoStitchingNode,
    "GetLastFrameNode": GetLastFrameNode,
    "GetFirstFrameNode": GetFirstFrameNode,
    "VideoUtilitiesGetVHSFilePath": VideoUtilitiesGetVHSFilePath,
    "VideoToGIFNode": VideoToGIFNode,
    "PreviewGIFNode": PreviewGIFNode,
    "VideoPreviewNode": VideoPreviewNode,
    "VideoUtilitiesUploadLiveVideo": VideoUtilitiesUploadLiveVideo,
    "VideoUtilitiesLoadAFVideo": VideoUtilitiesLoadAFVideo,
    "VideoUtilitiesPromptTextNode": VideoUtilitiesPromptTextNode,
    "VideoUtilitiesLiveVideoMonitor": VideoUtilitiesLiveVideoMonitor,
    "VideoUtilitiesRGBEmptyImage": VideoUtilitiesRGBEmptyImage,
    "VideoUtilitiesAudioToSubtitle": VideoUtilitiesAudioToSubtitle,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoStitchingNode": "Video_Stitching",
    "GetLastFrameNode": "Get_Last_Frame",
    "GetFirstFrameNode": "Get_First_Frame",
    "VideoUtilitiesGetVHSFilePath": "Get VHS File Path",
    "VideoToGIFNode": "Video_To_GIF",
    "PreviewGIFNode": "Preview_GIF",
    "VideoPreviewNode": "Video_Preview",
    "VideoUtilitiesUploadLiveVideo": "Upload_Live_Video",
    "VideoUtilitiesLoadAFVideo": "Load_AF_Video",
    "VideoUtilitiesPromptTextNode": "Prompt_Text_Node",
    "VideoUtilitiesLiveVideoMonitor": "Live_Video_Monitor",
    "VideoUtilitiesRGBEmptyImage": "RGB_Empty_Image",
    "VideoUtilitiesAudioToSubtitle": "Audio_To_Subtitle",
}

