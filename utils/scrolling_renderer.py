"""
æ»šåŠ¨å­—å¹•æ¸²æŸ“å™¨
å®ç°ä¸“ä¸šçš„ç”µå½±çº§æ»šåŠ¨æ•ˆæœ
"""

import os
import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from typing import Tuple
import math


def _log_info(message):
    print(f"[ScrollingRenderer] {message}")


def _log_error(message):
    print(f"[ScrollingRenderer ERROR] {message}")


class ScrollingRenderer:
    """æ»šåŠ¨å­—å¹•æ¸²æŸ“å™¨"""
    
    def __init__(self, video_width: int, video_height: int, fps: float):
        self.video_width = video_width
        self.video_height = video_height
        self.fps = fps
    
    def render_scrolling_text(
        self,
        video_path: str,
        output_path: str,
        text: str,
        font_path: str,
        font_size: int,
        font_color: str,
        scroll_type: str,
        scroll_speed: float,
        start_position: str,
        loop: bool,
        background_opacity: float,
        stroke_width: float,
        stroke_color: str,
        fade_in_duration: float,
        fade_out_duration: float,
        line_spacing: float,
        text_align: str,
        perspective_strength: float,
        offset_x: int = 0,
        offset_y: int = 0
    ):
        """
        æ¸²æŸ“æ»šåŠ¨å­—å¹•

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            text: æ»šåŠ¨æ–‡æœ¬
            å…¶ä»–å‚æ•°: å­—å¹•æ ·å¼å‚æ•°
        """
        _log_info(f"ğŸ¬ å¼€å§‹æ¸²æŸ“æ»šåŠ¨å­—å¹•")

        # æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")

        # è·å–è§†é¢‘ä¿¡æ¯
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / self.fps

        # åŠ è½½å­—ä½“
        try:
            font = ImageFont.truetype(font_path, font_size)
        except Exception as e:
            _log_error(f"åŠ è½½å­—ä½“å¤±è´¥: {e}")
            font = ImageFont.load_default()

        # é¢œè‰²æ˜ å°„
        color_map = {
            "white": (255, 255, 255),
            "yellow": (255, 255, 0),
            "black": (0, 0, 0),
            "red": (255, 0, 0),
            "green": (0, 255, 0),
            "blue": (0, 0, 255),
            "cyan": (0, 255, 255),
            "magenta": (255, 0, 255)
        }
        font_rgb = color_map.get(font_color, (255, 255, 0))
        stroke_rgb = color_map.get(stroke_color, (0, 0, 0)) if stroke_width > 0 else None

        # å‡†å¤‡æ–‡æœ¬
        lines = text.strip().split('\n')
        
        # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦å’Œæœ€å¤§å®½åº¦
        text_image = self._create_text_image(
            lines, font, font_rgb, stroke_width, stroke_rgb, 
            line_spacing, text_align
        )
        text_height = text_image.height
        text_width = text_image.width

        _log_info(f"ğŸ“ æ–‡æœ¬å°ºå¯¸: {text_width}x{text_height}")
        _log_info(f"ğŸ“¹ è§†é¢‘å°ºå¯¸: {self.video_width}x{self.video_height}")
        _log_info(f"â±ï¸ è§†é¢‘æ—¶é•¿: {duration:.2f}ç§’")
        _log_info(f"ğŸš€ åŸå§‹æ»šåŠ¨é€Ÿåº¦: {scroll_speed} åƒç´ /ç§’")

        # è®¡ç®—æ»šåŠ¨å‚æ•°
        scroll_params = self._calculate_scroll_params(
            scroll_type, scroll_speed, start_position,
            text_width, text_height, duration
        )
        
        _log_info(f"ğŸ¯ æ»šåŠ¨å‚æ•°: {scroll_params}")
        
        # è®¡ç®—å®é™…éœ€è¦çš„æ»šåŠ¨è·ç¦»å’Œæ—¶é—´
        if 'start_y' in scroll_params and 'end_y' in scroll_params:
            total_distance = abs(scroll_params['start_y'] - scroll_params['end_y'])
            time_needed = total_distance / scroll_speed
            _log_info(f"ğŸ“ æ»šåŠ¨è·ç¦»: {total_distance} åƒç´ ")
            _log_info(f"â±ï¸ éœ€è¦æ—¶é—´: {time_needed:.2f} ç§’ (è§†é¢‘æ—¶é•¿: {duration:.2f} ç§’)")
            
            if time_needed > duration:
                _log_info(f"âš ï¸ è­¦å‘Š: æ»šåŠ¨æ—¶é—´({time_needed:.2f}s) > è§†é¢‘æ—¶é•¿({duration:.2f}s)")
                _log_info(f"ğŸ’¡ å»ºè®®: æé«˜æ»šåŠ¨é€Ÿåº¦åˆ° {total_distance / duration:.1f} åƒç´ /ç§’")

        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, self.fps, (self.video_width, self.video_height))

        # é€å¸§å¤„ç†
        frame_idx = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            current_time = frame_idx / self.fps

            # è®¡ç®—å½“å‰å¸§çš„é€æ˜åº¦ï¼ˆæ·¡å…¥æ·¡å‡ºï¼‰
            alpha = self._calculate_fade_alpha(
                current_time, duration, fade_in_duration, fade_out_duration
            )

            if alpha > 0:
                # æ ¹æ®æ»šåŠ¨ç±»å‹ç»˜åˆ¶å­—å¹•
                frame = self._draw_scrolling_text(
                    frame, text_image, scroll_type, scroll_params,
                    current_time, alpha, background_opacity,
                    perspective_strength, loop, duration, offset_x, offset_y
                )

            out.write(frame)
            frame_idx += 1

            # è¿›åº¦æ˜¾ç¤ºï¼ˆæ¯30å¸§æ˜¾ç¤ºä¸€æ¬¡ï¼Œçº¦1ç§’ï¼‰
            if frame_idx % 30 == 0:
                progress = (frame_idx / total_frames) * 100
                _log_info(f"è¿›åº¦: {progress:.1f}% ({frame_idx}/{total_frames}) - æ—¶é—´: {current_time:.2f}s, Alpha: {alpha:.2f}")

        cap.release()
        out.release()

        # ä½¿ç”¨ ffmpeg åˆå¹¶éŸ³é¢‘
        _log_info(f"ğŸµ æ­£åœ¨åˆå¹¶éŸ³é¢‘...")
        self._merge_audio(video_path, output_path)

        _log_info(f"âœ… æ»šåŠ¨å­—å¹•æ¸²æŸ“å®Œæˆ: {output_path}")

    def _create_text_image(
        self,
        lines: list,
        font: ImageFont.FreeTypeFont,
        font_color: Tuple[int, int, int],
        stroke_width: float,
        stroke_color: Tuple[int, int, int],
        line_spacing: float,
        text_align: str
    ) -> Image.Image:
        """åˆ›å»ºæ–‡æœ¬å›¾åƒ"""
        
        # è®¡ç®—æ¯è¡Œçš„å°ºå¯¸
        temp_img = Image.new('RGBA', (1, 1))
        temp_draw = ImageDraw.Draw(temp_img)
        
        line_heights = []
        line_widths = []
        
        for line in lines:
            bbox = temp_draw.textbbox((0, 0), line, font=font)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])
        
        # è®¡ç®—æ€»å°ºå¯¸
        max_width = max(line_widths) if line_widths else 100
        line_height = max(line_heights) if line_heights else font.size
        total_height = int(line_height * line_spacing * len(lines))
        
        # æ·»åŠ è¾¹è·
        padding = int(stroke_width * 2 + 20)
        img_width = max_width + padding * 2
        img_height = total_height + padding * 2
        
        # åˆ›å»ºé€æ˜å›¾åƒ
        text_img = Image.new('RGBA', (img_width, img_height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(text_img)
        
        # ç»˜åˆ¶æ¯ä¸€è¡Œ
        y = padding
        for i, line in enumerate(lines):
            line_width = line_widths[i]
            
            # è®¡ç®— x ä½ç½®ï¼ˆå¯¹é½ï¼‰
            if text_align == "center":
                x = (img_width - line_width) // 2
            elif text_align == "right":
                x = img_width - line_width - padding
            else:  # left
                x = padding
            
            # ç»˜åˆ¶æè¾¹
            if stroke_width > 0 and stroke_color:
                for offset_x in range(-int(stroke_width), int(stroke_width) + 1):
                    for offset_y in range(-int(stroke_width), int(stroke_width) + 1):
                        if offset_x != 0 or offset_y != 0:
                            draw.text(
                                (x + offset_x, y + offset_y),
                                line,
                                font=font,
                                fill=(*stroke_color, 255)
                            )
            
            # ç»˜åˆ¶ä¸»æ–‡å­—
            draw.text((x, y), line, font=font, fill=(*font_color, 255))
            
            y += int(line_height * line_spacing)
        
        return text_img

    def _calculate_scroll_params(
        self,
        scroll_type: str,
        scroll_speed: float,
        start_position: str,
        text_width: int,
        text_height: int,
        duration: float
    ) -> dict:
        """è®¡ç®—æ»šåŠ¨å‚æ•°"""
        
        params = {
            'scroll_speed': scroll_speed,
            'text_width': text_width,
            'text_height': text_height
        }
        
        # æ ¹æ®æ»šåŠ¨ç±»å‹è®¡ç®—èµ·å§‹ä½ç½®
        if scroll_type == "vertical_up":
            # å‚ç›´å‘ä¸Šæ»šåŠ¨
            if start_position == "off_screen":
                params['start_y'] = self.video_height  # æ–‡æœ¬é¡¶éƒ¨åœ¨å±å¹•åº•éƒ¨ä¸‹æ–¹
            elif start_position == "bottom":
                params['start_y'] = self.video_height - 100  # æ–‡æœ¬åº•éƒ¨å¯¹é½å±å¹•åº•éƒ¨ï¼Œç•™100åƒç´ å¯è§
            elif start_position == "center":
                params['start_y'] = (self.video_height - text_height) // 2
            else:  # top
                params['start_y'] = 0
            
            params['end_y'] = -text_height
            params['x'] = (self.video_width - text_width) // 2
            
        elif scroll_type == "vertical_down":
            # å‚ç›´å‘ä¸‹æ»šåŠ¨
            if start_position == "off_screen":
                params['start_y'] = -text_height
            elif start_position == "top":
                params['start_y'] = 0
            elif start_position == "center":
                params['start_y'] = (self.video_height - text_height) // 2
            else:  # bottom
                params['start_y'] = self.video_height - text_height
            
            params['end_y'] = self.video_height
            params['x'] = (self.video_width - text_width) // 2
            
        elif scroll_type.startswith("horizontal_left"):
            # æ°´å¹³å‘å·¦æ»šåŠ¨
            if start_position == "off_screen":
                params['start_x'] = self.video_width
            else:
                params['start_x'] = self.video_width - text_width
            
            params['end_x'] = -text_width
            
            # æ ¹æ®æ»šåŠ¨ç±»å‹ç¡®å®šYä½ç½®
            if scroll_type == "horizontal_left_top":
                params['y'] = int(self.video_height * 0.1)  # é¡¶éƒ¨10%ä½ç½®
            elif scroll_type == "horizontal_left_bottom":
                params['y'] = int(self.video_height * 0.9 - text_height)  # åº•éƒ¨10%ä½ç½®
            else:  # horizontal_left_center æˆ– horizontal_leftï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
                params['y'] = (self.video_height - text_height) // 2  # ä¸­éƒ¨
            
        elif scroll_type.startswith("horizontal_right"):
            # æ°´å¹³å‘å³æ»šåŠ¨
            if start_position == "off_screen":
                params['start_x'] = -text_width
            else:
                params['start_x'] = 0
            
            params['end_x'] = self.video_width
            
            # æ ¹æ®æ»šåŠ¨ç±»å‹ç¡®å®šYä½ç½®
            if scroll_type == "horizontal_right_top":
                params['y'] = int(self.video_height * 0.1)  # é¡¶éƒ¨10%ä½ç½®
            elif scroll_type == "horizontal_right_bottom":
                params['y'] = int(self.video_height * 0.9 - text_height)  # åº•éƒ¨10%ä½ç½®
            else:  # horizontal_right_center æˆ– horizontal_rightï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
                params['y'] = (self.video_height - text_height) // 2  # ä¸­éƒ¨
            
        elif scroll_type == "star_wars":
            # æ˜Ÿæˆ˜å¼3Dé€è§†æ»šåŠ¨
            if start_position == "off_screen":
                params['start_y'] = self.video_height
            elif start_position == "bottom":
                params['start_y'] = self.video_height - 100  # ç•™100åƒç´ å¯è§
            elif start_position == "center":
                params['start_y'] = (self.video_height - text_height) // 2
            else:  # top
                params['start_y'] = 0
            
            params['end_y'] = -text_height
            params['x'] = (self.video_width - text_width) // 2
            
        elif scroll_type == "fade_scroll":
            # æ¸å˜æ»šåŠ¨
            if start_position == "off_screen":
                params['start_y'] = self.video_height
            elif start_position == "bottom":
                params['start_y'] = self.video_height - 100  # ç•™100åƒç´ å¯è§
            elif start_position == "center":
                params['start_y'] = (self.video_height - text_height) // 2
            else:  # top
                params['start_y'] = 0
            
            params['end_y'] = -text_height
            params['x'] = (self.video_width - text_width) // 2
        
        return params

    def _calculate_fade_alpha(
        self,
        current_time: float,
        duration: float,
        fade_in_duration: float,
        fade_out_duration: float
    ) -> float:
        """è®¡ç®—æ·¡å…¥æ·¡å‡ºé€æ˜åº¦"""
        
        alpha = 1.0
        
        # æ·¡å…¥
        if current_time < fade_in_duration:
            alpha = current_time / fade_in_duration if fade_in_duration > 0 else 1.0
        
        # æ·¡å‡º
        time_until_end = duration - current_time
        if time_until_end < fade_out_duration:
            alpha = min(alpha, time_until_end / fade_out_duration if fade_out_duration > 0 else 1.0)
        
        return max(0.0, min(1.0, alpha))

    def _draw_scrolling_text(
        self,
        frame: np.ndarray,
        text_img: Image.Image,
        scroll_type: str,
        params: dict,
        current_time: float,
        alpha: float,
        background_opacity: float,
        perspective_strength: float,
        loop: bool,
        duration: float,
        offset_x: int = 0,
        offset_y: int = 0
    ) -> np.ndarray:
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ»šåŠ¨æ–‡æœ¬"""
        
        # è½¬æ¢ä¸º PIL Image
        pil_frame = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        
        # è®¡ç®—å½“å‰ä½ç½®
        if scroll_type in ["vertical_up", "vertical_down", "fade_scroll"]:
            # å‚ç›´æ»šåŠ¨
            distance = abs(params['start_y'] - params['end_y'])
            if distance > 0:
                progress = (current_time * params['scroll_speed']) / distance

                # å¾ªç¯é€»è¾‘
                if loop:
                    # ä½¿ç”¨æ¨¡è¿ç®—å®ç°å¾ªç¯
                    progress = progress % 1.0
                else:
                    # ä¸å¾ªç¯ï¼Œé™åˆ¶åœ¨0-1ä¹‹é—´
                    progress = min(progress, 1.0)
            else:
                progress = 0.0

            if scroll_type == "vertical_up" or scroll_type == "fade_scroll" or scroll_type == "star_wars":
                # å‘ä¸Šæ»šåŠ¨
                current_y = int(params['start_y'] - progress * distance)
            else:
                # å‘ä¸‹æ»šåŠ¨
                current_y = int(params['start_y'] + progress * distance)

            current_x = params['x']

            # åº”ç”¨åç§»é‡
            # offset_x: æ­£æ•°å‘å³ï¼Œè´Ÿæ•°å‘å·¦
            # offset_y: æ­£æ•°å‘ä¸Šï¼Œè´Ÿæ•°å‘ä¸‹ï¼ˆæ³¨æ„ï¼šå›¾åƒåæ ‡ç³» Y è½´å‘ä¸‹ï¼Œæ‰€ä»¥è¦å–åï¼‰
            current_x += offset_x
            current_y -= offset_y

            if scroll_type == "fade_scroll":
                # æ¸å˜æ»šåŠ¨ï¼šæ ¹æ®ä½ç½®è°ƒæ•´é€æ˜åº¦
                screen_progress = (params['start_y'] - current_y) / (params['start_y'] + params['text_height'])
                alpha *= self._calculate_gradient_alpha(screen_progress)
            
        elif scroll_type.startswith("horizontal_left") or scroll_type.startswith("horizontal_right"):
            # æ°´å¹³æ»šåŠ¨
            distance = abs(params['start_x'] - params['end_x'])
            if distance > 0:
                progress = (current_time * params['scroll_speed']) / distance

                # å¾ªç¯é€»è¾‘
                if loop:
                    # ä½¿ç”¨æ¨¡è¿ç®—å®ç°å¾ªç¯
                    progress = progress % 1.0
                else:
                    # ä¸å¾ªç¯ï¼Œé™åˆ¶åœ¨0-1ä¹‹é—´
                    progress = min(progress, 1.0)
            else:
                progress = 0.0

            if scroll_type.startswith("horizontal_left"):
                current_x = int(params['start_x'] - progress * distance)
            else:
                current_x = int(params['start_x'] + progress * distance)

            current_y = params['y']

            # åº”ç”¨åç§»é‡
            # offset_x: æ­£æ•°å‘å³ï¼Œè´Ÿæ•°å‘å·¦
            # offset_y: æ­£æ•°å‘ä¸Šï¼Œè´Ÿæ•°å‘ä¸‹ï¼ˆæ³¨æ„ï¼šå›¾åƒåæ ‡ç³» Y è½´å‘ä¸‹ï¼Œæ‰€ä»¥è¦å–åï¼‰
            current_x += offset_x
            current_y -= offset_y
            
        elif scroll_type == "star_wars":
            # æ˜Ÿæˆ˜å¼3Dé€è§†æ»šåŠ¨
            distance = abs(params['start_y'] - params['end_y'])
            if distance > 0:
                progress = (current_time * params['scroll_speed']) / distance

                # å¾ªç¯é€»è¾‘
                if loop:
                    # ä½¿ç”¨æ¨¡è¿ç®—å®ç°å¾ªç¯
                    progress = progress % 1.0
                else:
                    # ä¸å¾ªç¯ï¼Œé™åˆ¶åœ¨0-1ä¹‹é—´
                    progress = min(progress, 1.0)
            else:
                progress = 0.0

            current_y = int(params['start_y'] - progress * distance)

            # åº”ç”¨3Dé€è§†å˜æ¢
            text_img = self._apply_perspective_transform(
                text_img, current_y, perspective_strength
            )

            current_x = (self.video_width - text_img.width) // 2

            # åº”ç”¨åç§»é‡
            # offset_x: æ­£æ•°å‘å³ï¼Œè´Ÿæ•°å‘å·¦
            # offset_y: æ­£æ•°å‘ä¸Šï¼Œè´Ÿæ•°å‘ä¸‹ï¼ˆæ³¨æ„ï¼šå›¾åƒåæ ‡ç³» Y è½´å‘ä¸‹ï¼Œæ‰€ä»¥è¦å–åï¼‰
            current_x += offset_x
            current_y -= offset_y
        
        # åº”ç”¨é€æ˜åº¦
        if alpha < 1.0:
            text_img = self._apply_alpha(text_img, alpha)
        
        # ç»˜åˆ¶èƒŒæ™¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if background_opacity > 0:
            bg_layer = Image.new('RGBA', pil_frame.size, (0, 0, 0, 0))
            bg_draw = ImageDraw.Draw(bg_layer)
            
            bg_padding = 20
            bg_x1 = max(0, current_x - bg_padding)
            bg_y1 = max(0, current_y - bg_padding)
            bg_x2 = min(self.video_width, current_x + text_img.width + bg_padding)
            bg_y2 = min(self.video_height, current_y + text_img.height + bg_padding)
            
            bg_draw.rectangle(
                [bg_x1, bg_y1, bg_x2, bg_y2],
                fill=(0, 0, 0, int(255 * background_opacity * alpha))
            )
            
            pil_frame = Image.alpha_composite(pil_frame.convert('RGBA'), bg_layer)
        
        # ç²˜è´´æ–‡æœ¬ï¼ˆç¡®ä¿è½¬æ¢ä¸ºRGBAæ¨¡å¼ï¼‰
        if pil_frame.mode != 'RGBA':
            pil_frame = pil_frame.convert('RGBA')
        
        # è°ƒè¯•ï¼šæ¯ç§’è¾“å‡ºä¸€æ¬¡ä½ç½®ä¿¡æ¯
        if int(current_time * 10) % 10 == 0:  # æ¯0.1ç§’
            _log_info(f"ğŸ“ ä½ç½®: x={current_x}, y={current_y}, æ–‡æœ¬å°ºå¯¸: {text_img.width}x{text_img.height}, å±å¹•: {self.video_width}x{self.video_height}")
        
        # ç²˜è´´æ–‡æœ¬ï¼ˆåªè¦æœ‰éƒ¨åˆ†åœ¨å±å¹•å†…å°±ç²˜è´´ï¼‰
        if (current_x + text_img.width > 0 and current_x < self.video_width and
            current_y + text_img.height > 0 and current_y < self.video_height):
            pil_frame.paste(text_img, (current_x, current_y), text_img)
        else:
            # è°ƒè¯•ï¼šæ–‡æœ¬ä¸åœ¨å¯è§åŒºåŸŸ
            if int(current_time * 10) % 10 == 0:
                _log_info(f"âš ï¸ æ–‡æœ¬ä¸åœ¨å¯è§åŒºåŸŸ")
        
        # è½¬æ¢å› OpenCV æ ¼å¼
        return cv2.cvtColor(np.array(pil_frame.convert('RGB')), cv2.COLOR_RGB2BGR)

    def _apply_perspective_transform(
        self,
        img: Image.Image,
        y_position: int,
        strength: float
    ) -> Image.Image:
        """åº”ç”¨3Dé€è§†å˜æ¢ï¼ˆæ˜Ÿæˆ˜æ•ˆæœï¼‰"""
        
        if strength <= 0:
            return img
        
        # è®¡ç®—é€è§†æ¯”ä¾‹
        screen_ratio = 1.0 - (y_position / self.video_height)
        screen_ratio = max(0.1, min(1.0, screen_ratio))
        
        # åº”ç”¨é€è§†ç¼©æ”¾
        scale_factor = 0.3 + 0.7 * screen_ratio * (1.0 - strength * 0.7)
        new_width = int(img.width * scale_factor)
        new_height = int(img.height * scale_factor)
        
        if new_width > 0 and new_height > 0:
            return img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        return img

    def _calculate_gradient_alpha(self, progress: float) -> float:
        """è®¡ç®—æ¸å˜é€æ˜åº¦"""
        
        # åœ¨å±å¹•é¡¶éƒ¨å’Œåº•éƒ¨æ¸å˜
        if progress < 0.2:
            return progress / 0.2
        elif progress > 0.8:
            return (1.0 - progress) / 0.2
        else:
            return 1.0

    def _apply_alpha(self, img: Image.Image, alpha: float) -> Image.Image:
        """åº”ç”¨é€æ˜åº¦"""
        
        img_with_alpha = img.copy()
        
        # è·å– alpha é€šé“
        if img_with_alpha.mode != 'RGBA':
            img_with_alpha = img_with_alpha.convert('RGBA')
        
        # è°ƒæ•´ alpha é€šé“
        alpha_channel = img_with_alpha.split()[3]
        alpha_channel = alpha_channel.point(lambda p: int(p * alpha))
        img_with_alpha.putalpha(alpha_channel)
        
        return img_with_alpha

    def _merge_audio(self, source_video: str, target_video: str):
        """ä½¿ç”¨ ffmpeg å°†æºè§†é¢‘çš„éŸ³é¢‘åˆå¹¶åˆ°ç›®æ ‡è§†é¢‘"""
        import subprocess
        
        temp_output = target_video + ".temp.mp4"
        
        try:
            cmd = [
                'ffmpeg',
                '-i', target_video,
                '-i', source_video,
                '-map', '0:v:0',
                '-map', '1:a:0?',
                '-c:v', 'copy',
                '-c:a', 'aac',
                '-shortest',
                '-y',
                temp_output
            ]
            
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            if result.returncode == 0:
                import shutil
                shutil.move(temp_output, target_video)
                _log_info(f"âœ… éŸ³é¢‘åˆå¹¶æˆåŠŸ")
            else:
                _log_error(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {result.stderr}")
                if os.path.exists(temp_output):
                    os.remove(temp_output)
        
        except FileNotFoundError:
            _log_error(f"âŒ æœªæ‰¾åˆ° ffmpegï¼Œæ— æ³•åˆå¹¶éŸ³é¢‘")
            if os.path.exists(temp_output):
                os.remove(temp_output)
        
        except Exception as e:
            _log_error(f"âŒ éŸ³é¢‘åˆå¹¶å‡ºé”™: {str(e)}")
            if os.path.exists(temp_output):
                os.remove(temp_output)